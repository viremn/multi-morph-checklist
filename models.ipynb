{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from accelerate import init_empty_weights\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  83%|████████▎ | 5/6 [00:41<00:10, 10.29s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mGPT_model = AutoModelForCausalLM.from_pretrained('ai-forever/mGPT-13B', device_map=\"auto\", offload_folder=\"offload\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.wte.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.wpe.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.0.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.1.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.2.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.3.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.4.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.5.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.6.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.7.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.8.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.9.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.10.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.11.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.12.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.13.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00, 11.33it/s]/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.14.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.15.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.16.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.17.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.18.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.19.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.20.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.21.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.22.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.23.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.24.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.25.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.26.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.27.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.28.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00, 10.97it/s]/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.29.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.30.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.31.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.32.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.33.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.34.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.35.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.36.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.37.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.38.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.ln_1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.ln_1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.attn.c_attn.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.attn.c_attn.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.attn.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.attn.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.ln_2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.ln_2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.mlp.c_fc.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.mlp.c_fc.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.mlp.c_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.h.39.mlp.c_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.ln_f.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for transformer.ln_f.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/home/norrman/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for lm_head.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 10.61it/s]\n"
     ]
    }
   ],
   "source": [
    "with init_empty_weights():\n",
    "    mGPT_model = AutoModelForCausalLM.from_pretrained(\"ai-forever/mGPT-13B\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mGPT_pipe = pipeline(\"text-generation\", model=\"ai-forever/mGPT-13B\")\n",
    "\n",
    "\n",
    "# mGPT_tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/mGPT-13B\")\n",
    "# mGPT_model = AutoModelForCausalLM.from_pretrained(\"ai-forever/mGPT-13B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGLM_tokenizer = AutoTokenizer.from_pretrained(\"facebook/xglm-564M\")\n",
    "XGLM_model = AutoModelForCausalLM.from_pretrained(\"facebook/xglm-564M\")\n",
    "\n",
    "XGLM_pipe = pipeline(\"text-generation\", model=\"facebook/xglm-564M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     2,  37248,     53,  87674,    256,    422, 128590,      4,    540,\n",
       "           7102,     53,  36890,    256,      5,  16850,    256, 128590,     28]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'Emma and Monica are not doctors, but Mark and Andrew are.'\n",
    "question = 'Who are doctors?'\n",
    "answer = 'Mark and Andrew.'\n",
    "\n",
    "inputs = XGLM_tokenizer(context + ' ' + question, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=tensor(8.0554, grad_fn=<NllLossBackward0>), logits=tensor([[[-2.6019, -2.7024, 23.7592,  ..., -2.3627, -2.8033, -2.4592],\n",
       "         [-1.4118, -2.1522, 33.1611,  ..., -0.9947, -2.3361, -2.4036],\n",
       "         [-1.2028, -2.0319, 37.6757,  ..., -1.2416, -2.1702, -2.4323],\n",
       "         ...,\n",
       "         [-0.4248, -1.3479, 58.3325,  ...,  0.3015, -1.3919, -2.2220],\n",
       "         [ 0.2053, -0.8029, 59.3268,  ...,  0.8111, -0.8421, -2.0320],\n",
       "         [-0.2830, -0.9417, 62.7670,  ...,  0.5663, -0.9786, -0.9961]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[ 0.6833, -0.2425, -0.7981,  ...,  0.1691,  0.2525, -0.0896],\n",
       "          [ 0.4186, -0.9559,  0.2865,  ...,  0.2985, -0.2212, -0.5420],\n",
       "          [ 1.0518, -1.0907, -0.2447,  ..., -0.1912,  0.6064,  0.6801],\n",
       "          ...,\n",
       "          [ 0.3815, -0.1635, -0.3790,  ...,  0.7586, -0.1006,  0.9094],\n",
       "          [ 0.4064,  0.9045,  0.2225,  ..., -0.2729, -0.0916, -0.6946],\n",
       "          [ 0.4343, -0.4388, -0.5212,  ...,  0.4996,  0.4285,  0.1704]],\n",
       "\n",
       "         [[ 0.9573, -0.3581, -0.3643,  ...,  0.0151, -2.1183, -0.2684],\n",
       "          [ 0.7671,  1.9932,  0.4520,  ...,  0.5319,  0.9042, -0.7692],\n",
       "          [-1.1113, -0.3000, -0.3576,  ..., -0.4826,  0.4646,  1.0367],\n",
       "          ...,\n",
       "          [-0.3584,  0.4343,  1.1502,  ..., -1.1926, -1.8075,  0.5001],\n",
       "          [ 1.9574,  0.4151, -1.8156,  ..., -0.3745, -0.2211, -0.9734],\n",
       "          [ 0.4534, -0.7910,  0.2671,  ...,  0.4684,  0.6192, -0.7197]],\n",
       "\n",
       "         [[-0.5760,  0.6985, -0.0922,  ..., -0.2084,  0.0369,  0.5118],\n",
       "          [ 1.3634,  1.0690,  0.9311,  ..., -0.2558,  1.6848, -2.3373],\n",
       "          [ 0.8327, -0.6221,  0.5068,  ...,  0.9057,  0.8754, -0.9944],\n",
       "          ...,\n",
       "          [ 1.0814, -0.8244,  0.1529,  ...,  0.5851,  0.5116, -1.6676],\n",
       "          [ 0.4254, -1.2760, -0.0925,  ...,  0.8128,  1.9194, -0.6750],\n",
       "          [ 0.2439,  0.4192, -0.3618,  ..., -0.1206, -0.4085,  0.1719]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4508,  0.6371,  0.5233,  ...,  0.2902,  0.5445, -0.6182],\n",
       "          [-1.2287, -1.9601, -2.1249,  ...,  0.6202, -1.1572, -1.3468],\n",
       "          [ 0.4782, -0.6156, -0.9828,  ...,  0.9731, -0.1659, -1.0535],\n",
       "          ...,\n",
       "          [-0.9071,  0.8867,  0.5789,  ..., -0.5771,  0.2244, -2.1790],\n",
       "          [ 0.5065,  0.7095,  1.8458,  ..., -0.7731, -1.5218, -1.7629],\n",
       "          [-0.0597, -0.9060,  0.3674,  ..., -1.4235,  0.5729, -0.5871]],\n",
       "\n",
       "         [[-1.4665, -0.1987,  0.6019,  ..., -0.5060, -0.1687,  0.0097],\n",
       "          [-0.2451, -0.3344,  0.8143,  ...,  0.8047,  0.8543,  0.7144],\n",
       "          [ 0.2384, -1.5916, -0.4650,  ...,  0.2353,  0.2006, -0.9573],\n",
       "          ...,\n",
       "          [ 1.8566, -1.5074,  0.9950,  ...,  0.7735,  1.3006,  1.0160],\n",
       "          [ 0.8138,  0.4303,  0.7467,  ..., -1.1807,  0.9996, -0.1395],\n",
       "          [-0.5030,  0.5962, -0.4344,  ...,  0.4094,  0.9113,  1.9073]],\n",
       "\n",
       "         [[-0.7950,  1.0900,  0.4308,  ...,  0.1675, -1.8816, -1.3043],\n",
       "          [-0.6843,  0.7948, -1.2376,  ..., -0.6317, -2.6487, -2.4311],\n",
       "          [-0.0089, -0.3831,  0.6258,  ..., -0.7449, -1.1721, -1.9317],\n",
       "          ...,\n",
       "          [-1.7569, -0.5886,  1.6796,  ...,  0.5086, -0.7442, -2.4494],\n",
       "          [-0.0503,  0.5310, -0.6715,  ..., -2.4542, -1.2016, -1.8353],\n",
       "          [-0.5504, -0.0929,  0.2274,  ..., -0.1027, -2.6195, -0.9091]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 4.9796e-01,  8.3864e-01,  7.3965e-01,  ..., -1.6212e+00,\n",
       "           -7.9371e-01,  1.0779e+00],\n",
       "          [-1.3180e+00, -5.7183e-02,  4.7231e-02,  ..., -9.2225e-01,\n",
       "            6.4938e-01, -1.7138e-01],\n",
       "          [ 4.5345e-01, -1.2111e+00, -1.0529e-01,  ..., -2.5719e-01,\n",
       "           -1.5339e+00,  5.6940e-01],\n",
       "          ...,\n",
       "          [-8.5322e-01,  1.2956e+00, -1.6544e+00,  ..., -1.2635e+00,\n",
       "           -1.2467e+00,  9.7383e-01],\n",
       "          [-1.3845e+00, -2.5821e-01, -5.8537e-01,  ..., -1.8078e+00,\n",
       "           -1.7429e-01, -8.7395e-01],\n",
       "          [ 3.1970e-02,  1.3784e+00,  5.2064e-01,  ..., -1.9270e+00,\n",
       "           -6.2752e-01,  3.6563e-02]],\n",
       "\n",
       "         [[-4.4398e-01,  5.4297e-01,  1.0010e+00,  ...,  2.2567e+00,\n",
       "           -1.0689e+00, -1.6018e+00],\n",
       "          [ 1.5499e-01,  3.7075e-01, -6.3244e-02,  ..., -8.7470e-01,\n",
       "            8.4078e-01,  1.4157e+00],\n",
       "          [ 4.4790e-01, -4.5956e-01,  4.4897e-01,  ...,  6.0389e-01,\n",
       "            1.2864e+00, -9.3352e-01],\n",
       "          ...,\n",
       "          [-3.6449e-01, -8.1387e-01, -7.8505e-01,  ...,  6.3304e-01,\n",
       "            1.2404e-01, -6.7104e-01],\n",
       "          [ 1.4345e+00,  1.9254e+00, -4.6290e-01,  ..., -6.4121e-01,\n",
       "            2.1337e+00, -9.4864e-01],\n",
       "          [ 2.5430e+00,  6.3009e-01, -8.6929e-01,  ..., -1.3666e+00,\n",
       "           -2.7559e-01,  7.5407e-01]],\n",
       "\n",
       "         [[-7.1792e-01, -2.6537e+00,  4.9106e-01,  ...,  5.7534e-02,\n",
       "            4.9904e-01, -9.2049e-01],\n",
       "          [ 1.2703e-01, -5.6966e-01, -2.0060e-01,  ..., -2.6783e-01,\n",
       "           -3.3441e-01,  4.1006e-01],\n",
       "          [ 1.2859e-01, -1.3971e+00, -1.0398e+00,  ...,  1.8703e-01,\n",
       "            1.7267e-02,  3.6597e-01],\n",
       "          ...,\n",
       "          [-7.0578e-01, -1.1736e+00, -1.1725e+00,  ..., -1.3648e-01,\n",
       "           -1.8229e-01,  4.7503e-01],\n",
       "          [-4.7767e-01,  8.3545e-04, -1.6275e+00,  ..., -3.6777e-01,\n",
       "            6.2654e-01,  2.1982e-01],\n",
       "          [-2.1382e-01,  9.4307e-02, -3.6120e-01,  ..., -1.1322e+00,\n",
       "           -1.7850e-01, -2.3736e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.0606e-01,  3.6846e-01, -1.4962e-01,  ..., -1.0321e-01,\n",
       "            1.3560e-01, -8.3008e-01],\n",
       "          [ 4.8806e-02, -1.0678e+00,  5.0532e-01,  ...,  7.1631e-02,\n",
       "           -9.9044e-01,  5.8660e-01],\n",
       "          [-5.8219e-02, -2.9421e-01,  3.6594e-01,  ...,  1.3004e+00,\n",
       "           -4.8869e-01, -8.8352e-01],\n",
       "          ...,\n",
       "          [ 3.6031e-01,  2.7972e-01,  6.5645e-01,  ...,  6.1712e-01,\n",
       "            1.6280e-01, -8.1566e-01],\n",
       "          [ 1.2648e+00, -2.2407e-01,  2.0857e-01,  ...,  7.3628e-01,\n",
       "           -1.3085e+00, -9.4682e-01],\n",
       "          [-2.6582e-01, -2.8746e-01, -6.9686e-01,  ...,  1.0122e+00,\n",
       "            6.3014e-01,  1.0114e-01]],\n",
       "\n",
       "         [[-5.8344e-01,  1.5213e+00, -4.2943e-01,  ...,  1.6560e-02,\n",
       "           -9.0992e-01, -3.7074e-01],\n",
       "          [-7.6290e-01, -1.5563e-01,  7.9698e-01,  ...,  3.4970e-01,\n",
       "           -5.4965e-01, -8.9292e-01],\n",
       "          [-7.9914e-01,  1.3469e+00, -1.7013e+00,  ..., -2.8151e-02,\n",
       "            3.8591e-01,  2.6147e-01],\n",
       "          ...,\n",
       "          [ 1.7649e-01,  1.4121e+00,  8.7790e-02,  ..., -5.2260e-02,\n",
       "            1.9807e-02,  2.5219e-02],\n",
       "          [-1.4178e+00,  4.2159e-01,  2.0463e-01,  ..., -1.2088e+00,\n",
       "           -8.8915e-01,  9.2370e-01],\n",
       "          [ 1.1731e+00, -6.9549e-01, -5.9077e-01,  ..., -6.5013e-01,\n",
       "            1.7701e-01, -1.1664e+00]],\n",
       "\n",
       "         [[-4.7224e-01, -1.4135e-01, -1.4400e+00,  ..., -1.7161e-01,\n",
       "            4.9184e-01, -3.3131e-01],\n",
       "          [ 6.4846e-01, -8.3768e-01,  1.0785e+00,  ..., -2.2506e-01,\n",
       "           -3.3960e-01,  3.3594e-01],\n",
       "          [ 2.5750e-01, -8.0217e-01, -3.3189e-01,  ..., -2.2588e-01,\n",
       "            3.3811e-01,  3.4845e-01],\n",
       "          ...,\n",
       "          [-2.5348e-01,  5.2119e-01, -3.7190e-01,  ..., -1.6005e-01,\n",
       "           -9.2980e-01,  7.9044e-01],\n",
       "          [ 2.6739e-01, -1.2335e+00,  1.1160e+00,  ...,  6.7393e-01,\n",
       "           -1.2356e+00, -3.4074e-01],\n",
       "          [ 8.0534e-02,  3.1596e-01, -1.3471e+00,  ..., -1.1865e-01,\n",
       "            4.0771e-01,  2.7647e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.1074, -2.0165,  2.2562,  ...,  1.4369, -0.6917, -0.3495],\n",
       "          [-1.1945, -3.4317,  2.4583,  ...,  2.4844, -1.7166,  0.9832],\n",
       "          [-1.0517, -2.2294,  2.3105,  ...,  1.0292, -0.9387, -0.5451],\n",
       "          ...,\n",
       "          [-1.0551, -1.2240,  1.2463,  ...,  0.6992, -0.8165, -0.6813],\n",
       "          [-1.9573, -1.5995,  1.5329,  ...,  1.2334, -2.1123, -0.4757],\n",
       "          [-0.9928, -1.1486,  1.5753,  ...,  0.7514, -0.9918, -1.2342]],\n",
       "\n",
       "         [[-0.0632,  0.4719,  1.5443,  ...,  0.4062, -0.0591,  1.1828],\n",
       "          [ 1.2501, -0.5213,  2.6478,  ...,  0.4394,  0.1450,  1.4162],\n",
       "          [ 1.7955, -0.1893,  0.2834,  ..., -0.0743,  0.1199,  0.8680],\n",
       "          ...,\n",
       "          [ 2.0066, -0.5254,  1.0493,  ...,  0.4959, -0.6736,  1.1382],\n",
       "          [ 1.3916, -2.2792,  1.9001,  ...,  0.6355, -0.3168,  0.5988],\n",
       "          [ 0.2142,  0.3708,  1.3079,  ..., -0.9636, -0.2022,  1.8992]],\n",
       "\n",
       "         [[ 0.4711, -2.8589, -0.6459,  ..., -0.5909, -1.8948, -1.9398],\n",
       "          [ 4.0316, -1.1398, -2.5162,  ..., -0.7107, -2.2327, -0.0975],\n",
       "          [ 0.7226,  0.4636, -0.9383,  ..., -0.4190, -0.9634, -2.0021],\n",
       "          ...,\n",
       "          [ 1.3575, -0.8034, -0.6243,  ..., -1.1055, -0.3734, -1.1901],\n",
       "          [ 2.5720, -2.3744, -2.0649,  ..., -1.6059, -1.3564,  0.4414],\n",
       "          [ 2.0414, -0.3867, -1.8499,  ..., -0.4047, -0.8655, -0.2120]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5581, -1.2760,  1.3397,  ...,  0.4565,  1.1121, -0.3899],\n",
       "          [-0.7129, -0.7011, -0.4366,  ...,  0.8437,  0.8215, -1.1848],\n",
       "          [-0.4788, -1.2384,  0.4424,  ...,  1.4782, -0.6672, -1.6829],\n",
       "          ...,\n",
       "          [ 0.4257, -1.9987, -0.5864,  ...,  1.4900, -0.8646,  0.6201],\n",
       "          [ 0.1768, -1.2635, -1.8726,  ...,  0.8667,  1.0504,  0.0836],\n",
       "          [ 0.3654, -2.1724, -0.4980,  ...,  1.2231,  0.0536, -0.2105]],\n",
       "\n",
       "         [[ 1.1057, -2.4037, -0.5226,  ..., -1.6126, -0.3274,  3.7265],\n",
       "          [ 1.1943, -1.2084, -0.8787,  ..., -3.5603, -1.2168,  2.2158],\n",
       "          [ 1.8500, -2.0636, -0.2496,  ..., -1.9199, -0.2846,  2.5092],\n",
       "          ...,\n",
       "          [ 1.4574, -2.5785, -2.1364,  ..., -1.3646,  0.6816,  2.3014],\n",
       "          [ 2.0242, -1.0091, -0.4470,  ..., -2.1915,  0.3249,  1.0757],\n",
       "          [ 1.5688, -2.5334, -1.2509,  ..., -1.7337, -0.3739,  2.7893]],\n",
       "\n",
       "         [[ 0.2077, -0.2576, -1.4207,  ..., -0.7097,  0.3637,  1.3428],\n",
       "          [-0.3012, -0.7191, -0.8056,  ...,  0.4309,  0.7010,  0.7638],\n",
       "          [-2.0051, -0.5483,  0.2051,  ..., -0.0569,  0.6411,  1.8354],\n",
       "          ...,\n",
       "          [-1.7539, -0.6063, -0.8977,  ..., -0.2135,  1.6797,  1.3635],\n",
       "          [ 0.3855,  1.0766,  0.1875,  ..., -0.1488,  0.9661,  1.9746],\n",
       "          [-0.6441,  0.0972,  0.4598,  ..., -0.5564,  0.2979,  0.3092]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 3.8644e-01, -7.3645e-02,  3.0636e-02,  ...,  1.1750e-01,\n",
       "            2.8556e-02, -2.5613e-01],\n",
       "          [ 4.2130e-01,  3.0680e-01,  5.0308e-01,  ..., -6.4084e-01,\n",
       "           -4.6896e-01,  9.5399e-01],\n",
       "          [ 1.8030e-01,  1.1875e-01, -1.5521e-02,  ..., -9.2548e-02,\n",
       "           -2.8618e-03,  8.4098e-01],\n",
       "          ...,\n",
       "          [-2.9814e-01, -2.4512e-01, -4.9047e-01,  ..., -8.1631e-02,\n",
       "            6.4655e-01,  1.3697e-01],\n",
       "          [-1.0397e+00, -1.9451e+00,  1.7987e+00,  ..., -4.0413e-01,\n",
       "            2.3044e+00, -2.5512e-01],\n",
       "          [-1.3349e-01,  1.8297e-01, -1.7659e-01,  ...,  7.1262e-01,\n",
       "            2.4350e-01,  3.8124e-01]],\n",
       "\n",
       "         [[ 7.5653e-02,  1.1363e-01, -4.2587e-01,  ...,  1.1034e+00,\n",
       "            9.9408e-02,  5.6434e-01],\n",
       "          [-4.6922e-01,  1.7519e-01,  8.4952e-01,  ..., -5.6273e-02,\n",
       "            1.2562e+00,  4.6214e-01],\n",
       "          [ 5.0109e-02,  1.2960e+00,  7.4014e-01,  ...,  7.5790e-01,\n",
       "            1.0287e+00,  7.0808e-01],\n",
       "          ...,\n",
       "          [-7.2412e-01, -7.9668e-01, -9.5928e-02,  ...,  1.0456e+00,\n",
       "            2.5135e-02,  1.4899e+00],\n",
       "          [-1.4070e-01,  4.9367e-01,  1.2931e+00,  ..., -6.8170e-02,\n",
       "            1.9066e+00,  1.5023e-02],\n",
       "          [-1.4696e-01,  5.0899e-01,  5.7885e-03,  ...,  6.6114e-01,\n",
       "           -1.5230e-01,  4.7753e-01]],\n",
       "\n",
       "         [[ 1.0705e-01, -3.4597e-02, -1.6449e-01,  ...,  6.3523e-02,\n",
       "           -1.0437e-01, -3.4646e-01],\n",
       "          [ 4.0640e-01,  3.2492e-01,  6.3597e-01,  ...,  5.0404e-01,\n",
       "           -8.6164e-01, -1.0394e+00],\n",
       "          [-6.0443e-02,  5.6776e-01, -5.4446e-02,  ...,  3.6107e-01,\n",
       "           -3.9689e-01,  1.5891e-01],\n",
       "          ...,\n",
       "          [ 7.1256e-01,  4.3083e-03,  7.1651e-02,  ...,  2.6422e-01,\n",
       "           -1.4824e-01,  3.6842e-01],\n",
       "          [-4.0427e-01, -1.3261e+00,  4.0394e-01,  ...,  5.5419e-01,\n",
       "           -9.5805e-01,  1.6709e+00],\n",
       "          [ 6.3558e-01,  3.1345e-01, -2.8016e-01,  ..., -1.1536e+00,\n",
       "            6.7032e-01, -7.1407e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6521e-01, -1.5924e+00,  1.9533e+00,  ...,  1.1819e+00,\n",
       "            1.0722e-01,  5.4127e-01],\n",
       "          [-3.6728e-01,  2.1367e-02, -6.4842e-02,  ...,  7.4812e-01,\n",
       "            1.6449e-01,  7.9555e-01],\n",
       "          [-3.4558e-02,  8.7616e-03, -3.4862e-01,  ...,  7.1330e-01,\n",
       "           -4.0427e-01,  1.1446e-01],\n",
       "          ...,\n",
       "          [ 2.8526e-01,  1.9437e-01, -1.3077e+00,  ..., -9.5332e-02,\n",
       "           -7.4528e-01, -1.1593e+00],\n",
       "          [ 2.5030e-01, -4.9791e-01, -5.3826e-01,  ..., -1.3458e-01,\n",
       "            2.9354e-01,  9.9514e-02],\n",
       "          [ 4.1539e-01,  1.0878e+00, -4.7740e-01,  ..., -9.9540e-02,\n",
       "            7.2067e-01, -2.6751e-01]],\n",
       "\n",
       "         [[-3.1702e-01,  6.1072e-02,  3.9835e-01,  ..., -5.4907e-01,\n",
       "           -1.1053e-03, -4.3206e-01],\n",
       "          [ 7.7545e-01, -5.9146e-01,  6.0731e-01,  ...,  8.3819e-01,\n",
       "            1.2369e-01, -2.5940e-01],\n",
       "          [ 3.4833e-01,  2.7534e-01, -6.0496e-01,  ..., -4.7138e-01,\n",
       "            2.8923e-01,  1.4164e+00],\n",
       "          ...,\n",
       "          [-4.2124e-02,  8.0364e-02,  1.8974e-01,  ..., -4.5649e-01,\n",
       "            8.3645e-03,  2.5441e+00],\n",
       "          [-9.8280e-01, -3.1170e-01,  2.7360e-01,  ..., -6.5652e-01,\n",
       "            1.0517e-01,  8.5295e-01],\n",
       "          [-9.4565e-01, -4.7392e-01,  6.4950e-02,  ..., -1.3378e+00,\n",
       "           -4.5045e-01,  1.0676e+00]],\n",
       "\n",
       "         [[ 5.0925e-02,  1.6639e-01, -8.1169e-02,  ...,  3.2586e-02,\n",
       "           -4.3006e-01,  2.4635e-01],\n",
       "          [ 4.7229e-01, -8.6231e-01,  6.4555e-01,  ..., -2.0536e-01,\n",
       "           -2.9535e-01, -2.1713e-01],\n",
       "          [ 5.1354e-01,  1.3126e-01, -2.9181e-01,  ..., -4.4244e-01,\n",
       "            2.4366e-02,  5.8214e-01],\n",
       "          ...,\n",
       "          [-1.0244e-01,  4.0776e-01, -3.2639e-01,  ...,  5.1756e-01,\n",
       "           -2.9134e-01,  4.4414e-01],\n",
       "          [ 1.6953e+00, -7.9539e-01,  8.4647e-01,  ..., -5.1045e-01,\n",
       "            6.2547e-01, -4.2763e-01],\n",
       "          [ 2.8257e-01,  8.1107e-01, -1.9953e-01,  ..., -2.5241e-01,\n",
       "            1.8614e-01,  9.7428e-02]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 6.6739,  2.4635,  3.3297,  ...,  0.0126,  0.3472, -4.5544],\n",
       "          [ 7.3244, -0.1251,  2.9123,  ...,  0.5093, -0.2259, -6.5316],\n",
       "          [ 5.8958,  1.4279,  3.1945,  ...,  1.0813, -0.2870, -6.7599],\n",
       "          ...,\n",
       "          [ 7.2664,  1.1557,  3.6675,  ..., -1.3414, -0.6924, -5.8627],\n",
       "          [ 8.0399,  1.3366,  3.0557,  ...,  1.1390, -0.6690, -5.8110],\n",
       "          [ 7.5184,  1.7404,  3.3877,  ...,  0.3399, -0.7835, -5.6463]],\n",
       "\n",
       "         [[-1.3401, -1.9661, -1.8458,  ...,  1.4883,  2.7332,  2.7513],\n",
       "          [-1.7952, -2.3302, -3.6659,  ...,  4.9931, -1.1515,  0.9580],\n",
       "          [-2.9568, -0.8481, -1.2292,  ...,  2.5804, -1.0702,  1.3903],\n",
       "          ...,\n",
       "          [-1.5532, -1.2918, -2.5913,  ...,  1.3806, -0.0707,  0.6731],\n",
       "          [-0.8035, -1.8303,  0.0193,  ...,  1.8300,  0.0114,  0.3368],\n",
       "          [-1.2139, -1.1258, -3.8543,  ...,  0.5928, -0.1411,  0.6891]],\n",
       "\n",
       "         [[ 3.1880, -2.7843,  4.2306,  ...,  3.2270,  5.3107, -4.0030],\n",
       "          [ 2.1685, -3.6831,  4.3112,  ...,  3.6360,  5.6557, -4.9983],\n",
       "          [ 2.1796, -3.0966,  5.2842,  ...,  2.5299,  5.1815, -4.0826],\n",
       "          ...,\n",
       "          [ 1.3237, -2.6255,  4.1902,  ...,  3.6852,  6.2713, -3.5748],\n",
       "          [ 2.4704, -1.3767,  3.4837,  ...,  2.9179,  6.5940, -4.5431],\n",
       "          [ 2.4170, -2.1035,  4.2815,  ...,  3.3306,  6.2848, -3.6170]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9141, -0.2738, -1.0419,  ..., -3.0455,  3.6067,  2.4714],\n",
       "          [-2.4396,  0.2117, -3.1636,  ..., -3.6243,  2.5873,  1.8646],\n",
       "          [-2.4359,  1.0901, -0.7305,  ..., -2.4317,  2.3663,  1.8335],\n",
       "          ...,\n",
       "          [-2.4903,  0.4124, -0.3435,  ..., -4.4404,  3.3569,  1.2452],\n",
       "          [-1.3212, -0.7710, -2.2436,  ..., -4.0314,  1.8536,  3.4971],\n",
       "          [-2.0147,  1.0232,  0.5767,  ..., -3.5784,  4.3514,  1.8443]],\n",
       "\n",
       "         [[-3.7262, -2.3693,  2.3718,  ..., -1.1064, -3.7732,  0.3875],\n",
       "          [-0.7113, -2.7154,  2.0684,  ..., -1.2395,  0.6340,  0.7682],\n",
       "          [-0.3521, -2.6673,  2.0183,  ..., -1.7602, -0.4664,  0.7403],\n",
       "          ...,\n",
       "          [ 0.3354, -2.8165,  1.8990,  ..., -0.5364, -1.3925,  0.4908],\n",
       "          [ 0.7868, -2.7155,  1.7121,  ..., -0.3327, -0.6933,  0.1735],\n",
       "          [ 0.3929, -2.7499,  1.9203,  ..., -0.6045, -0.7562,  0.2344]],\n",
       "\n",
       "         [[-0.0370,  5.7874,  1.7780,  ...,  8.0827,  6.7384,  3.4312],\n",
       "          [-2.0734,  5.0321, -0.3422,  ...,  7.3962,  5.1427,  3.9297],\n",
       "          [-1.3039,  5.7972,  0.8016,  ...,  8.9874,  5.9440,  5.0521],\n",
       "          ...,\n",
       "          [-0.2025,  4.4655, -0.5756,  ...,  7.0805,  5.7512,  4.4110],\n",
       "          [-0.1769,  3.9687, -3.3628,  ...,  8.1805,  6.3226,  4.0985],\n",
       "          [-1.8970,  2.7714,  0.8802,  ...,  8.9187,  5.7220,  2.6937]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.2778,  0.0493,  0.1055,  ...,  0.1656, -0.2193, -0.4513],\n",
       "          [-0.2972,  0.1273, -0.7147,  ...,  1.1151,  1.0372,  0.0966],\n",
       "          [ 0.1226, -1.0779,  0.1446,  ..., -0.5607,  2.0888, -0.4725],\n",
       "          ...,\n",
       "          [ 0.7025,  0.7865, -0.3632,  ..., -0.5771,  1.8207, -0.7966],\n",
       "          [ 0.3718, -0.5603,  0.6274,  ...,  1.3041,  0.6703, -0.8418],\n",
       "          [-0.3390, -0.1652,  0.4209,  ..., -0.5159,  1.9957, -1.2080]],\n",
       "\n",
       "         [[ 0.2720,  0.0582, -0.4205,  ...,  0.2578,  0.1427, -0.0469],\n",
       "          [-0.4205,  0.8587,  1.1104,  ...,  0.6831,  0.4582, -0.9657],\n",
       "          [-4.0412, -2.3600, -2.5557,  ..., -1.7686, -0.6201, -3.7725],\n",
       "          ...,\n",
       "          [ 0.2503, -0.6876,  1.0566,  ..., -0.2884, -0.0092,  0.4845],\n",
       "          [-0.4393, -0.0139,  1.3599,  ..., -0.3300,  0.3682,  0.0320],\n",
       "          [ 0.2510,  0.9904, -1.0513,  ..., -0.1731,  0.6182, -0.0354]],\n",
       "\n",
       "         [[-0.0757, -0.2855, -0.2700,  ..., -0.4739,  0.3243,  0.0551],\n",
       "          [-0.2542, -0.7086,  0.7829,  ...,  0.6529, -0.3393, -0.3834],\n",
       "          [-1.0404,  0.2258, -0.3545,  ...,  0.2436, -0.1258,  0.4774],\n",
       "          ...,\n",
       "          [ 0.1932,  0.4254,  0.7182,  ...,  0.1036, -0.0954,  0.5401],\n",
       "          [-0.6315, -1.0253,  0.0082,  ...,  0.7328,  0.1533,  0.6972],\n",
       "          [-0.5077, -0.5695, -0.9481,  ...,  0.4793, -0.0064, -0.3812]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0932, -0.0601,  0.2614,  ..., -0.0756, -0.1819,  0.1038],\n",
       "          [-0.1711,  0.5123, -1.3167,  ...,  0.5361, -1.1271, -0.6362],\n",
       "          [-0.0716, -0.0048, -0.0587,  ...,  0.2353,  0.3328,  0.1435],\n",
       "          ...,\n",
       "          [ 0.0457, -0.2746,  0.4811,  ..., -0.1211,  0.3406, -0.1429],\n",
       "          [-0.8148, -0.8647, -0.4607,  ...,  1.0927,  0.1208,  0.4016],\n",
       "          [ 0.1979, -0.9679,  0.3369,  ..., -0.3693, -0.7391, -0.3340]],\n",
       "\n",
       "         [[-1.0473,  1.1516,  0.0778,  ...,  0.8068,  1.6204,  0.0378],\n",
       "          [-0.7993, -0.2746,  0.2471,  ...,  0.2510,  0.2319, -0.4471],\n",
       "          [-0.7032, -0.1325, -0.0583,  ..., -0.2154, -0.3190,  0.2359],\n",
       "          ...,\n",
       "          [-0.1714,  0.2589,  0.3810,  ...,  0.0844,  0.2864, -0.1811],\n",
       "          [-0.1250, -0.5287,  0.7424,  ...,  0.5608, -0.0342, -0.1123],\n",
       "          [ 0.0849, -0.1824,  0.2594,  ..., -0.0632,  0.6536,  0.1823]],\n",
       "\n",
       "         [[-0.0574,  0.0837, -0.2248,  ..., -0.0454,  0.0521, -0.1536],\n",
       "          [ 0.0840,  1.1055, -0.0480,  ..., -0.0676, -0.3514,  0.9745],\n",
       "          [ 0.3028,  0.0985,  0.1408,  ...,  0.7233,  0.4896, -0.3146],\n",
       "          ...,\n",
       "          [ 0.9559, -0.1325, -0.1461,  ..., -0.1387,  0.0285,  0.0146],\n",
       "          [ 1.5439,  1.3888, -0.6379,  ...,  0.1578, -0.0521,  0.0991],\n",
       "          [ 0.4723,  0.6229,  0.5375,  ..., -0.1856,  0.8193, -0.4268]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[ 5.9421e-01,  6.3685e-01,  1.9902e+00,  ...,  2.6326e+00,\n",
       "           -5.7996e-01, -2.9947e+00],\n",
       "          [ 4.8043e-01,  1.3968e-01,  9.4480e-01,  ...,  4.0679e-01,\n",
       "           -1.3149e-01, -1.9001e+00],\n",
       "          [ 3.0140e-01,  2.1928e-01,  2.0843e-01,  ...,  2.6264e-01,\n",
       "            4.1331e-03, -2.3464e+00],\n",
       "          ...,\n",
       "          [ 3.9961e-02,  7.8807e-01,  9.6550e-01,  ...,  4.3314e-01,\n",
       "           -2.2351e-01, -2.5856e+00],\n",
       "          [ 1.3711e-01, -5.6865e-02,  4.1849e-01,  ...,  4.4011e-01,\n",
       "           -2.0190e-01, -2.1557e+00],\n",
       "          [ 1.3423e-01,  4.8360e-01,  1.0472e+00,  ...,  9.9885e-01,\n",
       "           -8.3663e-01, -2.6588e+00]],\n",
       "\n",
       "         [[ 2.5997e+00,  1.3611e+00, -4.8520e+00,  ..., -2.6213e+00,\n",
       "            1.7856e+00,  5.0402e+00],\n",
       "          [ 4.1443e+00,  4.0945e-01, -4.8705e+00,  ..., -2.4665e+00,\n",
       "           -1.2158e+00,  3.9436e+00],\n",
       "          [ 3.2193e+00, -5.9700e-02, -4.6852e+00,  ..., -3.3099e+00,\n",
       "           -1.0211e+00,  5.8825e+00],\n",
       "          ...,\n",
       "          [ 4.4674e+00, -3.4225e+00, -4.9052e+00,  ..., -1.6140e+00,\n",
       "           -8.2364e-01,  5.2322e+00],\n",
       "          [ 2.5441e+00, -5.0586e+00, -3.4280e+00,  ..., -3.0804e+00,\n",
       "           -1.7095e-02,  5.7163e+00],\n",
       "          [ 3.2980e+00, -2.9500e+00, -5.2275e+00,  ..., -3.2059e+00,\n",
       "            1.8727e+00,  5.1892e+00]],\n",
       "\n",
       "         [[-4.2680e+00,  1.0921e+00,  4.2821e+00,  ...,  8.0920e-01,\n",
       "            1.0656e+00,  2.5476e+00],\n",
       "          [-5.4750e+00,  4.3789e+00, -1.2716e-01,  ..., -3.0437e+00,\n",
       "           -3.1560e+00,  4.0028e+00],\n",
       "          [-4.6821e+00,  4.4298e+00,  3.0955e-01,  ..., -5.2871e+00,\n",
       "           -4.1403e+00,  5.4038e+00],\n",
       "          ...,\n",
       "          [-3.3002e+00,  5.2714e+00, -1.8079e+00,  ..., -7.7809e+00,\n",
       "           -7.3999e+00,  2.8710e+00],\n",
       "          [-3.6418e+00,  3.3488e+00, -2.1526e+00,  ..., -9.2336e+00,\n",
       "           -7.2596e+00,  4.4912e+00],\n",
       "          [-3.2732e+00,  3.1544e+00, -9.5928e-01,  ..., -7.3510e+00,\n",
       "           -6.6869e+00,  4.9130e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.2458e+00, -1.1999e+00,  2.7327e+00,  ...,  3.6893e+00,\n",
       "            1.7029e+00,  3.9785e+00],\n",
       "          [-4.2433e+00, -1.3615e+00,  4.6010e-01,  ...,  4.0602e+00,\n",
       "            2.1074e+00,  6.7084e-01],\n",
       "          [-3.2447e+00, -6.9002e-01,  2.5696e+00,  ...,  3.2459e+00,\n",
       "            1.8266e+00,  3.4502e-02],\n",
       "          ...,\n",
       "          [-3.5605e+00, -2.0798e-01,  1.1286e+00,  ...,  2.4243e+00,\n",
       "            1.2604e+00,  5.5543e-01],\n",
       "          [-3.2464e+00,  3.7383e-02,  2.2382e+00,  ...,  4.2164e+00,\n",
       "            1.3861e+00,  2.0554e+00],\n",
       "          [-4.7685e+00, -3.5810e-01,  1.9480e+00,  ...,  1.6201e+00,\n",
       "            1.7587e+00,  2.6803e+00]],\n",
       "\n",
       "         [[ 1.1262e+01,  1.0946e+01,  1.5905e+01,  ...,  7.0141e+00,\n",
       "           -6.8601e+00,  6.2239e+00],\n",
       "          [ 1.1206e+01,  1.1540e+01,  1.5413e+01,  ...,  8.1980e+00,\n",
       "           -4.9049e+00,  5.8038e+00],\n",
       "          [ 1.1047e+01,  1.1004e+01,  1.5841e+01,  ...,  8.3275e+00,\n",
       "           -5.3385e+00,  5.5874e+00],\n",
       "          ...,\n",
       "          [ 1.0449e+01,  1.0400e+01,  1.4322e+01,  ...,  8.8797e+00,\n",
       "           -5.3683e+00,  6.3493e+00],\n",
       "          [ 1.1143e+01,  1.0102e+01,  1.3874e+01,  ...,  9.3764e+00,\n",
       "           -5.9142e+00,  6.0430e+00],\n",
       "          [ 1.1282e+01,  1.0146e+01,  1.4774e+01,  ...,  8.0576e+00,\n",
       "           -4.7966e+00,  7.2507e+00]],\n",
       "\n",
       "         [[-7.0631e+00,  1.8736e+00, -2.0791e+00,  ..., -1.4176e+00,\n",
       "            2.8940e+00,  4.0378e+00],\n",
       "          [-5.1514e+00,  5.5135e-01, -2.8188e+00,  ..., -1.6849e+00,\n",
       "            4.4847e+00,  2.2703e+00],\n",
       "          [-5.7483e+00,  6.0063e-01, -2.2455e+00,  ..., -2.3146e+00,\n",
       "            3.3127e+00,  1.7774e+00],\n",
       "          ...,\n",
       "          [-4.9688e+00, -2.5160e-01, -3.4405e+00,  ..., -1.8952e+00,\n",
       "            3.6337e+00,  1.9209e+00],\n",
       "          [-5.4364e+00, -5.2645e-01, -4.1333e+00,  ..., -1.7773e+00,\n",
       "            4.5472e+00,  2.4344e+00],\n",
       "          [-4.3130e+00, -9.8994e-01, -4.0604e+00,  ..., -2.2695e+00,\n",
       "            4.8391e+00,  2.8412e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 1.4772e-01,  2.8686e-01,  1.0540e-01,  ..., -3.3586e-02,\n",
       "            2.2573e-01,  2.5908e-01],\n",
       "          [ 2.6915e-01,  3.2660e-01, -3.7405e-01,  ...,  3.9357e-01,\n",
       "           -3.7638e-01, -2.2072e-01],\n",
       "          [-1.0068e-01,  3.0461e-01, -6.1789e-02,  ...,  2.0337e-01,\n",
       "            3.1739e-01, -3.6199e-01],\n",
       "          ...,\n",
       "          [ 4.6969e-01, -5.5017e-01, -9.2335e-01,  ...,  3.4439e-01,\n",
       "           -7.5744e-01, -1.6010e-01],\n",
       "          [ 1.3813e-01, -1.7056e-02,  5.4435e-01,  ...,  4.2905e-01,\n",
       "            7.6427e-01,  2.6879e-01],\n",
       "          [ 1.0826e-01,  1.0504e-01,  5.3112e-01,  ..., -3.5894e-01,\n",
       "            1.5021e-01, -1.4333e-01]],\n",
       "\n",
       "         [[ 1.0059e+00,  1.4502e-01,  1.6070e-01,  ...,  1.8066e-02,\n",
       "            4.9706e-02,  3.6215e-02],\n",
       "          [-1.4415e+00, -1.5731e-03, -1.0295e-01,  ..., -8.5596e-01,\n",
       "           -5.3301e-01,  9.1076e-02],\n",
       "          [ 9.3261e-01,  4.9327e-02,  1.1300e-01,  ...,  1.5559e-01,\n",
       "            1.3526e-01,  1.4924e-01],\n",
       "          ...,\n",
       "          [ 1.9636e+00,  3.4182e-01, -7.6478e-02,  ..., -2.1634e-01,\n",
       "           -3.3077e-01, -4.6771e-02],\n",
       "          [ 8.9215e-01, -3.6413e-02,  9.3401e-01,  ...,  1.8269e-01,\n",
       "           -1.7390e-01,  2.2593e-01],\n",
       "          [ 1.0533e+00,  1.4033e-01,  6.3179e-02,  ...,  4.5078e-02,\n",
       "            1.1490e-01, -4.6283e-02]],\n",
       "\n",
       "         [[ 6.6789e-02,  2.5061e-01,  2.5276e-01,  ...,  6.7347e-02,\n",
       "           -6.4112e-02, -6.6089e-02],\n",
       "          [-1.4949e-01,  2.5886e-01,  5.5233e-01,  ...,  1.4872e-01,\n",
       "           -4.0992e-02,  4.7389e-01],\n",
       "          [-7.1751e-01, -1.6475e-01, -3.2305e-01,  ..., -8.3899e-02,\n",
       "            7.5088e-03, -1.8541e-01],\n",
       "          ...,\n",
       "          [ 1.6000e-01,  3.0949e-01, -4.7604e-01,  ...,  1.1614e-01,\n",
       "           -1.7536e-02, -6.4764e-02],\n",
       "          [ 4.9808e-01,  8.8220e-01,  6.2509e-01,  ..., -4.4422e-02,\n",
       "           -2.6787e-01,  1.1371e-01],\n",
       "          [ 4.9626e-02, -2.0483e-01, -1.2345e-01,  ..., -1.3458e-01,\n",
       "           -3.5316e-01, -3.8093e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8578e-01,  1.9468e-01,  2.6356e-01,  ..., -2.7787e-01,\n",
       "           -9.7847e-02, -2.3721e-01],\n",
       "          [ 6.3614e-01, -7.0057e-01,  2.5693e-01,  ..., -3.0346e-01,\n",
       "            1.3816e+00,  7.2567e-01],\n",
       "          [ 1.5449e-01, -8.2996e-02, -2.7314e-01,  ...,  1.3354e-01,\n",
       "           -1.6816e-01,  7.4576e-01],\n",
       "          ...,\n",
       "          [-6.2931e-01, -8.0372e-01, -6.6529e-01,  ...,  8.0279e-01,\n",
       "           -6.9424e-01, -6.8043e-01],\n",
       "          [ 2.6688e-01,  4.4785e-02, -1.0395e+00,  ..., -8.0205e-01,\n",
       "           -1.1230e-01,  3.1755e-01],\n",
       "          [ 1.8372e-01, -2.5446e-01,  6.6026e-01,  ...,  2.9285e-01,\n",
       "           -2.3493e+00,  4.4585e-01]],\n",
       "\n",
       "         [[ 1.2662e-01, -8.9178e-02,  3.0091e-03,  ..., -3.8135e-02,\n",
       "           -6.9478e-02, -9.6154e-02],\n",
       "          [ 1.4213e-01, -1.1837e+00,  2.2703e-01,  ..., -1.0832e-01,\n",
       "           -1.3908e+00, -2.1368e-01],\n",
       "          [-2.2844e-02, -5.9562e-02, -1.7146e-01,  ..., -5.7462e-02,\n",
       "           -8.6551e-02,  9.5680e-02],\n",
       "          ...,\n",
       "          [ 2.7247e-02,  6.5401e-02, -8.5137e-02,  ...,  8.8980e-02,\n",
       "           -3.7283e-01, -3.7374e-01],\n",
       "          [-7.0857e-01, -4.3236e-01, -1.7433e+00,  ...,  6.2037e-01,\n",
       "           -1.2504e+00, -1.9545e-01],\n",
       "          [ 4.4222e-01, -7.6665e-02, -3.2797e-01,  ...,  3.5626e-01,\n",
       "            1.8378e-01,  8.8459e-01]],\n",
       "\n",
       "         [[ 1.3764e-01,  6.0452e-02,  3.0840e-01,  ..., -1.2319e-01,\n",
       "           -1.8042e-01, -9.0310e-02],\n",
       "          [-3.1356e-01,  9.6500e-02,  1.7672e-01,  ..., -6.0487e-01,\n",
       "           -1.3988e-01,  2.3962e-01],\n",
       "          [-8.4678e-02, -6.6886e-01, -1.0185e+00,  ...,  1.8811e+00,\n",
       "           -5.7693e-02, -1.2105e-01],\n",
       "          ...,\n",
       "          [ 1.9769e-01,  5.8560e-01,  3.8237e-01,  ...,  7.8544e-01,\n",
       "           -8.8944e-01, -1.2547e-01],\n",
       "          [ 5.6899e-01,  3.1005e-01,  4.3160e-01,  ..., -7.7554e-01,\n",
       "           -5.9929e-01, -8.5801e-01],\n",
       "          [ 3.0594e-01, -8.7553e-04, -2.4627e-01,  ..., -7.3322e-01,\n",
       "           -2.7263e-01,  2.5960e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.3576e+00,  1.9244e-01, -1.3355e-01,  ...,  1.4300e+00,\n",
       "           -1.6054e+00,  2.2648e-01],\n",
       "          [ 2.7598e+00, -1.9823e+00, -1.6681e+00,  ..., -2.6160e+00,\n",
       "           -7.3112e+00, -2.2537e+00],\n",
       "          [ 1.5638e-01,  3.9429e-01, -1.1867e+00,  ..., -1.2642e+00,\n",
       "           -4.8594e+00, -2.3045e-01],\n",
       "          ...,\n",
       "          [ 1.7563e+00,  1.7273e-01, -1.1181e-02,  ..., -2.1120e+00,\n",
       "           -6.6101e+00, -8.2530e-01],\n",
       "          [ 3.9225e+00, -6.7058e-01, -1.8496e+00,  ...,  1.6686e-01,\n",
       "           -5.0041e+00, -3.8461e-01],\n",
       "          [ 6.9385e-03,  4.3956e-01, -7.2311e-01,  ...,  9.5719e-02,\n",
       "           -4.4836e+00, -4.4426e-01]],\n",
       "\n",
       "         [[ 8.1994e-01,  4.9146e+00,  5.7374e+00,  ...,  4.0664e+00,\n",
       "           -1.8061e+00, -5.5370e-01],\n",
       "          [ 4.5390e+00,  9.8184e+00,  5.6978e+00,  ...,  1.0535e+01,\n",
       "           -2.9177e-02, -2.8151e+00],\n",
       "          [ 5.2338e+00,  1.0452e+01,  2.5788e+00,  ...,  1.0555e+01,\n",
       "            9.4936e-01, -3.8497e+00],\n",
       "          ...,\n",
       "          [ 6.9186e+00,  1.4618e+01,  1.4301e+00,  ...,  1.0993e+01,\n",
       "            2.0869e+00, -2.1028e+00],\n",
       "          [ 6.2856e+00,  1.2065e+01,  3.0019e+00,  ...,  1.1730e+01,\n",
       "            1.3241e+00, -1.9599e+00],\n",
       "          [ 4.1542e+00,  1.2321e+01,  3.9942e+00,  ...,  1.0964e+01,\n",
       "            2.6183e+00, -1.8128e-01]],\n",
       "\n",
       "         [[ 2.6470e+00,  6.5389e-01, -1.0798e-01,  ..., -6.2052e-02,\n",
       "            4.3648e+00,  5.1739e+00],\n",
       "          [ 5.2361e+00,  7.6412e-01,  1.1936e+00,  ..., -2.2670e+00,\n",
       "            4.0395e+00,  4.9230e+00],\n",
       "          [ 5.6069e+00,  1.7176e+00,  1.3419e+00,  ..., -2.9242e+00,\n",
       "            1.8383e+00,  5.5466e+00],\n",
       "          ...,\n",
       "          [ 6.4318e+00,  1.9220e+00,  1.5252e-01,  ..., -5.3973e+00,\n",
       "            8.7881e-01,  2.7245e+00],\n",
       "          [ 7.1188e+00,  1.0857e+00,  1.5721e+00,  ..., -4.9127e+00,\n",
       "            1.8868e+00,  2.5583e+00],\n",
       "          [ 5.8969e+00,  1.3531e+00,  4.5845e-01,  ..., -4.5296e+00,\n",
       "            2.9795e+00,  2.5852e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5300e-01, -4.9586e+00,  4.3570e-01,  ...,  7.5763e-01,\n",
       "            1.9043e+00, -2.0068e+00],\n",
       "          [-6.4004e-01, -3.7016e+00,  3.0330e+00,  ...,  5.2975e+00,\n",
       "            4.2020e+00, -5.3437e+00],\n",
       "          [-1.6257e-01, -4.8290e+00,  1.9211e+00,  ...,  3.2918e+00,\n",
       "            3.2585e+00, -3.8899e+00],\n",
       "          ...,\n",
       "          [-7.4189e-01, -3.4544e+00,  5.6609e+00,  ...,  4.5681e+00,\n",
       "            2.7140e+00, -4.1864e+00],\n",
       "          [-8.9835e-01, -4.9647e+00,  6.8241e+00,  ...,  5.7432e+00,\n",
       "            2.8360e+00, -4.0716e+00],\n",
       "          [-6.1232e-01, -4.7287e+00,  5.5202e+00,  ...,  4.4112e+00,\n",
       "            1.4855e+00, -2.1553e+00]],\n",
       "\n",
       "         [[-2.1107e-02, -1.1095e-01,  1.1861e+00,  ...,  1.1901e+00,\n",
       "           -1.0722e+00,  6.6906e-01],\n",
       "          [-5.7011e+00,  3.3192e+00,  1.6583e+00,  ..., -2.0246e+00,\n",
       "           -2.8897e+00,  4.4701e+00],\n",
       "          [-8.7649e-01,  1.2176e+00,  2.1698e+00,  ...,  2.7264e+00,\n",
       "           -2.3322e+00,  1.7567e+00],\n",
       "          ...,\n",
       "          [ 3.3747e-01,  1.0275e-01,  1.5981e+00,  ...,  1.2722e+00,\n",
       "           -2.3618e+00,  1.5149e+00],\n",
       "          [-3.7621e+00,  3.2921e+00,  2.6659e-01,  ...,  1.1483e+00,\n",
       "           -3.1722e+00,  4.8848e-01],\n",
       "          [-1.0653e+00,  6.2558e-01,  1.6825e+00,  ...,  1.3208e+00,\n",
       "           -1.7081e+00,  1.4666e+00]],\n",
       "\n",
       "         [[ 2.1508e+00, -3.4064e+00, -6.2933e-01,  ...,  2.7016e+00,\n",
       "            3.8477e+00,  2.5652e+00],\n",
       "          [ 6.0842e+00, -6.3622e+00, -3.3072e+00,  ...,  1.4321e+00,\n",
       "            6.7471e+00,  8.4550e+00],\n",
       "          [ 4.9037e+00, -6.5931e+00, -2.9396e+00,  ...,  1.7950e+00,\n",
       "            7.4534e+00,  9.4313e+00],\n",
       "          ...,\n",
       "          [ 6.4065e+00, -1.0568e+01, -6.4769e-01,  ...,  2.4292e+00,\n",
       "            5.5699e+00,  8.0195e+00],\n",
       "          [ 5.5559e+00, -8.2084e+00, -2.7855e+00,  ...,  2.0299e+00,\n",
       "            6.1733e+00,  8.6350e+00],\n",
       "          [ 5.4838e+00, -8.4183e+00, -1.7803e+00,  ...,  2.3404e+00,\n",
       "            6.3353e+00,  7.1106e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 9.2988e-02,  2.2797e-01, -1.6698e-02,  ..., -1.7250e-01,\n",
       "            1.0772e-01,  1.2396e-01],\n",
       "          [-1.0750e+00,  7.6244e-01, -1.4734e-01,  ..., -4.3770e-01,\n",
       "           -7.8798e-02, -1.4679e-01],\n",
       "          [ 2.0693e-01,  1.8534e-02, -4.8784e-02,  ..., -3.1521e-01,\n",
       "           -5.4683e-01,  3.7903e-01],\n",
       "          ...,\n",
       "          [-1.9779e-01,  2.6205e-01, -3.3519e-01,  ...,  4.0054e-01,\n",
       "            5.2470e-01,  2.7739e-01],\n",
       "          [-6.7007e-02,  1.1857e+00,  6.0165e-01,  ..., -5.0060e-01,\n",
       "           -7.4485e-02, -5.0454e-01],\n",
       "          [ 2.8102e-01,  3.5573e-01,  7.3257e-02,  ..., -4.6790e-02,\n",
       "           -4.4286e-02,  4.8753e-01]],\n",
       "\n",
       "         [[-2.7552e-01, -1.8836e-02, -2.3410e-01,  ..., -1.2092e-01,\n",
       "            1.9004e-01,  1.8750e-01],\n",
       "          [-2.1481e-02,  1.4510e-01, -9.8190e-02,  ...,  3.6907e-01,\n",
       "            1.4498e-01,  8.2738e-02],\n",
       "          [-1.8982e-01,  3.4879e-01, -2.1811e-01,  ..., -2.3233e-01,\n",
       "            1.2738e+00, -2.5564e-01],\n",
       "          ...,\n",
       "          [ 5.0412e-01,  2.0814e-01,  4.3060e-01,  ...,  1.6609e-01,\n",
       "            7.6202e-01, -1.6285e-01],\n",
       "          [-1.6412e-01,  6.0347e-01,  2.9437e-01,  ...,  2.5014e-01,\n",
       "            6.4791e-01, -5.0905e-02],\n",
       "          [-1.5602e-01,  3.6927e-01,  9.2941e-03,  ...,  2.1974e-01,\n",
       "            9.9064e-01, -2.3317e-01]],\n",
       "\n",
       "         [[-1.3793e-02,  2.6505e-01,  6.0013e-02,  ..., -8.7802e-02,\n",
       "           -2.0856e-01, -2.1040e-01],\n",
       "          [ 8.3399e-02, -6.7321e-01, -1.5439e-01,  ..., -7.2480e-01,\n",
       "           -8.6873e-03, -1.1895e-01],\n",
       "          [-8.7474e-01,  5.5460e-01, -3.3509e-01,  ..., -1.3031e-01,\n",
       "           -6.0027e-01, -5.1093e-01],\n",
       "          ...,\n",
       "          [-2.1691e-01, -2.8189e-01, -9.6641e-01,  ..., -2.7458e-01,\n",
       "           -6.5166e-02,  6.7217e-01],\n",
       "          [ 1.7237e-01, -2.8507e-01,  3.8569e-01,  ..., -2.6792e-02,\n",
       "            2.6501e-02,  2.7343e-01],\n",
       "          [ 1.2999e-01, -5.9593e-01, -2.9067e-01,  ..., -1.0525e-01,\n",
       "           -5.2521e-01, -4.5284e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4629e-02, -9.0977e-02,  2.4651e-02,  ..., -5.1333e-02,\n",
       "           -1.3229e-01,  7.6851e-02],\n",
       "          [-5.2482e-01, -4.7135e-01, -3.0569e-01,  ...,  3.4476e-01,\n",
       "            3.6689e-01, -7.5131e-02],\n",
       "          [ 1.3531e-03, -2.5919e-01,  2.6870e-01,  ..., -2.0635e-01,\n",
       "            3.5631e-01,  1.2292e-01],\n",
       "          ...,\n",
       "          [-1.2783e-01, -1.8620e-01,  3.6399e-01,  ..., -5.0921e-01,\n",
       "           -1.8142e-01, -2.6564e-01],\n",
       "          [-3.9670e-01, -3.8418e-02, -1.2717e-01,  ..., -1.7099e-01,\n",
       "           -7.6992e-01, -6.3694e-01],\n",
       "          [-2.6121e-01,  4.4625e-01, -1.5286e-01,  ...,  5.6131e-02,\n",
       "            2.0355e-01, -3.4772e-01]],\n",
       "\n",
       "         [[-5.7194e-03, -7.9253e-02,  2.2620e-01,  ..., -1.1749e-01,\n",
       "            5.6124e-02,  1.5009e+00],\n",
       "          [-6.2133e-01, -6.0344e-01, -5.3071e-01,  ...,  6.4258e-02,\n",
       "            2.1580e-01, -1.2080e+00],\n",
       "          [-1.7073e-01, -1.4936e-02,  1.5331e-01,  ...,  2.1158e-01,\n",
       "            6.9714e-02,  1.2061e+00],\n",
       "          ...,\n",
       "          [-1.9856e-01,  5.4572e-01, -1.0523e-01,  ...,  5.3811e-01,\n",
       "            5.3661e-01,  1.4242e+00],\n",
       "          [-6.5142e-01, -4.8874e-01, -1.0703e+00,  ...,  4.4068e-01,\n",
       "            8.9300e-02,  1.6167e-01],\n",
       "          [ 1.4484e-01,  9.9617e-03,  4.0910e-02,  ...,  1.4754e-01,\n",
       "           -9.6937e-02,  2.1275e+00]],\n",
       "\n",
       "         [[-3.9015e-02,  2.0331e-01, -1.6882e-02,  ...,  1.2671e-01,\n",
       "            1.0746e-01, -1.0979e-01],\n",
       "          [-1.6978e-01,  5.8945e-01,  2.5679e-01,  ...,  6.3498e-01,\n",
       "            2.0955e-01, -3.2298e-01],\n",
       "          [ 2.8159e-02,  2.9444e-02,  3.3036e-01,  ..., -4.5798e-01,\n",
       "           -1.0586e-01,  5.0038e-02],\n",
       "          ...,\n",
       "          [ 8.9135e-01, -6.3754e-01, -7.9391e-01,  ..., -2.5991e-01,\n",
       "           -6.4584e-01,  4.9921e-01],\n",
       "          [-3.3338e-01,  8.8571e-01,  4.4749e-02,  ...,  3.2511e-01,\n",
       "            9.5897e-02,  2.2813e-01],\n",
       "          [-7.1631e-02,  8.6530e-01,  3.2930e-01,  ..., -1.1843e-01,\n",
       "            1.8816e-01,  4.2969e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.1638e+00, -1.2716e+00,  2.0389e+00,  ...,  3.6198e-01,\n",
       "            1.2357e+00, -1.7090e+00],\n",
       "          [ 6.2880e-01,  1.0394e+00, -2.9107e-01,  ...,  6.0543e-02,\n",
       "            1.1274e+00,  4.1704e-01],\n",
       "          [ 1.5940e+00,  1.1989e+00, -1.3813e+00,  ...,  1.1611e+00,\n",
       "            1.1243e+00, -7.1745e-01],\n",
       "          ...,\n",
       "          [ 3.8033e+00,  2.2055e-01, -1.6952e+00,  ..., -3.3595e+00,\n",
       "           -1.8212e+00, -1.7086e+00],\n",
       "          [ 4.5220e+00, -1.2095e+00, -1.9478e+00,  ..., -8.5817e-01,\n",
       "           -2.1872e+00, -2.4688e-03],\n",
       "          [ 5.3687e+00, -6.3861e-01, -1.0295e+00,  ..., -2.0805e-01,\n",
       "           -1.7154e+00, -1.3063e+00]],\n",
       "\n",
       "         [[-2.1435e+00,  2.5321e-01, -2.4926e+00,  ..., -6.3080e-01,\n",
       "            4.8704e-01,  3.9457e+00],\n",
       "          [ 6.0276e+00,  3.4745e+00, -4.4074e+00,  ...,  1.4107e+00,\n",
       "           -9.4300e-01,  3.1365e+00],\n",
       "          [ 4.2280e+00,  3.7003e+00, -4.4822e+00,  ...,  2.1089e+00,\n",
       "            3.0357e-01,  2.4195e+00],\n",
       "          ...,\n",
       "          [ 5.1244e+00,  3.5651e+00, -4.8706e+00,  ...,  2.5678e+00,\n",
       "            3.0089e+00,  3.7941e-01],\n",
       "          [ 4.0750e+00,  3.6582e+00, -1.6195e+00,  ...,  4.4691e-01,\n",
       "            3.1110e+00, -1.2414e+00],\n",
       "          [ 4.6774e+00,  3.1050e+00, -2.5084e+00,  ...,  9.0162e-01,\n",
       "            3.0472e+00, -1.5166e+00]],\n",
       "\n",
       "         [[ 8.5481e-01,  2.9826e+00, -4.9277e-01,  ..., -1.4852e+00,\n",
       "            7.8318e-01,  1.7335e+00],\n",
       "          [ 2.4914e-01,  1.7249e+00, -1.6519e+00,  ..., -4.1218e-01,\n",
       "            2.8799e+00,  3.1425e+00],\n",
       "          [ 3.3229e-01,  1.6816e+00, -2.2846e+00,  ..., -1.7820e+00,\n",
       "            2.5706e+00,  2.0222e+00],\n",
       "          ...,\n",
       "          [ 1.3174e+00,  2.3530e+00, -1.4563e+00,  ..., -1.4093e+00,\n",
       "            3.6058e+00,  3.0382e+00],\n",
       "          [ 8.0775e-01,  6.0184e-01, -2.4055e+00,  ..., -9.7304e-02,\n",
       "            2.2791e+00,  2.7303e+00],\n",
       "          [ 1.2096e-01,  1.2357e+00, -1.1438e+00,  ..., -1.1652e+00,\n",
       "            1.3168e+00,  1.7442e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7119e+00, -1.9464e+00, -1.7124e+00,  ..., -1.4207e+00,\n",
       "           -2.4506e+00,  1.7133e+00],\n",
       "          [-1.9413e+00,  2.6487e+00, -4.5078e+00,  ..., -1.3407e+00,\n",
       "           -3.6070e+00,  2.6177e+00],\n",
       "          [ 2.7814e-01,  3.9441e+00, -4.2048e+00,  ..., -1.0286e+00,\n",
       "           -2.1804e+00,  4.0955e+00],\n",
       "          ...,\n",
       "          [ 1.6854e-02,  3.9619e+00, -2.2770e+00,  ..., -1.7368e-01,\n",
       "           -7.2618e-01,  3.9382e+00],\n",
       "          [ 8.6723e-01,  5.1645e+00, -3.4606e-01,  ..., -4.3463e-01,\n",
       "           -2.8535e+00,  2.2072e+00],\n",
       "          [ 1.3177e+00,  3.6831e+00, -4.3897e-01,  ..., -3.2244e-01,\n",
       "           -7.9153e-01,  1.9979e+00]],\n",
       "\n",
       "         [[-9.2036e-01,  1.2584e+00, -1.4160e+00,  ..., -2.5580e+00,\n",
       "           -1.1946e+00,  1.0026e+00],\n",
       "          [ 1.1922e+00,  3.0202e+00, -2.1918e-01,  ..., -1.9796e+00,\n",
       "            6.0427e-01,  1.1197e+00],\n",
       "          [ 6.5260e-01,  2.9134e+00, -1.4832e-01,  ..., -2.2683e+00,\n",
       "            1.2251e-02, -2.1085e-01],\n",
       "          ...,\n",
       "          [-2.4418e+00,  5.8111e+00,  5.9756e-01,  ..., -3.2361e+00,\n",
       "            2.3783e+00,  1.3471e+00],\n",
       "          [ 4.0323e-01,  4.6647e+00,  2.7318e-01,  ..., -2.3037e+00,\n",
       "            2.2551e+00, -2.5207e-01],\n",
       "          [-1.1922e+00,  5.1249e+00,  8.5260e-04,  ..., -3.7968e+00,\n",
       "            2.0748e+00,  8.2458e-02]],\n",
       "\n",
       "         [[ 2.8132e+00,  4.2111e+00,  3.6727e+00,  ..., -8.8936e-01,\n",
       "           -1.9275e+00,  1.6589e-02],\n",
       "          [ 8.7180e-01, -4.7890e-01,  4.0863e-01,  ..., -2.8029e+00,\n",
       "           -3.4519e+00,  8.8035e-01],\n",
       "          [-2.8814e+00, -1.3988e+00, -5.9154e-02,  ..., -3.0752e+00,\n",
       "           -3.1408e+00,  1.2079e+00],\n",
       "          ...,\n",
       "          [-4.5762e+00, -5.0718e-02, -9.9883e-01,  ..., -4.8835e+00,\n",
       "           -6.6631e+00,  1.0170e-01],\n",
       "          [-1.6734e+00,  2.7429e+00,  4.0305e-01,  ..., -3.4723e+00,\n",
       "           -6.1500e+00,  2.8028e-01],\n",
       "          [-3.4775e+00,  2.4605e+00,  9.3513e-01,  ..., -3.7337e+00,\n",
       "           -5.5139e+00,  1.9155e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 0.0451,  0.0440, -0.1482,  ...,  0.1467, -0.0395,  0.1334],\n",
       "          [-0.3732,  0.3430,  0.2341,  ...,  0.4997, -0.4515, -0.3769],\n",
       "          [-0.3538,  0.2594, -0.3504,  ...,  0.2562, -0.5941,  0.3240],\n",
       "          ...,\n",
       "          [-0.5723,  0.1570,  0.5866,  ..., -0.0020,  0.0668,  0.3426],\n",
       "          [-0.0073, -0.0425,  0.1801,  ..., -0.2694,  0.1594,  0.0509],\n",
       "          [ 0.4475, -0.3528, -0.1821,  ...,  0.0066,  0.2674, -0.0051]],\n",
       "\n",
       "         [[ 0.0686,  0.0599,  0.0245,  ...,  0.0112,  0.0963,  0.0178],\n",
       "          [-0.5401, -0.0786,  0.2272,  ...,  0.7410, -0.0917, -0.2143],\n",
       "          [ 0.1582,  0.2990,  0.3345,  ..., -0.0426,  0.0523, -0.0288],\n",
       "          ...,\n",
       "          [-0.0392,  0.2767,  0.9971,  ..., -0.7587,  0.0244,  0.8976],\n",
       "          [ 0.0718,  0.2267, -0.2734,  ...,  0.5517,  0.2220, -0.2777],\n",
       "          [ 0.0018,  0.0291,  0.3776,  ...,  0.0440,  0.3184, -0.2532]],\n",
       "\n",
       "         [[ 0.1458,  0.0261, -0.1387,  ...,  0.0883,  0.0195, -0.0268],\n",
       "          [-1.0945, -0.7312,  0.7015,  ...,  0.3120,  1.0567,  0.7958],\n",
       "          [ 0.3488, -0.3940,  0.1334,  ...,  0.4864, -0.2155, -0.2769],\n",
       "          ...,\n",
       "          [ 0.2880, -0.4717,  0.0888,  ...,  0.0946, -0.6347,  0.0447],\n",
       "          [-0.0989, -0.7629,  0.5492,  ..., -0.6656,  0.6488, -0.6146],\n",
       "          [ 0.4331,  0.5534, -0.2789,  ...,  0.1378,  0.4018, -0.3405]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0611,  0.3126, -0.0457,  ..., -0.0795,  0.1263,  0.1575],\n",
       "          [ 0.2951, -0.4733,  0.3565,  ..., -0.1441,  0.1573, -0.0085],\n",
       "          [ 1.0116, -0.1335, -0.5849,  ...,  0.7869,  0.0153,  0.2813],\n",
       "          ...,\n",
       "          [-0.2183, -0.2203,  0.6672,  ...,  1.0717,  0.1376,  0.4700],\n",
       "          [ 0.8649, -0.2516,  0.0810,  ..., -0.0120,  0.1261,  0.0348],\n",
       "          [ 0.2642, -0.1245, -0.0886,  ...,  0.4154,  0.2167,  0.8339]],\n",
       "\n",
       "         [[ 0.0155,  0.0593, -0.0275,  ...,  0.0281,  0.0252,  0.1127],\n",
       "          [ 0.0558,  0.7358, -0.5879,  ..., -0.7227,  0.3405, -0.6235],\n",
       "          [ 0.4749, -0.1900, -0.4050,  ...,  0.0145, -0.1275,  0.3852],\n",
       "          ...,\n",
       "          [-0.7306, -0.3424,  0.4745,  ..., -0.1677, -0.2557,  0.3741],\n",
       "          [-0.0790,  0.3139,  0.4371,  ...,  0.0451, -0.2700,  0.4781],\n",
       "          [-0.2666, -0.3319,  0.1653,  ..., -0.3297,  0.2580,  0.1514]],\n",
       "\n",
       "         [[ 0.0473,  0.0053,  0.0397,  ..., -0.0356,  0.0052, -0.0222],\n",
       "          [ 0.2879,  0.8327, -0.4752,  ...,  0.6763,  0.0171, -0.1384],\n",
       "          [-0.2826, -0.1022, -0.2649,  ..., -0.4144,  0.3359, -0.1592],\n",
       "          ...,\n",
       "          [-0.2219,  0.0384,  0.0159,  ..., -0.3347, -0.1987,  0.0608],\n",
       "          [-0.6066, -0.1514,  0.0375,  ..., -0.0662,  0.5449, -0.5647],\n",
       "          [ 0.3301,  0.2082,  0.0848,  ..., -0.0847, -0.0247,  0.1917]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[-0.5066,  1.0326, -0.1479,  ..., -1.0469,  0.5469,  0.7771],\n",
       "          [ 1.7304, -0.7024, -1.1355,  ..., -1.5611, -0.2827, -0.2150],\n",
       "          [ 0.8589, -0.1637, -0.1721,  ..., -0.6831, -1.0582,  0.6353],\n",
       "          ...,\n",
       "          [ 0.7291,  1.8569, -2.0179,  ...,  0.3719,  1.2270, -1.9977],\n",
       "          [ 2.1715,  1.8580, -2.8857,  ..., -0.0796, -0.1616, -2.0091],\n",
       "          [ 1.5251, -0.0364, -1.2219,  ..., -0.8143, -0.4066, -0.5502]],\n",
       "\n",
       "         [[-0.1609,  2.5331,  1.4223,  ..., -3.0982,  0.6860,  2.5895],\n",
       "          [-3.4755,  3.8347, -2.8630,  ..., -0.0100, -0.8879,  3.5235],\n",
       "          [-3.2847,  2.7595, -4.3657,  ...,  0.1222, -1.3623,  3.4848],\n",
       "          ...,\n",
       "          [-2.6102,  0.2099, -3.2819,  ..., -0.4256,  1.2256,  0.3120],\n",
       "          [-3.1355,  1.1009, -3.5102,  ...,  0.7822,  0.0219,  0.6368],\n",
       "          [-1.4876, -0.6735, -2.6018,  ...,  0.5838, -0.8328,  0.0353]],\n",
       "\n",
       "         [[ 2.4886, -2.4384, -2.6314,  ...,  1.7192, -1.2662,  0.7335],\n",
       "          [-0.4173,  5.6497,  2.4878,  ...,  1.0822,  3.7090, -3.6008],\n",
       "          [-0.1541,  3.4928,  0.8615,  ..., -0.3623,  1.4628, -0.5250],\n",
       "          ...,\n",
       "          [-0.4446,  6.1704, -0.4862,  ..., -0.8356,  2.5281, -1.5015],\n",
       "          [-3.0161,  6.0344,  1.3204,  ..., -0.6702,  2.3319, -2.4910],\n",
       "          [-2.5392,  2.9576,  1.5891,  ..., -3.5607,  1.9109, -0.4931]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8759, -3.3464, -2.9740,  ...,  2.9935, -2.3181,  1.0846],\n",
       "          [-2.1262,  1.0526, -0.6999,  ...,  2.0783, -3.2655,  1.9641],\n",
       "          [-0.3054,  3.2472, -2.1600,  ...,  1.2734, -4.2128,  2.2281],\n",
       "          ...,\n",
       "          [ 2.4006,  4.0640,  2.2070,  ..., -0.5117, -2.5379,  2.6061],\n",
       "          [ 2.1860,  2.9505,  0.9963,  ...,  0.4688, -1.3478,  0.6525],\n",
       "          [ 3.9404,  2.3197,  0.3630,  ...,  0.0236, -2.2307,  1.2780]],\n",
       "\n",
       "         [[ 1.4228,  1.2669,  0.2790,  ..., -1.8236,  0.7051, -0.3585],\n",
       "          [ 1.9377,  4.1205,  0.6092,  ...,  0.6080, -0.7598,  1.4338],\n",
       "          [ 1.3025,  1.4187,  1.1896,  ..., -1.6748,  1.7730,  0.8234],\n",
       "          ...,\n",
       "          [ 1.2136,  1.1473,  1.2372,  ...,  0.1917,  1.4177,  0.1871],\n",
       "          [ 0.9871,  0.2473,  1.4439,  ..., -1.1754,  1.2430, -0.3122],\n",
       "          [ 2.2114,  2.1039,  1.9990,  ...,  0.4176,  1.2510,  1.9525]],\n",
       "\n",
       "         [[-2.4118, -2.2244,  1.2773,  ...,  0.9303,  2.1639,  1.3551],\n",
       "          [ 3.6385, -0.0714, -5.4642,  ..., -2.4041, -0.7410,  5.2959],\n",
       "          [ 4.2130,  4.2296, -7.4085,  ..., -2.0241,  3.3226,  6.6538],\n",
       "          ...,\n",
       "          [ 3.5604,  4.7467, -8.1957,  ..., -3.9444, -3.9534, -1.7799],\n",
       "          [ 4.7151,  4.8232, -6.4434,  ..., -7.0326, -1.6380, -1.4743],\n",
       "          [ 4.2090,  5.0740, -1.1189,  ..., -2.9701, -1.3850, -4.9835]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 4.5830e-02, -3.1325e-04, -8.9678e-02,  ...,  1.0699e-02,\n",
       "           -5.3167e-02,  2.0576e-02],\n",
       "          [ 1.2748e-01, -7.3498e-01, -1.3829e-01,  ..., -4.6683e-01,\n",
       "            7.5591e-01, -5.0420e-01],\n",
       "          [ 4.6570e-01, -4.0435e-01, -7.1585e-01,  ..., -2.1045e-01,\n",
       "            7.1988e-01, -8.9948e-01],\n",
       "          ...,\n",
       "          [-1.7965e-01, -5.9870e-01, -4.4868e-01,  ..., -3.5864e-01,\n",
       "           -4.9987e-01, -1.1531e-03],\n",
       "          [-6.2202e-01, -4.1449e-01, -4.6006e-01,  ...,  5.8013e-01,\n",
       "            7.9518e-01,  1.5925e-01],\n",
       "          [ 7.2563e-01,  6.6932e-01, -1.4246e+00,  ..., -4.8653e-01,\n",
       "           -6.7166e-01,  9.7652e-02]],\n",
       "\n",
       "         [[-4.9913e-02, -1.1128e-01, -1.4799e-01,  ..., -9.1787e-02,\n",
       "            9.4453e-03,  1.6199e-02],\n",
       "          [ 4.1417e-01,  7.0329e-01,  4.1765e-01,  ...,  3.1520e-01,\n",
       "            7.4186e-01, -7.5154e-01],\n",
       "          [ 4.1337e-01, -1.2480e-01,  5.4813e-01,  ...,  2.0132e-01,\n",
       "           -5.6682e-01, -5.1580e-01],\n",
       "          ...,\n",
       "          [-4.5624e-02, -6.6009e-01,  6.6838e-03,  ...,  3.7132e-01,\n",
       "            1.2500e-01, -5.0182e-01],\n",
       "          [ 2.0770e-01, -3.3323e-01, -6.3370e-01,  ...,  6.4716e-02,\n",
       "            1.3532e-04, -3.4249e-01],\n",
       "          [-2.5183e-01, -6.4836e-01, -3.8939e-01,  ...,  4.1261e-02,\n",
       "            6.5810e-02,  5.6339e-01]],\n",
       "\n",
       "         [[ 6.3827e-02,  4.9751e-03,  2.6441e-03,  ..., -6.2008e-02,\n",
       "            7.8930e-02,  6.3015e-02],\n",
       "          [ 4.1618e-01,  1.2199e-01, -2.0202e-01,  ...,  4.7133e-01,\n",
       "            4.9450e-01,  6.0228e-01],\n",
       "          [ 1.0271e+00, -1.1229e+00, -7.4033e-02,  ..., -1.1097e+00,\n",
       "           -6.1066e-01, -5.9581e-01],\n",
       "          ...,\n",
       "          [-1.5259e-01, -2.9692e-01, -4.3982e-01,  ..., -4.6482e-01,\n",
       "           -5.0765e-01, -1.5665e-01],\n",
       "          [-4.5715e-01,  1.3353e-02,  4.3838e-01,  ..., -6.8975e-02,\n",
       "            4.6799e-01,  2.3803e-01],\n",
       "          [ 4.6689e-03, -1.8310e-01, -2.0016e-01,  ...,  1.0325e+00,\n",
       "           -2.1367e-01,  1.2942e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.5568e-03,  1.7426e-02,  8.7219e-02,  ..., -2.2173e-02,\n",
       "           -1.4829e-02, -4.9174e-02],\n",
       "          [-2.4684e-01,  1.2997e-01,  2.3710e-01,  ..., -2.5159e-01,\n",
       "            6.5800e-01, -4.0071e-01],\n",
       "          [-1.1316e+00,  3.3396e-02,  2.5053e-01,  ...,  2.6832e-01,\n",
       "           -5.8924e-01,  8.9185e-01],\n",
       "          ...,\n",
       "          [ 6.7104e-01, -1.2440e-01,  2.6212e-01,  ...,  3.0258e-01,\n",
       "            8.5179e-01, -1.3184e+00],\n",
       "          [ 5.6378e-01,  2.7589e-01,  5.1234e-01,  ..., -3.7196e-01,\n",
       "           -1.6730e-01, -6.0641e-03],\n",
       "          [ 2.6967e-01,  1.3391e-02, -1.9039e-01,  ...,  6.3394e-01,\n",
       "           -3.9038e-01, -2.3744e-01]],\n",
       "\n",
       "         [[-1.0020e-02,  1.0664e-02, -1.2269e-03,  ...,  3.7406e-02,\n",
       "            4.5519e-02, -4.0216e-02],\n",
       "          [-4.4051e-02,  1.4562e-01, -9.4358e-01,  ...,  7.9183e-02,\n",
       "           -6.5592e-01, -1.1771e-01],\n",
       "          [ 3.3124e-02, -5.5230e-01,  3.2673e-01,  ...,  1.7672e-01,\n",
       "           -2.8970e-01,  5.1941e-01],\n",
       "          ...,\n",
       "          [ 3.8435e-01,  2.0538e-03,  1.1443e-01,  ..., -3.8690e-02,\n",
       "           -1.4378e-01,  2.5690e-02],\n",
       "          [-1.0642e-01,  1.6683e-01, -1.3973e+00,  ..., -1.5863e+00,\n",
       "           -9.1751e-03, -1.2904e+00],\n",
       "          [ 7.7306e-01, -3.8870e-01, -3.6052e-01,  ..., -4.2982e-01,\n",
       "           -2.5231e-01, -1.1484e+00]],\n",
       "\n",
       "         [[-1.5841e-03,  7.4031e-02, -1.2651e-01,  ..., -1.4397e-01,\n",
       "            3.8472e-02,  8.2393e-02],\n",
       "          [ 7.5196e-01, -1.1544e+00, -4.0074e-01,  ..., -6.0930e-01,\n",
       "           -3.0520e-01, -1.9007e+00],\n",
       "          [ 8.5038e-01, -5.5010e-01, -9.2648e-01,  ..., -1.3386e-01,\n",
       "           -1.7937e-01, -3.5653e-01],\n",
       "          ...,\n",
       "          [-1.9970e-02, -2.5868e-01, -7.9598e-01,  ..., -6.8751e-01,\n",
       "           -2.0933e-02, -1.1767e+00],\n",
       "          [-2.5955e-01, -5.3724e-01, -7.0562e-01,  ..., -2.1274e-01,\n",
       "           -4.4577e-01, -9.8641e-01],\n",
       "          [ 3.2025e-01, -6.5030e-01, -2.8698e-01,  ...,  1.2119e-01,\n",
       "           -6.9572e-01, -1.4597e+00]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-2.4429e-01, -3.7187e-01,  3.0031e-01,  ..., -2.6041e-01,\n",
       "           -2.2911e-01,  1.1072e-01],\n",
       "          [ 1.0626e+00, -6.7137e-01, -2.7228e-01,  ..., -2.1417e+00,\n",
       "            5.7870e+00,  1.0475e+00],\n",
       "          [-4.1510e-01, -1.6333e+00, -1.0085e+00,  ...,  1.2615e-01,\n",
       "            5.4548e+00,  2.2781e+00],\n",
       "          ...,\n",
       "          [ 7.8392e-02, -9.1922e-01, -5.4366e-01,  ...,  3.6791e-01,\n",
       "            5.9136e+00,  2.9782e+00],\n",
       "          [-1.7115e+00, -1.2672e+00, -6.7359e-01,  ...,  1.3536e+00,\n",
       "            6.5819e+00,  2.7493e+00],\n",
       "          [-4.8476e-01, -3.8238e-01,  4.3281e-01,  ...,  1.2278e-02,\n",
       "            5.5665e+00,  2.3775e+00]],\n",
       "\n",
       "         [[ 1.8872e+00,  4.5456e-01, -6.0834e-02,  ..., -9.5449e-01,\n",
       "           -1.3249e-01, -7.3890e-01],\n",
       "          [-8.4686e+00,  2.9687e+00,  9.3444e-01,  ..., -8.8711e-01,\n",
       "           -4.4666e-01, -5.2254e-01],\n",
       "          [-9.1725e+00,  1.0328e+00, -9.6033e-01,  ...,  1.2104e+00,\n",
       "           -1.4412e+00, -1.3354e-01],\n",
       "          ...,\n",
       "          [-9.9798e+00,  1.7171e+00, -1.5484e+00,  ..., -1.3790e+00,\n",
       "            3.3174e-01,  6.1811e-01],\n",
       "          [-1.0501e+01,  3.1057e+00, -1.4713e+00,  ..., -2.6061e+00,\n",
       "            7.0517e-01,  9.4193e-02],\n",
       "          [-1.0166e+01,  1.8243e+00,  8.8762e-01,  ..., -2.7621e+00,\n",
       "            9.5692e-01,  2.6171e-01]],\n",
       "\n",
       "         [[ 4.6280e-02, -7.0185e-01,  1.0022e+00,  ..., -5.2133e+00,\n",
       "            1.7165e+00,  2.9285e-01],\n",
       "          [ 1.3377e+00, -6.8131e-01,  1.8280e+00,  ...,  1.0717e+01,\n",
       "            3.1219e-02,  4.1371e+00],\n",
       "          [ 1.3127e+00, -1.7430e+00,  1.3523e+00,  ...,  1.3146e+01,\n",
       "            1.4221e+00,  3.6930e+00],\n",
       "          ...,\n",
       "          [ 1.3324e+00, -1.5797e+00,  2.3141e+00,  ...,  1.3707e+01,\n",
       "           -2.4810e+00,  2.8621e+00],\n",
       "          [-2.9126e-01, -1.7141e+00,  1.9236e+00,  ...,  1.3220e+01,\n",
       "           -1.5008e+00,  2.3560e+00],\n",
       "          [ 2.0102e-01, -1.9692e+00,  2.3575e+00,  ...,  1.2783e+01,\n",
       "           -4.0048e-01,  2.8200e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0172e-01,  9.0430e-01,  3.4237e-01,  ...,  5.1380e-03,\n",
       "            1.9560e+00,  1.3770e-02],\n",
       "          [-8.5449e-01, -9.9591e-01,  6.3884e-01,  ...,  8.4060e-01,\n",
       "           -3.1619e+00, -6.0490e-01],\n",
       "          [-7.3119e-01,  9.4241e-02, -2.0843e+00,  ...,  2.5633e+00,\n",
       "           -4.3007e+00, -4.5710e-01],\n",
       "          ...,\n",
       "          [-7.0284e-01, -3.0721e-01,  8.3281e-01,  ...,  5.5861e-01,\n",
       "           -6.0607e+00, -1.1567e+00],\n",
       "          [ 9.7059e-01, -1.3040e+00,  7.5629e-01,  ...,  1.5338e+00,\n",
       "           -5.4741e+00, -4.2475e-01],\n",
       "          [ 2.0201e-01,  3.2419e-01,  2.3005e-01,  ...,  8.5555e-01,\n",
       "           -5.6302e+00, -2.9837e+00]],\n",
       "\n",
       "         [[ 4.8817e-01,  5.5611e-01,  1.7679e-01,  ...,  5.7587e-01,\n",
       "           -5.9991e-01, -4.3871e-01],\n",
       "          [-2.3804e+00, -2.5151e-01, -1.3153e-01,  ..., -2.1762e-01,\n",
       "           -4.8824e-01, -1.0050e+00],\n",
       "          [-8.0360e-01, -1.4264e+00,  8.3816e-01,  ..., -7.5620e-02,\n",
       "           -9.1244e-01,  8.3507e-02],\n",
       "          ...,\n",
       "          [ 6.9123e-01,  7.8223e-01, -9.6482e-01,  ...,  4.0848e-01,\n",
       "           -6.6194e-01,  6.9465e-01],\n",
       "          [-8.7003e-01, -4.0424e-02,  6.6969e-01,  ..., -7.8491e-01,\n",
       "            5.5019e-01,  4.8040e-01],\n",
       "          [-2.6742e+00,  1.0535e-02, -2.6393e-01,  ...,  1.1477e+00,\n",
       "           -8.5113e-01,  5.8719e-01]],\n",
       "\n",
       "         [[ 1.3037e-01, -5.8231e-02,  3.2528e-01,  ...,  3.9894e-01,\n",
       "            1.0309e-01, -3.1685e-01],\n",
       "          [ 4.0329e+00,  8.1970e-01, -1.5689e-02,  ...,  7.5521e-01,\n",
       "            4.6949e-01,  3.0322e-02],\n",
       "          [ 3.3804e+00,  1.6817e-01,  2.4104e-01,  ...,  1.3452e+00,\n",
       "            7.4412e-01,  1.4914e-01],\n",
       "          ...,\n",
       "          [ 4.0052e+00, -7.0468e-01,  2.1171e-01,  ..., -5.4007e-01,\n",
       "           -3.4932e-01, -4.3369e-01],\n",
       "          [ 3.7764e+00,  9.7915e-01,  9.1872e-02,  ...,  1.9360e+00,\n",
       "           -6.8548e-01,  1.1065e-01],\n",
       "          [ 4.1951e+00,  7.3312e-01,  2.2844e-01,  ...,  4.2410e-01,\n",
       "            3.4931e-01, -5.7745e-05]]]], grad_fn=<CloneBackward0>), tensor([[[[-5.2420e-02, -3.8264e-02,  8.5889e-03,  ...,  6.5232e-03,\n",
       "            2.5135e-02,  2.2225e-02],\n",
       "          [-1.5744e+00, -1.5696e-01, -1.5124e+00,  ..., -1.9559e-01,\n",
       "           -6.2622e-01,  9.8069e-01],\n",
       "          [ 1.1226e+00,  2.6053e-02,  1.4191e+00,  ..., -9.8041e-01,\n",
       "           -1.0557e+00,  3.1996e+00],\n",
       "          ...,\n",
       "          [-5.7987e-01,  1.5204e+00, -1.0566e+00,  ...,  4.6897e-01,\n",
       "           -5.0130e-01,  2.7047e-01],\n",
       "          [ 1.1852e+00, -9.5359e-01, -1.8380e+00,  ...,  6.7159e-01,\n",
       "            1.4402e+00,  1.0008e+00],\n",
       "          [-2.4192e-02,  1.5667e+00, -7.4846e-01,  ..., -4.7901e-01,\n",
       "            1.9469e-01,  8.3849e-01]],\n",
       "\n",
       "         [[-3.6966e-02, -5.6703e-02, -1.1514e-01,  ..., -1.8700e-02,\n",
       "           -4.8239e-02, -6.7138e-02],\n",
       "          [-4.2143e-01,  3.0042e-01, -4.7498e-01,  ...,  1.0817e+00,\n",
       "           -1.0952e-01,  7.3849e-01],\n",
       "          [-3.4794e-01,  1.3245e-01, -9.4260e-02,  ...,  3.6267e-01,\n",
       "            7.3962e-02,  1.0959e-01],\n",
       "          ...,\n",
       "          [-5.8795e-01, -5.2608e-01,  4.3665e-01,  ..., -1.9626e-01,\n",
       "            9.2344e-01, -6.4289e-01],\n",
       "          [ 4.4376e-01, -1.1283e+00, -2.3623e+00,  ...,  1.3996e+00,\n",
       "            2.5676e-01, -5.5503e-01],\n",
       "          [-6.7275e-01, -1.2790e+00,  3.0538e-01,  ..., -7.4728e-01,\n",
       "           -1.1694e-01,  4.9606e-02]],\n",
       "\n",
       "         [[ 3.0048e-02,  6.5512e-02,  7.5136e-02,  ...,  9.0852e-02,\n",
       "           -5.9102e-02,  4.1977e-02],\n",
       "          [ 6.7686e-01,  1.0848e+00, -3.9098e-01,  ..., -2.2683e-01,\n",
       "           -2.7053e-01,  8.9507e-01],\n",
       "          [ 1.4466e+00,  6.5152e-01,  3.5439e-01,  ...,  1.7937e-01,\n",
       "            4.1530e-01,  6.2020e-01],\n",
       "          ...,\n",
       "          [ 4.2075e-01,  1.1688e+00,  7.1175e-02,  ...,  8.0336e-02,\n",
       "           -1.5424e-02,  4.1469e-01],\n",
       "          [ 1.2831e-01,  5.0820e-01,  3.9268e-01,  ...,  5.4920e-01,\n",
       "            1.3027e+00, -4.0252e-01],\n",
       "          [ 8.4376e-01, -8.3829e-01,  5.1929e-01,  ..., -4.2274e-01,\n",
       "            3.5554e-01, -3.0865e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8806e-02, -3.6617e-02,  1.3755e-02,  ...,  2.6339e-02,\n",
       "            7.2744e-03, -3.0262e-02],\n",
       "          [-3.0464e-01,  6.4527e-01, -3.7065e-01,  ..., -2.9884e-01,\n",
       "           -4.5525e-01,  3.9111e-02],\n",
       "          [ 1.9920e-01, -1.4727e-01,  1.9490e+00,  ...,  8.7103e-02,\n",
       "            8.5730e-01,  5.8792e-01],\n",
       "          ...,\n",
       "          [ 3.3728e-02, -3.4515e-01,  2.3914e-01,  ...,  5.7046e-01,\n",
       "           -3.3762e-01, -4.6748e-02],\n",
       "          [-2.7098e-01, -7.6473e-01,  2.6854e-02,  ...,  3.6987e-01,\n",
       "           -1.9434e-01,  7.4750e-02],\n",
       "          [-7.9663e-01, -3.5027e-01, -5.2210e-03,  ...,  5.8415e-01,\n",
       "            7.0408e-01, -4.3725e-02]],\n",
       "\n",
       "         [[-6.4300e-02,  3.2982e-02,  2.2752e-03,  ...,  1.9581e-02,\n",
       "            5.3579e-01,  1.9468e-02],\n",
       "          [ 1.2122e+00, -1.0497e+00,  6.7110e-01,  ..., -2.5296e-02,\n",
       "            4.4319e+00,  1.0796e+00],\n",
       "          [-1.2668e-01, -1.5481e+00,  1.6575e+00,  ...,  1.5580e-01,\n",
       "            2.7164e+00, -7.8722e-01],\n",
       "          ...,\n",
       "          [-1.1537e+00, -1.0311e+00,  8.8169e-01,  ...,  6.7043e-01,\n",
       "            1.7605e+00,  1.2374e+00],\n",
       "          [ 8.6914e-01, -5.9700e-02, -4.8025e-02,  ..., -2.3378e-02,\n",
       "            2.7082e+00,  9.7827e-01],\n",
       "          [-8.4733e-01,  3.2202e-01, -4.2967e-02,  ..., -1.2557e+00,\n",
       "            4.0435e+00, -8.6018e-01]],\n",
       "\n",
       "         [[ 1.5382e-02,  5.9672e-02,  2.5998e-02,  ..., -5.8654e-02,\n",
       "           -5.3551e-02,  2.1974e-02],\n",
       "          [-1.0341e-01, -2.0319e+00,  1.0035e+00,  ..., -9.6793e-01,\n",
       "           -1.0997e+00, -5.6191e-01],\n",
       "          [-4.8187e-01,  3.7343e-02,  5.6528e-01,  ..., -1.4742e-02,\n",
       "           -2.2510e-01, -5.4724e-02],\n",
       "          ...,\n",
       "          [ 1.0966e+00, -3.3593e-01, -1.5564e+00,  ...,  2.2303e-01,\n",
       "            6.3122e-01,  1.1434e+00],\n",
       "          [-2.8434e+00, -1.3374e+00, -1.7123e-01,  ...,  1.8715e+00,\n",
       "            1.3265e+00,  3.3814e-01],\n",
       "          [-6.7990e-01, -1.0497e-01, -9.3723e-01,  ...,  2.2228e-02,\n",
       "            6.5439e-01,  5.7083e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-3.1620e-01,  3.5192e-02, -8.4203e-03,  ...,  1.0374e-02,\n",
       "            1.1619e-01, -6.6468e-02],\n",
       "          [-9.6576e-01, -3.8004e-01, -7.7400e-01,  ..., -7.9243e-01,\n",
       "            2.3131e-01, -1.6573e-01],\n",
       "          [-5.6435e-01,  2.2987e-01, -1.5394e+00,  ..., -1.4732e-01,\n",
       "           -1.5100e-01, -1.0687e+00],\n",
       "          ...,\n",
       "          [-9.3453e-01, -1.5076e+00, -3.7211e-01,  ..., -2.7778e-01,\n",
       "            3.0691e-01, -1.5423e+00],\n",
       "          [ 2.0844e-01, -5.3849e-01, -1.1553e+00,  ...,  2.9115e-02,\n",
       "            1.5051e+00, -3.7925e-01],\n",
       "          [ 3.5069e-01, -1.3672e+00, -8.0237e-01,  ..., -4.3684e-01,\n",
       "           -1.3756e+00,  3.8840e-01]],\n",
       "\n",
       "         [[-4.8983e+00,  7.3490e-01,  3.8103e-01,  ...,  4.5219e-01,\n",
       "            8.7170e-02, -6.4601e-01],\n",
       "          [ 8.1084e+00,  5.2880e-01, -1.4247e-01,  ...,  4.0303e+00,\n",
       "            1.2756e+00, -4.9042e-01],\n",
       "          [ 8.9663e+00, -3.2214e-01, -4.6669e-01,  ...,  1.3972e+00,\n",
       "            1.0784e+00, -6.6118e-01],\n",
       "          ...,\n",
       "          [ 9.8531e+00, -2.5497e-01, -1.9754e-01,  ...,  1.2925e+00,\n",
       "            1.3362e-01, -5.6174e-01],\n",
       "          [ 8.3653e+00,  9.5056e-01,  6.5695e-01,  ...,  1.2137e+00,\n",
       "            1.5614e+00, -9.1657e-01],\n",
       "          [ 8.6394e+00, -3.5557e-01, -8.8179e-01,  ..., -1.1966e+00,\n",
       "            1.1382e+00, -1.9744e+00]],\n",
       "\n",
       "         [[-1.3572e-01,  3.5208e+00,  1.3748e+00,  ..., -7.4923e-01,\n",
       "            6.1225e-01, -2.2144e+00],\n",
       "          [-1.9477e-01, -4.7993e+00, -2.4612e+00,  ..., -2.7576e-01,\n",
       "            5.3344e-01,  1.5629e+00],\n",
       "          [-7.5537e-02, -4.4016e+00, -1.7601e+00,  ...,  5.8547e-01,\n",
       "            1.5371e+00,  2.1901e+00],\n",
       "          ...,\n",
       "          [-8.8458e-01, -6.4114e+00, -8.7528e-01,  ..., -6.8168e-01,\n",
       "            5.3654e-01,  8.4134e-02],\n",
       "          [-2.5363e-01, -6.3282e+00,  6.1199e-01,  ...,  5.5383e-01,\n",
       "            2.5155e-01,  3.0813e-02],\n",
       "          [-1.6868e+00, -6.4713e+00, -1.8389e-02,  ...,  1.1915e+00,\n",
       "            6.8818e-01, -5.8264e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5330e-01,  4.0731e-01,  1.7040e-01,  ...,  4.3437e-02,\n",
       "           -1.0679e+00, -2.0179e-01],\n",
       "          [ 2.1967e+00, -3.2909e-01,  1.0819e+00,  ..., -4.0863e-01,\n",
       "            1.3363e+00, -2.8469e-01],\n",
       "          [ 1.7710e+00,  1.0846e+00, -3.4849e-01,  ..., -1.7091e+00,\n",
       "            1.4776e+00,  5.4822e-01],\n",
       "          ...,\n",
       "          [ 3.4205e-01,  2.2453e-01, -8.9494e-01,  ...,  5.3103e-01,\n",
       "            2.8897e+00,  2.4855e-01],\n",
       "          [-9.4099e-01,  1.4740e-01,  7.0018e-01,  ..., -2.1740e-01,\n",
       "            2.0505e+00,  1.2145e+00],\n",
       "          [-4.5833e-01, -6.0893e-01,  6.4360e-01,  ..., -1.7761e+00,\n",
       "            2.0907e+00,  9.9793e-02]],\n",
       "\n",
       "         [[-3.5022e+00,  3.7221e-01,  3.3470e-01,  ..., -1.4446e-01,\n",
       "            1.1427e-01, -8.4977e-01],\n",
       "          [ 1.4635e+00,  1.0664e+00, -6.1804e-01,  ..., -5.4757e-01,\n",
       "            1.2304e+00,  2.5483e-01],\n",
       "          [ 9.5965e-01,  4.2337e-01, -1.6361e-01,  ...,  6.5779e-01,\n",
       "            6.8206e-01,  2.3885e-01],\n",
       "          ...,\n",
       "          [ 1.1234e+00, -6.6210e-01,  3.0468e-01,  ...,  7.5498e-01,\n",
       "           -3.4030e+00,  2.7268e-01],\n",
       "          [ 1.3491e+00, -4.0650e-01,  1.3447e+00,  ..., -1.0343e+00,\n",
       "           -1.4770e+00,  1.5414e+00],\n",
       "          [ 1.9309e+00,  1.1405e-02,  3.1453e-01,  ..., -1.7852e+00,\n",
       "           -1.0296e+00,  1.0238e+00]],\n",
       "\n",
       "         [[ 8.6508e-02,  1.2214e+00, -2.2239e+00,  ..., -1.4464e-01,\n",
       "            1.6709e-01, -1.1645e-01],\n",
       "          [ 7.8956e-01, -3.3216e+00,  4.1655e+00,  ..., -7.2117e-01,\n",
       "            1.0361e+00, -4.2268e-01],\n",
       "          [ 1.3752e+00, -3.1867e+00,  4.8438e+00,  ..., -1.1656e+00,\n",
       "            1.1416e+00, -9.8167e-01],\n",
       "          ...,\n",
       "          [-4.2314e-01, -3.7145e+00,  4.4816e+00,  ..., -1.6336e-01,\n",
       "            3.0019e-01,  3.4161e-01],\n",
       "          [-6.0907e-02, -3.3562e+00,  4.5845e+00,  ...,  9.6603e-01,\n",
       "           -1.0010e+00,  3.9183e-01],\n",
       "          [ 6.8965e-01, -3.1460e+00,  4.7537e+00,  ..., -2.1665e-01,\n",
       "            5.3008e-01, -5.9157e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-4.5085e-03, -2.1284e-02, -3.3724e-02,  ...,  4.1160e-02,\n",
       "           -3.8839e-02,  2.7103e-02],\n",
       "          [-9.0234e-01,  9.8000e-01,  6.7309e-01,  ..., -1.3336e+00,\n",
       "           -1.4929e+00, -1.0208e+00],\n",
       "          [-8.9999e-01,  8.0987e-01,  4.0038e-01,  ...,  3.3310e-01,\n",
       "           -1.5204e+00, -1.1944e+00],\n",
       "          ...,\n",
       "          [ 8.2971e-01, -3.3612e-01,  9.3543e-01,  ...,  9.6930e-01,\n",
       "           -5.3653e-03, -4.7475e-01],\n",
       "          [ 4.3127e-01,  1.9586e+00,  9.1970e-01,  ..., -1.4448e+00,\n",
       "           -1.4868e+00,  1.2852e+00],\n",
       "          [ 1.2369e-01,  1.3082e+00,  1.9632e+00,  ...,  3.5817e-01,\n",
       "           -2.1542e+00,  1.5822e-01]],\n",
       "\n",
       "         [[-6.6686e-02, -5.5596e-02, -2.0442e-03,  ..., -4.0177e-02,\n",
       "           -2.8112e-02, -2.4175e-02],\n",
       "          [-4.0588e-02,  1.4512e-01,  3.5361e-03,  ..., -3.4912e-01,\n",
       "           -5.5508e-02,  1.7111e-02],\n",
       "          [ 9.7307e-02, -7.9019e-01, -7.9259e-01,  ..., -2.0411e-01,\n",
       "            6.6391e-02,  1.8675e-01],\n",
       "          ...,\n",
       "          [-2.4280e-01, -4.3390e-01, -3.1012e-01,  ..., -6.7296e-01,\n",
       "            6.6719e-01, -1.3686e-01],\n",
       "          [ 9.4483e-01,  3.5186e-01, -4.7675e-02,  ...,  1.1478e-01,\n",
       "            5.1615e-01,  4.2685e-02],\n",
       "          [ 8.0570e-01,  2.8522e-01,  9.5020e-02,  ...,  9.1115e-01,\n",
       "            3.8061e-01, -7.5640e-01]],\n",
       "\n",
       "         [[ 1.7260e-02, -4.2052e-02, -4.8381e-02,  ..., -1.7365e-01,\n",
       "            1.7129e-02,  1.2608e-01],\n",
       "          [-1.2828e-01, -7.4391e-01,  4.8943e-01,  ...,  6.2862e-01,\n",
       "            6.5881e-01, -8.5009e-01],\n",
       "          [-3.9203e-01, -2.4985e-01,  1.0925e+00,  ..., -5.8717e-01,\n",
       "           -5.4878e-01, -9.9798e-01],\n",
       "          ...,\n",
       "          [-9.6892e-01,  8.7645e-01,  1.3086e+00,  ..., -6.1534e-02,\n",
       "           -4.4738e-01,  2.1974e-01],\n",
       "          [ 6.9126e-01,  1.0028e+00, -7.0303e-01,  ...,  2.3257e-01,\n",
       "            8.4788e-01, -2.2287e-01],\n",
       "          [ 2.7169e-02,  1.2902e+00, -7.5664e-01,  ...,  2.2327e-01,\n",
       "            4.1065e-01,  8.5401e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1061e-02, -3.0327e-02, -9.0346e-02,  ..., -2.9031e-02,\n",
       "            1.7625e-02,  1.5886e-02],\n",
       "          [ 4.8932e-01,  1.9842e+00,  5.8329e-01,  ...,  1.7657e-01,\n",
       "            7.5752e-02, -1.3096e+00],\n",
       "          [-2.0278e-01,  1.8250e+00, -3.4073e-01,  ...,  6.5080e-01,\n",
       "           -9.1005e-01, -1.2456e+00],\n",
       "          ...,\n",
       "          [ 7.0687e-01,  5.5072e-01, -1.0454e+00,  ...,  1.6037e-01,\n",
       "            3.5916e-01, -1.3389e+00],\n",
       "          [-4.2870e-01, -4.6245e-01,  1.6619e-01,  ...,  2.6551e-01,\n",
       "            1.2443e-01, -1.1032e+00],\n",
       "          [ 4.4569e-01, -8.8821e-02,  3.5980e-01,  ..., -2.4885e-01,\n",
       "            3.3251e-01,  1.4591e+00]],\n",
       "\n",
       "         [[ 5.6077e-03,  6.4386e-02, -5.6489e-02,  ...,  1.0502e-01,\n",
       "            8.1499e-02,  2.2195e-02],\n",
       "          [-1.1862e+00,  5.3596e-02,  1.6758e+00,  ..., -2.9369e-01,\n",
       "            7.8734e-02,  6.5227e-01],\n",
       "          [-2.5397e-01, -1.3149e+00,  1.4548e+00,  ..., -1.6742e-01,\n",
       "           -2.2189e+00,  4.4719e-01],\n",
       "          ...,\n",
       "          [ 4.8158e-02, -3.9588e-01,  7.0132e-01,  ..., -1.8020e+00,\n",
       "           -3.2126e-01,  3.9224e-01],\n",
       "          [-3.2105e-01,  5.4308e-01, -3.1096e-01,  ..., -1.9153e+00,\n",
       "            5.3272e-02, -4.8706e-01],\n",
       "          [ 1.7024e-01, -4.4215e-01,  1.0797e+00,  ..., -5.6902e-01,\n",
       "            1.2103e+00, -7.3675e-01]],\n",
       "\n",
       "         [[ 2.4851e-02,  2.0092e-02,  4.4202e-02,  ..., -4.8186e-02,\n",
       "            2.8430e-02,  1.4678e-02],\n",
       "          [-1.7336e+00, -2.0121e-01,  3.0788e-01,  ...,  3.1697e-01,\n",
       "           -2.3928e-01, -1.9257e-01],\n",
       "          [-2.0181e-01, -8.0173e-02, -1.3753e-01,  ..., -4.8939e-01,\n",
       "           -1.2830e+00,  4.0782e-01],\n",
       "          ...,\n",
       "          [-5.5975e-01,  4.8152e-01, -6.8213e-01,  ..., -2.2938e-01,\n",
       "           -5.8334e-01, -1.2061e+00],\n",
       "          [-2.6902e+00,  1.9571e+00, -1.4847e+00,  ...,  2.4470e-01,\n",
       "           -9.7478e-01,  1.3873e-01],\n",
       "          [-2.2965e-01, -7.4341e-01, -7.2398e-01,  ..., -1.2300e-02,\n",
       "           -4.9545e-01,  3.3204e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.0212, -0.1637,  0.3006,  ...,  0.3544, -0.5675,  0.2796],\n",
       "          [-2.9118,  1.4985,  2.7371,  ...,  4.1697,  6.6011, -1.9517],\n",
       "          [-2.4185,  2.2224,  1.3576,  ...,  4.3502,  8.1620, -0.1434],\n",
       "          ...,\n",
       "          [-2.7835,  0.4083,  2.3613,  ...,  4.8439,  9.9244, -0.9654],\n",
       "          [-3.1515, -1.0769,  3.1980,  ...,  2.9876,  7.5478, -1.4565],\n",
       "          [-3.8122,  1.0224,  3.1160,  ...,  3.8895,  8.4554,  0.2221]],\n",
       "\n",
       "         [[ 0.3043,  0.2946,  0.6602,  ...,  0.2869, -0.1246, -1.7083],\n",
       "          [ 1.3211,  0.5044,  2.4926,  ...,  1.4724,  0.3970, -6.2736],\n",
       "          [ 0.2971,  0.6168,  3.5351,  ...,  0.6023, -0.4486, -5.4024],\n",
       "          ...,\n",
       "          [ 0.1776,  0.8290,  4.0237,  ...,  0.3323, -0.3753, -5.9894],\n",
       "          [-0.0799, -0.0434,  2.9692,  ...,  1.1327, -0.1089, -6.3558],\n",
       "          [ 0.1703,  0.5343,  2.8145,  ..., -0.0537,  0.6995, -6.1831]],\n",
       "\n",
       "         [[-0.3804,  0.9425,  2.6764,  ..., -1.8956,  1.7175, -2.2629],\n",
       "          [ 0.2280,  1.4249, -0.0792,  ..., -0.6600,  1.0318, -3.4404],\n",
       "          [-1.8184,  0.1634,  1.1425,  ..., -1.3384,  0.7265, -2.3992],\n",
       "          ...,\n",
       "          [-0.3479, -0.9593,  1.3809,  ..., -1.0439,  1.5623, -3.1702],\n",
       "          [-0.5119, -0.6518,  1.4815,  ..., -0.5499,  2.3215, -2.8588],\n",
       "          [-0.7756, -1.0317,  1.8409,  ..., -1.4826,  0.5124, -2.8882]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2666,  0.4389,  0.0223,  ..., -1.2350,  0.4739,  0.6299],\n",
       "          [ 1.1472,  0.4836,  0.8208,  ..., -1.2371,  0.2194, -0.5084],\n",
       "          [-0.3902, -0.2325,  0.1103,  ..., -1.1736, -1.2604,  1.0103],\n",
       "          ...,\n",
       "          [-0.1499, -1.0672,  0.3941,  ..., -0.3508,  0.6040,  0.7141],\n",
       "          [ 0.1293, -0.0584, -0.1690,  ..., -1.1425, -1.3625,  0.2995],\n",
       "          [ 1.0860, -0.0731, -0.7875,  ..., -0.9416,  1.9583,  0.3419]],\n",
       "\n",
       "         [[ 0.7296, -1.3380, -0.0776,  ...,  1.2765, -4.6570, -1.0397],\n",
       "          [ 0.0413, -1.5888, -0.0783,  ...,  2.4664,  1.6371, -0.4977],\n",
       "          [-1.4474, -1.8260,  1.7563,  ...,  1.8191,  6.9939, -4.0824],\n",
       "          ...,\n",
       "          [-2.7313, -1.5967,  0.6669,  ...,  3.9795,  4.7231, -0.2320],\n",
       "          [ 0.5592,  0.1729,  1.8855,  ...,  4.0194,  3.6458, -1.2439],\n",
       "          [-0.3063,  0.3750, -0.8500,  ...,  4.1685,  4.1902, -2.4345]],\n",
       "\n",
       "         [[-1.0397,  0.5083, -0.8637,  ..., -0.1045, -0.8968,  1.0154],\n",
       "          [-0.8533, -0.4714,  1.1676,  ...,  0.1854, -1.8358,  0.2904],\n",
       "          [ 0.3752, -0.0472, -0.1380,  ..., -0.5483, -2.2154, -1.0815],\n",
       "          ...,\n",
       "          [-1.7931,  2.4355, -0.4333,  ..., -2.6417, -1.4613,  0.7890],\n",
       "          [-0.7198,  1.5644, -0.7712,  ..., -3.2202, -0.5264, -1.2814],\n",
       "          [-1.2069,  2.9476,  0.1754,  ..., -1.8319, -1.3131,  0.4097]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 7.7001e-02,  8.7798e-02, -3.7787e-02,  ...,  2.1135e-03,\n",
       "           -1.4944e-02,  1.6904e-02],\n",
       "          [ 4.4811e-02,  1.2530e-01, -3.7741e-01,  ..., -1.0527e+00,\n",
       "           -1.6805e-02,  1.1218e+00],\n",
       "          [-5.1406e-01, -8.2075e-02,  2.4546e-01,  ..., -9.0456e-02,\n",
       "           -1.5295e+00, -3.3651e-01],\n",
       "          ...,\n",
       "          [-1.3354e+00, -7.2781e-01, -8.4127e-02,  ...,  1.7435e+00,\n",
       "           -3.1887e-01, -1.0368e+00],\n",
       "          [-1.3934e+00, -4.5197e-01,  1.6344e+00,  ...,  3.0315e+00,\n",
       "           -4.2538e-01, -6.3943e-01],\n",
       "          [-3.9428e-01, -6.7917e-02,  5.0987e-01,  ...,  1.7419e+00,\n",
       "           -1.1961e+00, -5.1955e-01]],\n",
       "\n",
       "         [[ 1.1877e-02,  3.4336e-02, -6.9645e-02,  ...,  2.2854e-02,\n",
       "            2.4814e-03, -1.0586e-02],\n",
       "          [ 3.8960e-02, -1.2511e+00,  1.6568e-01,  ..., -1.0374e+00,\n",
       "           -1.6335e+00, -1.2286e-01],\n",
       "          [ 6.1797e-02, -9.3424e-01, -2.9625e-01,  ...,  3.4849e-01,\n",
       "           -2.0768e-01,  4.5617e-01],\n",
       "          ...,\n",
       "          [ 9.5708e-01,  7.5607e-01,  3.7382e-02,  ...,  4.0215e-01,\n",
       "           -1.0204e-01,  8.0223e-01],\n",
       "          [ 2.5796e+00,  2.3853e+00, -8.5969e-01,  ..., -2.4120e+00,\n",
       "           -5.6823e-01, -1.2537e+00],\n",
       "          [ 9.0121e-01,  7.3205e-01,  1.4122e+00,  ..., -1.3521e+00,\n",
       "           -5.0421e-01, -1.7394e+00]],\n",
       "\n",
       "         [[-1.2618e-01,  5.3238e-02, -5.0291e-02,  ...,  2.8343e-02,\n",
       "           -4.8323e-02,  7.0708e-02],\n",
       "          [ 1.5205e+00, -1.9335e+00,  1.7253e+00,  ..., -1.5559e+00,\n",
       "            6.3899e-01, -7.0093e-01],\n",
       "          [ 9.4345e-01,  6.2787e-01,  1.4288e+00,  ..., -1.6878e+00,\n",
       "            2.4369e+00,  3.8050e-01],\n",
       "          ...,\n",
       "          [ 1.7463e-01, -1.1073e+00,  6.1138e-01,  ..., -4.4996e-01,\n",
       "            1.2291e+00, -9.7345e-01],\n",
       "          [ 3.1186e-01,  2.5541e-01,  1.7698e+00,  ..., -1.4031e+00,\n",
       "           -5.6362e-01, -2.2883e+00],\n",
       "          [-2.4793e-01,  2.3792e-01, -4.4002e-02,  ...,  7.8549e-01,\n",
       "            1.9573e+00,  1.3605e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.8122e-02, -5.1926e-03, -1.2005e-02,  ..., -5.1986e-02,\n",
       "           -3.0285e-02,  6.3679e-02],\n",
       "          [-7.7115e-01,  8.2849e-01,  7.2812e-01,  ..., -2.0516e-01,\n",
       "           -1.6620e+00,  1.4508e-01],\n",
       "          [-2.7784e+00,  4.6457e-01, -2.0467e+00,  ..., -2.4017e-01,\n",
       "            3.6763e-01, -1.3733e-01],\n",
       "          ...,\n",
       "          [-1.7247e+00, -5.9616e-01, -2.5614e+00,  ..., -2.1933e+00,\n",
       "           -1.9482e+00,  3.7975e-01],\n",
       "          [-2.9616e-01, -2.8036e-01,  5.9002e-02,  ..., -4.3927e-01,\n",
       "            4.0805e-01,  9.3668e-01],\n",
       "          [ 2.1444e+00, -8.5004e-01, -4.1239e+00,  ..., -3.0323e-02,\n",
       "           -2.9972e-01,  6.8452e-01]],\n",
       "\n",
       "         [[ 1.8095e-03, -5.9661e-02,  1.4596e-02,  ...,  1.2167e-02,\n",
       "            3.6521e-02,  2.6548e-02],\n",
       "          [-1.3634e+00, -9.2095e-01, -3.0086e-01,  ...,  1.8535e-01,\n",
       "            8.6497e-01,  1.0616e+00],\n",
       "          [-1.7927e+00, -1.4204e+00,  8.6539e-01,  ..., -1.3913e+00,\n",
       "            2.1454e+00,  1.2259e+00],\n",
       "          ...,\n",
       "          [-8.2489e-02,  5.5210e-01, -4.2416e-01,  ..., -3.2954e-01,\n",
       "            1.1073e+00,  5.9003e-01],\n",
       "          [ 1.3974e+00, -7.6060e-01, -4.7792e-01,  ...,  7.8660e-01,\n",
       "           -1.3102e+00, -7.1202e-01],\n",
       "          [ 8.3326e-02, -4.2652e-01, -5.2155e-01,  ..., -1.0414e-01,\n",
       "           -2.7769e-01, -5.3884e-01]],\n",
       "\n",
       "         [[-1.8261e-02, -3.3795e-02, -3.0540e-02,  ..., -1.0795e-02,\n",
       "            1.9100e-02, -7.8019e-03],\n",
       "          [-9.2693e-01,  5.8950e-01, -5.3207e-01,  ...,  3.1606e-01,\n",
       "            3.2079e-01,  9.4555e-01],\n",
       "          [-7.8442e-01,  1.8838e+00,  1.4643e+00,  ...,  4.6898e-01,\n",
       "            1.2946e+00, -2.6995e-01],\n",
       "          ...,\n",
       "          [ 7.9159e-01,  3.6235e-01, -1.2996e-01,  ...,  1.5105e+00,\n",
       "           -2.0469e-01,  1.9911e-01],\n",
       "          [ 1.4933e+00,  1.8120e+00, -1.2729e+00,  ..., -1.0786e-02,\n",
       "            2.2400e-01, -8.0071e-01],\n",
       "          [-4.4813e-01,  2.0074e+00, -7.0202e-01,  ...,  5.9584e-01,\n",
       "           -2.3741e-01,  1.5338e+00]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 4.4040e-01, -6.5628e-01,  1.3372e-01,  ...,  4.1126e-02,\n",
       "           -7.1747e-01, -3.7593e-01],\n",
       "          [ 1.0172e+00,  2.9836e+00, -6.1567e-01,  ..., -1.2552e+00,\n",
       "           -1.5745e+00, -1.0160e+00],\n",
       "          [ 9.3751e-01,  1.7742e+00, -3.6995e-01,  ..., -7.3494e-01,\n",
       "           -1.5067e+00, -2.9358e-01],\n",
       "          ...,\n",
       "          [ 1.1834e+00,  1.8507e+00, -2.8827e-01,  ..., -1.1764e-01,\n",
       "           -1.0566e+00, -8.3056e-01],\n",
       "          [ 2.8922e+00,  3.2684e+00,  3.6824e-01,  ..., -7.3017e-01,\n",
       "           -1.4482e+00, -1.4166e+00],\n",
       "          [ 1.7421e+00,  1.6787e+00, -2.7157e-01,  ...,  1.3764e+00,\n",
       "           -2.2091e+00, -1.3700e+00]],\n",
       "\n",
       "         [[-2.9680e-02,  4.2158e-01, -5.4876e-01,  ...,  8.6769e-02,\n",
       "            7.6181e-03,  4.4803e-02],\n",
       "          [-1.9087e-02,  2.0097e-01, -1.5212e+00,  ..., -2.0042e+00,\n",
       "           -2.5129e+00,  1.3188e+00],\n",
       "          [-2.0813e+00, -2.8195e-01, -1.8077e+00,  ..., -4.7653e+00,\n",
       "           -1.1056e+00,  1.0917e+00],\n",
       "          ...,\n",
       "          [ 1.5092e+00,  1.5570e+00, -3.1786e-02,  ..., -4.6334e+00,\n",
       "           -7.8757e-01,  5.4953e-01],\n",
       "          [ 2.0370e+00, -1.1620e+00, -1.0339e+00,  ..., -3.6761e+00,\n",
       "           -2.2760e+00,  5.9016e-01],\n",
       "          [ 4.4423e-01,  4.1671e-01, -1.0900e+00,  ..., -2.6844e+00,\n",
       "           -2.6708e+00,  6.8801e-01]],\n",
       "\n",
       "         [[-3.3706e+00, -3.9957e-03, -7.5434e-01,  ..., -4.6267e-01,\n",
       "           -1.4506e-01,  1.9253e-01],\n",
       "          [ 8.1659e+00,  2.5631e-01, -3.6615e-01,  ...,  5.3597e-01,\n",
       "            5.8141e-01,  3.2382e-01],\n",
       "          [ 9.2053e+00, -3.3585e-01, -7.6832e-01,  ...,  1.4284e+00,\n",
       "           -5.2350e-01, -3.2517e-01],\n",
       "          ...,\n",
       "          [ 9.6478e+00,  6.0213e-01, -1.7718e+00,  ..., -1.3039e-01,\n",
       "            2.9022e-01,  6.9352e-01],\n",
       "          [ 8.6187e+00,  6.1967e-01, -1.2464e+00,  ...,  3.1844e-01,\n",
       "           -1.0366e+00,  3.9078e-01],\n",
       "          [ 8.7685e+00,  2.0996e-01, -1.7398e+00,  ..., -6.1193e-01,\n",
       "           -1.0885e+00, -1.4087e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.3632e+00,  4.7601e-01, -1.4165e+00,  ...,  2.6590e-01,\n",
       "            2.7011e-01,  4.2314e+00],\n",
       "          [-6.4314e+00,  3.3806e-01,  3.0226e+00,  ..., -9.7844e-01,\n",
       "           -2.0089e-01, -6.2899e+00],\n",
       "          [-8.3032e+00, -5.1969e-01,  4.2177e+00,  ..., -9.2274e-01,\n",
       "            1.5183e+00, -4.4938e+00],\n",
       "          ...,\n",
       "          [-6.7602e+00,  1.4630e+00,  6.4155e-01,  ..., -3.1585e+00,\n",
       "            1.8239e+00, -6.6969e+00],\n",
       "          [-6.6875e+00,  1.6324e-01,  2.3106e+00,  ..., -2.2079e+00,\n",
       "           -1.6870e-01, -7.0845e+00],\n",
       "          [-6.6694e+00,  1.0355e+00,  2.1673e+00,  ..., -1.3448e+00,\n",
       "            4.2085e-02, -6.1612e+00]],\n",
       "\n",
       "         [[ 8.3477e-01,  1.0962e+00, -1.7854e-01,  ...,  4.9275e-02,\n",
       "           -5.9750e-01,  4.2539e-01],\n",
       "          [-1.9142e+00,  8.2301e-01, -1.2921e-01,  ...,  4.0305e-01,\n",
       "           -1.3289e+00, -1.5642e+00],\n",
       "          [-2.7430e+00,  5.7834e-01, -1.6446e+00,  ...,  4.8496e-01,\n",
       "           -2.6986e+00, -9.6300e-01],\n",
       "          ...,\n",
       "          [-3.2023e+00,  1.4933e+00, -1.3188e+00,  ..., -4.7411e-02,\n",
       "           -1.9444e+00,  6.0990e-01],\n",
       "          [-1.9610e+00, -7.3695e-01, -5.9795e-01,  ..., -1.6249e+00,\n",
       "           -1.0604e+00, -1.6697e+00],\n",
       "          [-2.9750e+00,  1.2451e+00,  4.5881e-01,  ..., -1.3251e+00,\n",
       "           -1.8696e+00,  8.3164e-01]],\n",
       "\n",
       "         [[ 2.4793e+00,  5.7677e-01, -3.7553e-01,  ..., -3.1920e+00,\n",
       "           -5.0025e-01, -9.9078e-02],\n",
       "          [-9.5308e-01,  1.4507e+00,  3.3108e-01,  ...,  5.4319e+00,\n",
       "            1.4862e+00,  1.9269e-02],\n",
       "          [-9.3256e-01,  4.3418e-01,  2.0465e+00,  ...,  4.6181e+00,\n",
       "            1.1157e+00, -4.7137e-01],\n",
       "          ...,\n",
       "          [-2.5328e+00,  1.3441e+00, -9.3660e-01,  ...,  3.6659e+00,\n",
       "            1.5589e+00,  2.2295e+00],\n",
       "          [-1.9849e+00,  9.0739e-01, -9.5918e-02,  ...,  2.9862e+00,\n",
       "            1.4124e-01, -1.2550e+00],\n",
       "          [-1.6003e+00,  5.8317e-01, -1.7986e+00,  ...,  2.5126e+00,\n",
       "            3.0310e-01,  1.5541e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 0.0369,  0.0286, -0.0259,  ..., -0.0137, -0.0255,  0.0142],\n",
       "          [-0.5544, -0.0528, -0.2906,  ..., -0.4066, -1.0416,  0.0044],\n",
       "          [ 0.7692, -1.0086,  0.3254,  ...,  0.0249, -1.3343, -0.4564],\n",
       "          ...,\n",
       "          [-0.1638,  0.0387,  0.1531,  ..., -0.5909, -0.6504,  0.1164],\n",
       "          [ 0.5398,  1.8020,  0.0319,  ...,  0.2183, -0.1688, -0.7623],\n",
       "          [-0.1392,  0.2228,  0.5821,  ..., -0.0846,  0.0819, -1.2276]],\n",
       "\n",
       "         [[-0.1716, -0.4328,  0.0273,  ...,  0.1864, -0.0854,  0.1225],\n",
       "          [ 0.4931, -1.3203, -0.1568,  ...,  0.1786,  0.0686, -1.6885],\n",
       "          [ 1.1465, -1.6695, -1.0557,  ..., -0.4720, -0.1514, -0.0290],\n",
       "          ...,\n",
       "          [ 0.0795, -1.6303, -0.0907,  ..., -0.8998,  0.0562, -0.6545],\n",
       "          [ 0.3716, -0.7086, -0.7750,  ..., -0.3410,  1.2397,  0.4609],\n",
       "          [ 1.1651, -0.0087, -0.5707,  ..., -0.5358,  0.2380, -0.9280]],\n",
       "\n",
       "         [[-0.0323, -0.0120, -0.1584,  ...,  0.0054, -0.0170,  0.1039],\n",
       "          [ 0.4705, -0.4732, -0.4588,  ..., -0.0952,  0.4254,  0.4675],\n",
       "          [-0.8675,  0.3888, -0.7080,  ..., -0.9545,  0.5174,  1.4192],\n",
       "          ...,\n",
       "          [ 1.6984, -0.4869, -0.3858,  ..., -1.5941,  1.1732,  0.1882],\n",
       "          [-0.2264, -1.2845,  0.7810,  ..., -0.3748,  1.0260,  1.4150],\n",
       "          [ 0.6992,  0.6109,  1.3865,  ..., -1.6313,  0.8790, -0.1605]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0073,  0.0020,  0.1902,  ...,  0.1803,  0.0215,  0.0847],\n",
       "          [ 0.3045,  0.3173,  0.0867,  ...,  0.0295, -0.8044,  0.3290],\n",
       "          [ 0.6474,  0.8373, -0.5074,  ..., -1.0284, -0.6165, -0.1547],\n",
       "          ...,\n",
       "          [-0.8206, -0.1048, -1.7495,  ..., -0.5065, -0.7572, -0.1454],\n",
       "          [ 0.5323,  1.0090, -0.3770,  ..., -0.9527,  0.3911,  0.0523],\n",
       "          [ 0.1105,  0.1925, -0.6167,  ..., -1.4972,  0.1291, -0.6891]],\n",
       "\n",
       "         [[-0.0662, -0.0647, -0.0094,  ..., -0.0310, -0.0167,  0.0174],\n",
       "          [-0.9706,  0.6257, -0.9784,  ...,  0.6523,  1.0499, -0.5617],\n",
       "          [-0.2859, -0.0935, -0.2153,  ...,  0.5622,  1.3966,  0.4621],\n",
       "          ...,\n",
       "          [-0.4331, -0.5152,  0.6889,  ..., -0.0405,  0.7951, -0.8915],\n",
       "          [ 0.6542,  0.1838,  1.0977,  ...,  0.4217, -0.1645, -0.3914],\n",
       "          [ 0.2113, -1.2005,  1.0270,  ...,  0.1081, -0.4227, -0.9151]],\n",
       "\n",
       "         [[ 0.1139,  0.0031, -0.1675,  ...,  0.2489, -0.4257, -0.0636],\n",
       "          [-0.5225,  0.6717,  0.1021,  ...,  0.1500,  0.5521, -0.8216],\n",
       "          [-0.6722,  0.4033,  1.2812,  ...,  0.0519,  0.8271, -0.4543],\n",
       "          ...,\n",
       "          [-0.0370, -0.7733, -0.4131,  ..., -0.4685, -0.0726, -0.6018],\n",
       "          [-0.1261, -0.2497,  0.8795,  ...,  0.3531,  0.4109,  0.5507],\n",
       "          [-0.5179, -0.9547, -0.2765,  ..., -0.1349,  1.3940,  0.4651]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[ 0.4134,  0.5126, -0.3565,  ...,  0.5050,  0.8812, -0.0227],\n",
       "          [ 1.5014,  0.8687,  2.8506,  ...,  0.2573,  1.6400,  1.0839],\n",
       "          [ 1.7643,  0.0378, -0.5316,  ...,  0.3892,  0.0940,  1.1173],\n",
       "          ...,\n",
       "          [-0.1276,  2.2736,  1.0787,  ..., -0.6455, -0.6937, -0.5134],\n",
       "          [ 0.8662, -0.6099,  2.9288,  ...,  0.1047, -0.0329,  0.4246],\n",
       "          [ 1.8938, -0.6189,  0.6649,  ..., -0.7700,  0.0187, -1.3736]],\n",
       "\n",
       "         [[ 0.2975,  1.7514,  0.8115,  ...,  0.7068,  0.3864,  0.7346],\n",
       "          [ 1.1097,  0.7931,  0.0155,  ...,  0.7203, -0.3681, -0.4381],\n",
       "          [ 0.4444,  3.2093,  3.4601,  ...,  0.9542, -0.9968,  0.0537],\n",
       "          ...,\n",
       "          [ 0.8987,  1.4530,  1.2635,  ..., -0.0545,  0.7152, -0.0402],\n",
       "          [-0.0720, -0.7712,  0.5452,  ..., -0.3902,  0.2909,  2.2691],\n",
       "          [ 0.0643, -2.6421, -0.0720,  ...,  1.0006, -1.5616,  1.8124]],\n",
       "\n",
       "         [[ 0.0454, -0.6594,  1.4237,  ..., -1.8143,  0.1521, -5.2665],\n",
       "          [-0.6443,  2.3039, -3.3374,  ...,  1.3777, -0.6105,  2.2525],\n",
       "          [ 0.0320,  1.1766, -2.9474,  ...,  1.3734, -0.2546,  3.1972],\n",
       "          ...,\n",
       "          [ 0.2020, -0.8803, -3.5754,  ...,  3.3238, -0.4428,  2.0415],\n",
       "          [-0.3780, -0.2077, -3.3523,  ...,  3.2747,  0.3244,  3.3259],\n",
       "          [-0.2217, -0.3179, -1.6711,  ...,  2.6055,  0.5581,  3.7939]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0115, -0.5142,  0.4706,  ..., -0.0360, -0.3577,  0.0960],\n",
       "          [ 2.1916, -1.0603, -0.2255,  ..., -1.6042, -1.6899, -0.7781],\n",
       "          [ 1.3168, -0.7582, -0.4512,  ..., -1.8429, -1.6309, -1.4513],\n",
       "          ...,\n",
       "          [ 0.1801, -0.7192,  0.1969,  ..., -0.5013, -1.8166, -0.1517],\n",
       "          [ 1.1511, -0.9416, -1.6889,  ..., -0.5113, -2.4479,  0.8405],\n",
       "          [-0.3097, -0.2980, -0.3159,  ..., -1.2118, -2.0243,  0.0139]],\n",
       "\n",
       "         [[-0.6367,  0.7851, -0.1540,  ...,  0.3294, -1.0576, -0.5626],\n",
       "          [-2.0348,  0.9309, -0.1385,  ...,  0.9156,  3.2307, -3.7185],\n",
       "          [-1.9637,  0.7118,  0.1279,  ...,  0.6475,  3.8669, -4.2774],\n",
       "          ...,\n",
       "          [-1.7520, -1.1946,  0.8794,  ...,  0.7150,  4.4015, -2.1256],\n",
       "          [-2.3344, -0.0952, -0.6909,  ..., -0.4483,  5.2318, -1.1508],\n",
       "          [-1.9089,  0.2224, -0.3277,  ...,  1.4855,  3.9661, -1.0482]],\n",
       "\n",
       "         [[-1.1397,  0.7122, -0.5499,  ..., -0.9746, -0.7975,  1.1930],\n",
       "          [-0.0136,  0.7571,  0.2909,  ..., -0.8868, -1.0869, -1.8999],\n",
       "          [ 0.0057, -0.4774,  0.3340,  ..., -2.2704, -3.5179, -0.9949],\n",
       "          ...,\n",
       "          [ 0.9430, -0.4678,  1.5353,  ...,  0.8757,  1.4465, -1.3484],\n",
       "          [ 1.7656, -0.7283,  0.3450,  ..., -0.0490, -0.5545, -1.3791],\n",
       "          [ 0.9093,  0.4359,  1.5783,  ..., -1.1384, -1.4290,  1.3900]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-1.1750e-01, -1.8564e-03, -1.1595e-02,  ..., -6.1332e-03,\n",
       "           -7.9083e-03, -2.1423e-04],\n",
       "          [ 1.3380e+00, -7.0113e-01, -8.3018e-01,  ...,  5.0892e-01,\n",
       "            7.3189e-01,  8.1994e-01],\n",
       "          [ 9.0476e-01,  1.2220e-01, -2.8674e-01,  ..., -3.5194e-01,\n",
       "           -1.3039e-01, -6.4556e-01],\n",
       "          ...,\n",
       "          [-1.3369e+00, -6.1504e-01, -1.7729e+00,  ...,  8.2933e-01,\n",
       "           -1.7074e+00,  1.0730e+00],\n",
       "          [ 8.9468e-01,  3.9695e-01, -1.6152e+00,  ...,  1.0663e-01,\n",
       "           -1.3731e-01,  6.5623e-01],\n",
       "          [-1.4080e+00,  2.4959e+00, -2.8979e-01,  ...,  1.6930e+00,\n",
       "            5.6647e-01,  1.9557e-01]],\n",
       "\n",
       "         [[ 4.4245e-02, -3.5555e-02, -2.5556e-02,  ..., -4.2030e-02,\n",
       "            1.1624e-01,  2.0278e-02],\n",
       "          [ 7.0278e-01, -7.3413e-01,  5.9017e-01,  ..., -3.2180e+00,\n",
       "           -3.5188e-01, -5.7890e-01],\n",
       "          [-1.2073e+00, -2.5267e+00, -5.4367e-01,  ...,  8.9444e-01,\n",
       "            3.2940e-02, -6.8737e-01],\n",
       "          ...,\n",
       "          [-1.3075e-01, -1.3880e+00, -8.8215e-01,  ..., -1.6964e+00,\n",
       "           -8.9783e-01,  8.7502e-01],\n",
       "          [ 2.8518e-01, -3.6744e-01,  1.3760e-01,  ..., -1.7026e-02,\n",
       "           -2.3159e+00,  1.4010e+00],\n",
       "          [ 1.7147e-01, -5.6557e-01, -2.1163e-01,  ..., -6.5281e-01,\n",
       "           -1.8870e-01,  5.0863e-01]],\n",
       "\n",
       "         [[ 1.1546e-02, -2.6974e-02,  8.8379e-03,  ...,  2.9797e-02,\n",
       "            2.3260e-02, -5.4973e-02],\n",
       "          [ 1.8363e+00,  4.9412e-01, -2.1746e-01,  ...,  4.6753e-01,\n",
       "           -2.1268e-01,  5.6017e-01],\n",
       "          [ 1.7333e+00, -5.6635e-02,  3.5340e-01,  ..., -8.0227e-01,\n",
       "            6.7687e-01,  1.0146e+00],\n",
       "          ...,\n",
       "          [-4.2566e-01, -1.0551e+00, -6.2607e-01,  ..., -1.1661e-02,\n",
       "            1.2751e+00,  9.5720e-01],\n",
       "          [-1.1122e+00,  3.8758e-01,  2.0832e-01,  ...,  1.2566e+00,\n",
       "            2.8576e-01,  1.1847e+00],\n",
       "          [-5.1347e-01,  7.1838e-01,  8.7801e-01,  ...,  2.2666e+00,\n",
       "           -4.3931e-01,  1.1062e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.1618e-02, -7.7912e-02,  3.5984e-02,  ..., -1.0208e-01,\n",
       "           -6.2817e-02,  2.8280e-02],\n",
       "          [ 3.4412e-01,  6.3272e-02,  2.3880e-01,  ..., -1.8446e-01,\n",
       "            1.2179e-01, -8.4601e-02],\n",
       "          [-1.5065e-01, -4.3008e-01, -1.1113e-01,  ...,  7.5814e-01,\n",
       "            1.2266e+00,  9.8193e-01],\n",
       "          ...,\n",
       "          [ 4.1027e-01,  2.4755e-01, -1.5709e-01,  ..., -1.2464e+00,\n",
       "            1.5532e+00,  4.6036e-01],\n",
       "          [ 8.6292e-01, -5.6355e-01, -1.5794e+00,  ..., -5.2638e-01,\n",
       "           -8.7164e-01,  9.4883e-01],\n",
       "          [-4.2069e-01, -9.6427e-01, -7.3563e-01,  ..., -3.4964e-01,\n",
       "            5.1742e-01,  2.2429e-03]],\n",
       "\n",
       "         [[ 4.3703e-02,  4.1349e-02, -4.6607e-02,  ..., -5.2753e-03,\n",
       "            2.6049e-02, -1.4039e-02],\n",
       "          [-1.1863e+00, -4.9043e-01, -8.4538e-01,  ...,  7.0891e-02,\n",
       "            5.7836e-01,  1.1824e+00],\n",
       "          [ 2.0825e-01, -9.5330e-01, -1.8999e+00,  ..., -1.2404e+00,\n",
       "            2.5756e-02,  2.7558e-01],\n",
       "          ...,\n",
       "          [-1.0455e+00,  6.5433e-01,  5.7882e-01,  ..., -9.7277e-01,\n",
       "           -5.3312e-02,  1.5403e+00],\n",
       "          [-7.4097e-01, -2.8068e-01,  1.3905e-02,  ...,  1.0292e+00,\n",
       "            9.4087e-01,  2.2867e+00],\n",
       "          [ 4.6626e-01, -1.1013e-01,  4.4848e-01,  ...,  9.5315e-01,\n",
       "            2.0062e-01,  1.5909e+00]],\n",
       "\n",
       "         [[ 2.7937e-02, -1.0101e-02, -8.8046e-02,  ..., -3.3484e-02,\n",
       "            1.5669e-02,  8.1894e-02],\n",
       "          [-1.3312e-01,  1.4344e-02,  1.1171e-01,  ...,  5.6314e-01,\n",
       "           -4.0119e-01, -5.4647e-01],\n",
       "          [ 3.2832e-01, -6.1403e-03,  6.9552e-02,  ..., -2.0345e-01,\n",
       "           -4.4770e-01, -5.1075e-01],\n",
       "          ...,\n",
       "          [ 7.2606e-01,  8.4635e-01, -3.0000e-01,  ...,  6.1791e-01,\n",
       "           -6.4972e-01, -3.6289e-01],\n",
       "          [ 8.0658e-01,  5.4656e-03, -3.5166e-01,  ...,  4.5220e-01,\n",
       "            7.2128e-02,  8.8538e-01],\n",
       "          [ 1.6563e+00, -1.9767e-01,  2.9180e-02,  ...,  1.2071e+00,\n",
       "           -1.4584e+00, -4.2443e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 1.0874e-01,  1.8389e-01,  1.0193e+00,  ...,  4.6635e-02,\n",
       "           -2.2522e-01,  3.6284e-02],\n",
       "          [ 2.9143e-01, -4.9614e-01, -2.6890e+00,  ..., -2.1722e-01,\n",
       "           -1.3805e-01,  1.2794e-01],\n",
       "          [ 8.7777e-01,  1.0055e+00, -3.6636e+00,  ...,  3.4719e-01,\n",
       "           -1.1756e+00,  8.2735e-01],\n",
       "          ...,\n",
       "          [ 1.5174e+00,  3.5026e-01, -4.2045e+00,  ...,  2.1285e-01,\n",
       "            6.3565e-01,  8.2629e-01],\n",
       "          [-4.5075e-01, -1.1839e-01, -2.7729e+00,  ...,  1.6484e+00,\n",
       "            4.4409e-01,  6.3382e-01],\n",
       "          [-2.1243e-01,  9.6009e-01, -4.0864e+00,  ...,  2.0669e+00,\n",
       "            6.4206e-01,  2.0428e+00]],\n",
       "\n",
       "         [[-7.7149e-01,  5.1157e-01, -1.6099e+00,  ..., -2.3006e+00,\n",
       "           -5.4389e-01,  8.1595e-01],\n",
       "          [-3.3153e-01,  1.2074e+00, -3.7760e-01,  ..., -2.1764e+00,\n",
       "           -4.8357e-01, -2.6591e-01],\n",
       "          [-3.5310e+00, -2.7900e-01, -1.9332e+00,  ..., -1.0789e+00,\n",
       "           -1.3626e+00, -4.4553e-01],\n",
       "          ...,\n",
       "          [-3.9808e-01,  1.6287e+00, -2.4353e+00,  ..., -4.3235e-03,\n",
       "           -1.0247e+00, -4.7724e+00],\n",
       "          [ 8.6174e-01,  2.0109e+00, -6.4232e-01,  ..., -1.2155e+00,\n",
       "           -4.6797e-01, -2.5684e+00],\n",
       "          [ 1.7666e-01,  1.0738e+00, -5.6509e-01,  ..., -2.8559e+00,\n",
       "           -8.9182e-01, -2.9722e-01]],\n",
       "\n",
       "         [[-5.0902e-01, -5.3156e-01,  9.5317e-01,  ..., -1.7506e-01,\n",
       "           -1.2538e-01,  1.0310e+00],\n",
       "          [-1.8332e+00, -1.0426e+00,  1.4655e+00,  ...,  5.3115e-02,\n",
       "            5.0838e-01,  4.0347e-01],\n",
       "          [-2.0248e+00, -2.3844e+00,  5.5791e-01,  ...,  6.8779e-01,\n",
       "            1.5647e+00, -1.5494e-02],\n",
       "          ...,\n",
       "          [-1.8019e+00, -3.3914e-01,  1.6698e-01,  ...,  2.8994e-01,\n",
       "            1.2488e+00,  3.9615e-01],\n",
       "          [-2.1635e+00,  2.2620e-01,  2.2336e-02,  ...,  5.7337e-01,\n",
       "           -5.7641e-01, -1.2419e+00],\n",
       "          [-2.0280e+00,  8.2950e-01, -1.7914e-01,  ..., -1.4437e-01,\n",
       "            1.6969e+00,  2.2229e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8556e-01,  4.2703e-01, -8.6056e-01,  ...,  2.6656e-01,\n",
       "           -4.8840e-01,  3.1175e-02],\n",
       "          [ 6.4395e-01,  1.6435e-01, -1.2710e+00,  ...,  8.3796e-01,\n",
       "            2.3671e-01,  2.5412e-01],\n",
       "          [-6.8666e-01, -5.2041e-01, -1.8134e+00,  ...,  1.2326e+00,\n",
       "           -1.1955e+00, -1.0968e+00],\n",
       "          ...,\n",
       "          [ 8.7584e-01, -1.6379e-01, -1.7560e+00,  ...,  3.9036e-01,\n",
       "           -8.9924e-01, -7.1185e-01],\n",
       "          [-6.2033e-01, -8.8180e-01, -1.3850e+00,  ..., -5.4423e-02,\n",
       "           -7.0478e-01, -5.5385e-01],\n",
       "          [ 4.3284e-01, -2.5743e-01, -1.7440e+00,  ...,  8.0787e-01,\n",
       "           -4.3844e-02, -6.6234e-01]],\n",
       "\n",
       "         [[ 1.2516e-01,  6.1914e-01,  1.3410e+00,  ...,  9.2514e-01,\n",
       "            1.5356e+00, -7.0168e-01],\n",
       "          [ 2.7340e-01, -2.0291e+00, -1.0041e+00,  ...,  6.5834e-01,\n",
       "            5.8322e+00,  4.6434e-01],\n",
       "          [-1.2661e+00, -1.9693e+00, -1.1413e+00,  ..., -2.7826e-01,\n",
       "            5.8139e+00,  8.1243e-02],\n",
       "          ...,\n",
       "          [-1.9898e+00, -3.1351e+00,  5.6346e-01,  ..., -6.2848e-01,\n",
       "            6.3899e+00, -1.6634e+00],\n",
       "          [ 1.1108e-01, -9.3099e-01, -2.9645e+00,  ...,  3.2250e-01,\n",
       "            4.8793e+00, -3.2853e+00],\n",
       "          [-1.3283e+00, -2.0163e-01,  7.7027e-01,  ...,  6.5159e-01,\n",
       "            4.6898e+00, -1.4378e+00]],\n",
       "\n",
       "         [[-2.6611e-01, -2.1940e-01, -1.1391e+00,  ..., -3.1984e-01,\n",
       "            2.7949e-01,  4.6469e-01],\n",
       "          [ 2.1926e+00,  8.0740e-02, -1.6612e+00,  ..., -1.0302e+00,\n",
       "           -8.4862e-01,  1.0482e+00],\n",
       "          [ 2.3070e+00, -1.4414e+00,  7.7608e-02,  ..., -5.3173e-01,\n",
       "            8.1261e-01,  4.6066e-01],\n",
       "          ...,\n",
       "          [ 4.1034e-01, -8.7688e-01, -1.4740e+00,  ..., -3.3917e-01,\n",
       "           -3.9109e-01, -3.5583e-01],\n",
       "          [ 9.7544e-01, -9.9794e-02, -1.5674e+00,  ..., -1.2777e+00,\n",
       "           -7.1173e-01,  2.3656e-01],\n",
       "          [-1.6620e+00,  3.3771e-01, -1.6524e+00,  ..., -2.5759e+00,\n",
       "            7.3895e-03,  1.1748e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 4.4692e-02, -4.0584e-03,  6.6773e-02,  ...,  7.8727e-03,\n",
       "           -7.7856e-03,  7.2658e-02],\n",
       "          [-1.6551e+00, -7.9695e-02,  1.4513e+00,  ...,  2.0109e-01,\n",
       "           -7.6315e-01,  1.9685e+00],\n",
       "          [ 1.0633e+00, -6.1166e-01,  4.7161e-01,  ..., -4.5897e-01,\n",
       "           -2.0824e+00, -1.0657e+00],\n",
       "          ...,\n",
       "          [ 1.1065e+00, -8.8451e-01,  4.9602e-01,  ...,  2.3969e+00,\n",
       "           -5.0033e-01, -9.9632e-02],\n",
       "          [-7.6170e-01, -1.4193e+00,  9.5962e-01,  ..., -1.5559e-01,\n",
       "           -6.5235e-01,  3.3319e-01],\n",
       "          [-1.5792e+00,  1.4165e+00,  5.0431e-01,  ...,  2.7363e-01,\n",
       "            9.3477e-03, -2.5392e-01]],\n",
       "\n",
       "         [[ 5.4476e-02,  3.2120e-02, -6.2721e-02,  ..., -6.4782e-02,\n",
       "            3.8699e-02,  5.8799e-02],\n",
       "          [-5.4794e-01,  1.0307e-01, -2.1461e-01,  ..., -1.4107e+00,\n",
       "           -5.9327e-01,  1.1738e+00],\n",
       "          [-3.6549e-02,  9.6039e-01,  2.4205e+00,  ...,  4.7175e-01,\n",
       "           -4.1942e-03,  2.2690e+00],\n",
       "          ...,\n",
       "          [-1.0731e+00,  1.2828e+00, -6.2660e-01,  ..., -1.9776e+00,\n",
       "            3.6193e-01, -1.2012e+00],\n",
       "          [-1.4562e+00,  2.3332e+00,  1.2880e+00,  ..., -2.1616e+00,\n",
       "           -6.3706e-01,  1.3956e+00],\n",
       "          [-1.1536e+00,  2.5179e+00, -1.5133e+00,  ..., -8.1750e-01,\n",
       "            8.5656e-01,  2.4651e-02]],\n",
       "\n",
       "         [[-2.4881e-02, -7.7688e-03,  8.7013e-04,  ..., -3.1985e-03,\n",
       "           -3.4064e-02, -1.8946e-02],\n",
       "          [-6.2227e-02,  9.1138e-01,  2.0892e+00,  ..., -1.2382e-01,\n",
       "            1.2320e+00, -6.6676e-01],\n",
       "          [-1.0436e-01,  4.5836e-01,  1.5438e-01,  ...,  7.2324e-01,\n",
       "            8.0155e-01, -3.1616e-01],\n",
       "          ...,\n",
       "          [ 3.6810e-02,  1.2414e+00,  4.9574e-01,  ...,  1.3034e+00,\n",
       "            4.0665e-01,  1.6818e+00],\n",
       "          [-2.9367e-01,  2.5864e-01,  1.4175e+00,  ...,  9.2654e-01,\n",
       "           -1.6897e+00, -2.6249e-01],\n",
       "          [-8.9574e-01,  1.3150e+00,  1.2860e+00,  ...,  1.7564e+00,\n",
       "            1.1760e+00,  1.5992e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.3718e-03, -2.5565e-02,  6.4037e-03,  ..., -1.9668e-02,\n",
       "           -1.1186e-02, -1.7252e-02],\n",
       "          [ 6.6825e-01, -2.2263e+00,  1.7279e+00,  ..., -2.4906e+00,\n",
       "            7.2990e-01,  6.3800e-02],\n",
       "          [-7.0158e-01, -9.2789e-01,  1.3755e+00,  ..., -6.9152e-01,\n",
       "           -4.8917e-01,  6.5973e-01],\n",
       "          ...,\n",
       "          [ 4.5228e-01,  9.2781e-01,  2.6122e+00,  ...,  1.2962e+00,\n",
       "            1.1674e+00, -8.7322e-01],\n",
       "          [-3.4647e-01,  3.2780e+00,  1.0785e+00,  ..., -2.4314e-01,\n",
       "            1.3976e+00, -1.5660e+00],\n",
       "          [ 2.3470e-01,  6.5495e-01,  4.9204e-01,  ...,  1.0653e+00,\n",
       "            9.0662e-01, -1.1704e+00]],\n",
       "\n",
       "         [[ 1.0133e-02,  2.2000e-02, -9.9150e-03,  ...,  4.6675e-03,\n",
       "            6.8947e-03, -3.2200e-02],\n",
       "          [ 2.6333e-02, -1.6369e-01,  4.8509e-01,  ...,  3.2809e-01,\n",
       "           -2.3533e-02,  3.6167e-01],\n",
       "          [-1.0099e-01,  9.7149e-02,  2.7539e-01,  ..., -6.1825e-01,\n",
       "            3.0551e-01, -3.4562e-01],\n",
       "          ...,\n",
       "          [-8.4075e-01,  8.9226e-01,  8.7810e-01,  ..., -1.5738e+00,\n",
       "           -3.0444e-03,  9.8414e-01],\n",
       "          [ 5.4014e-02, -6.9957e-02, -9.0237e-01,  ..., -1.4474e+00,\n",
       "            1.3681e+00, -6.8570e-01],\n",
       "          [-5.5525e-01, -2.5305e-01, -1.2359e+00,  ...,  7.7428e-01,\n",
       "            8.3185e-01,  3.6988e-01]],\n",
       "\n",
       "         [[-3.7012e-02,  1.2777e-01, -1.9829e-02,  ..., -4.1874e-02,\n",
       "           -9.5179e-02,  5.9243e-02],\n",
       "          [-3.5790e-02,  3.1946e-01,  4.2228e-01,  ...,  6.0002e-01,\n",
       "            2.7747e-01, -9.0393e-01],\n",
       "          [ 3.6298e-01,  2.6515e-01, -1.3019e+00,  ..., -4.9175e-01,\n",
       "            5.3668e-01, -1.5160e-01],\n",
       "          ...,\n",
       "          [ 1.0936e+00,  1.6572e-01, -4.4774e-01,  ...,  7.7523e-01,\n",
       "           -4.8838e-01, -4.5938e-01],\n",
       "          [ 1.0137e+00, -6.6858e-01,  2.8607e-02,  ...,  1.0932e+00,\n",
       "           -1.8571e-01, -3.4027e-01],\n",
       "          [ 2.5815e-01, -1.2028e+00, -3.4409e-01,  ...,  8.1948e-02,\n",
       "           -6.9466e-01, -7.4942e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-2.3155e-01, -1.6976e-01, -2.7319e-01,  ..., -3.1475e-01,\n",
       "           -3.1646e-02,  7.1908e-01],\n",
       "          [-5.5430e-01, -5.3188e-01,  1.2787e+00,  ..., -8.4018e-01,\n",
       "            1.0458e+00,  7.5230e-01],\n",
       "          [-2.6704e-02, -8.0913e-01,  3.4372e-01,  ...,  8.0559e-02,\n",
       "            5.6401e-01,  8.0520e-01],\n",
       "          ...,\n",
       "          [-2.3303e+00, -2.0866e+00, -3.3164e-01,  ...,  5.6049e-01,\n",
       "            1.2646e+00, -2.5011e-01],\n",
       "          [-1.3535e+00, -1.7435e+00,  5.7816e-01,  ...,  8.2260e-01,\n",
       "            1.5840e+00,  4.3481e-01],\n",
       "          [-1.2057e+00, -2.4784e+00,  1.2103e-01,  ...,  1.0312e+00,\n",
       "            1.8390e+00,  7.7124e-01]],\n",
       "\n",
       "         [[ 1.3065e+00, -2.7798e+00,  7.8962e-01,  ...,  1.2042e+00,\n",
       "            1.0844e+00, -8.6267e-02],\n",
       "          [-1.8493e+00, -1.7827e+00, -1.1585e+00,  ..., -2.8983e+00,\n",
       "           -2.1160e+00,  1.9492e+00],\n",
       "          [-2.9735e+00, -2.9697e-01,  8.2768e-01,  ..., -2.2034e+00,\n",
       "           -2.8852e+00,  3.6963e+00],\n",
       "          ...,\n",
       "          [-2.8309e+00,  1.5889e-03, -3.6363e-01,  ..., -4.0888e+00,\n",
       "           -2.6388e+00,  2.4359e+00],\n",
       "          [-2.9543e+00,  4.8883e-02,  5.4029e-01,  ..., -2.3067e+00,\n",
       "           -2.9217e+00,  2.2393e+00],\n",
       "          [-2.3484e+00, -1.3019e+00, -2.8115e-01,  ..., -2.2763e+00,\n",
       "           -2.1000e+00,  2.1932e+00]],\n",
       "\n",
       "         [[-1.0825e+00,  2.0365e+00,  8.7235e-01,  ..., -1.7629e+00,\n",
       "            2.3171e+00,  1.2080e+00],\n",
       "          [-8.5467e-01,  7.3287e-01,  4.0586e-01,  ...,  3.7843e-01,\n",
       "           -2.2415e+00, -1.8002e-01],\n",
       "          [-1.3117e+00,  4.0338e-01, -2.7395e-01,  ...,  2.5100e+00,\n",
       "           -5.4472e+00, -5.4500e-01],\n",
       "          ...,\n",
       "          [-6.8345e-01, -3.1644e-01, -1.7110e-01,  ...,  1.6351e-01,\n",
       "           -5.3900e+00,  3.8943e-01],\n",
       "          [-1.0484e+00, -3.5764e-01,  1.6562e+00,  ...,  8.9184e-01,\n",
       "           -2.3508e+00, -6.2366e-01],\n",
       "          [ 3.1108e-01, -2.0108e-01, -5.6893e-02,  ...,  4.1867e-01,\n",
       "           -4.9480e+00,  1.5198e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2358e-01, -2.5186e-01, -1.1738e+00,  ..., -1.0090e+00,\n",
       "            8.2643e-01,  1.2156e+00],\n",
       "          [ 2.5663e+00, -1.4480e+00,  3.1674e-01,  ...,  1.5112e-01,\n",
       "            5.3369e-01,  1.5360e+00],\n",
       "          [ 3.0187e+00, -2.3081e+00,  3.8802e-02,  ...,  7.4695e-01,\n",
       "            1.3213e+00,  1.4319e+00],\n",
       "          ...,\n",
       "          [ 2.0246e+00, -1.0764e+00,  2.1282e-01,  ..., -1.1903e+00,\n",
       "            1.6431e+00,  2.2123e+00],\n",
       "          [ 2.3069e+00, -1.5369e+00,  6.5898e-01,  ..., -7.3566e-01,\n",
       "            3.0937e+00,  2.0842e+00],\n",
       "          [ 1.8059e+00, -1.2318e+00,  4.2971e-01,  ..., -1.5387e+00,\n",
       "            2.4817e+00,  2.6888e+00]],\n",
       "\n",
       "         [[-1.5288e-01,  9.2661e-02, -6.8307e-01,  ..., -7.0446e-01,\n",
       "            7.9165e-02, -6.1915e-01],\n",
       "          [-3.0322e+00, -6.6184e-01, -1.0477e+00,  ..., -1.1929e+00,\n",
       "            1.1339e+00,  4.7889e-01],\n",
       "          [-2.3522e+00, -1.7947e-01, -1.4928e+00,  ..., -1.3959e+00,\n",
       "            3.0019e-01,  1.7876e-02],\n",
       "          ...,\n",
       "          [-1.3439e+00, -1.8798e+00, -1.2231e+00,  ..., -9.4479e-01,\n",
       "           -3.3931e-01, -7.8487e-01],\n",
       "          [-1.4327e+00, -3.1124e-01, -6.1963e-01,  ..., -2.2864e-01,\n",
       "            9.9634e-01, -7.0179e-01],\n",
       "          [-4.5415e-01,  9.9834e-02, -7.7920e-01,  ..., -5.3774e-01,\n",
       "            1.0147e+00,  8.1363e-01]],\n",
       "\n",
       "         [[ 2.7354e-01,  8.5935e-01, -3.0232e-01,  ...,  1.4097e-01,\n",
       "            5.2536e-01,  1.8811e-01],\n",
       "          [ 5.3589e-01,  2.2476e+00, -9.6388e-03,  ..., -2.5385e-01,\n",
       "           -3.0309e-01, -1.7260e-01],\n",
       "          [ 2.3928e+00,  9.4140e-01,  8.5935e-01,  ..., -4.9057e-01,\n",
       "           -4.0004e-01, -8.9248e-01],\n",
       "          ...,\n",
       "          [-1.8602e-01,  5.1356e-01, -1.6676e+00,  ..., -1.7655e+00,\n",
       "           -4.5581e-01,  3.2594e-01],\n",
       "          [-3.2768e-02,  1.4452e+00,  1.6467e-01,  ...,  5.2025e-01,\n",
       "           -2.7676e-01, -5.7344e-01],\n",
       "          [-5.0837e-01,  1.0522e+00,  8.9861e-02,  ..., -5.1165e-02,\n",
       "            4.9688e-01, -1.3875e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 1.8781e-02,  8.2070e-04,  2.0853e-03,  ..., -6.1397e-02,\n",
       "           -3.4401e-02, -1.9900e-02],\n",
       "          [-2.2937e+00,  1.5562e+00, -1.3975e+00,  ...,  2.4157e-01,\n",
       "            7.8944e-01,  1.4800e+00],\n",
       "          [-1.4254e-01,  5.0630e-01,  1.2550e+00,  ...,  3.5517e-01,\n",
       "           -1.1748e+00,  1.0744e+00],\n",
       "          ...,\n",
       "          [ 1.2722e+00,  1.5255e+00, -7.0394e-01,  ..., -1.4458e+00,\n",
       "           -9.6761e-01,  1.1792e+00],\n",
       "          [-1.0762e-01,  1.3526e+00,  3.1500e-01,  ..., -2.0654e+00,\n",
       "            2.9270e+00, -7.7337e-01],\n",
       "          [ 2.5588e-01, -2.9798e-01,  6.1836e-01,  ..., -8.0210e-01,\n",
       "           -7.3179e-01,  8.6025e-01]],\n",
       "\n",
       "         [[-1.5030e-01, -2.3203e-02,  3.1464e-02,  ..., -5.6096e-02,\n",
       "            5.1047e-04,  7.6647e-02],\n",
       "          [-1.7727e+00,  3.8047e-01,  6.9032e-01,  ..., -9.3036e-02,\n",
       "            3.3536e-01,  4.2028e-01],\n",
       "          [-2.0881e+00, -2.7502e+00,  2.7822e-03,  ...,  1.3171e-01,\n",
       "            2.7406e+00, -9.8534e-01],\n",
       "          ...,\n",
       "          [ 6.8033e-01,  2.6024e+00,  9.6677e-01,  ..., -8.5839e-01,\n",
       "           -6.0554e-01, -9.4555e-01],\n",
       "          [-8.3406e-01,  4.3483e-01,  6.1066e-01,  ..., -5.6956e-02,\n",
       "            8.4723e-01, -5.3871e-01],\n",
       "          [ 8.6099e-01, -1.5578e-01,  1.4827e+00,  ..., -2.6179e-01,\n",
       "            1.4125e-01, -7.3516e-01]],\n",
       "\n",
       "         [[-7.4557e-02, -9.5394e-02,  2.1511e-01,  ..., -3.8806e-02,\n",
       "            4.7638e-03,  3.8401e-02],\n",
       "          [ 1.0924e+00, -2.2047e+00,  2.8009e+00,  ..., -5.9690e-01,\n",
       "           -9.8553e-01, -6.3108e-01],\n",
       "          [ 7.4192e-01, -5.5976e-01,  2.6289e+00,  ..., -1.8460e-01,\n",
       "           -1.8185e-01, -6.4851e-01],\n",
       "          ...,\n",
       "          [ 1.3909e-01, -9.3230e-01,  1.9025e+00,  ...,  4.2991e-01,\n",
       "            1.7662e-01,  4.8561e-01],\n",
       "          [ 1.3219e-01,  2.8605e-01,  3.6445e-01,  ...,  6.8009e-01,\n",
       "            2.2750e-02, -1.3695e+00],\n",
       "          [-4.8323e-01, -1.6980e+00,  3.2885e-01,  ..., -9.2880e-01,\n",
       "            2.8809e-01, -8.6660e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4070e-02,  2.7242e-02,  3.4874e-02,  ...,  1.4133e-02,\n",
       "           -7.9143e-02,  1.1040e-02],\n",
       "          [ 3.7383e-01,  1.1138e+00,  1.2042e+00,  ...,  1.6470e-01,\n",
       "           -2.6470e-01,  9.7229e-01],\n",
       "          [-2.6265e-01,  2.7638e-01,  1.2987e-01,  ..., -7.2376e-01,\n",
       "           -3.1979e-01,  4.1051e-01],\n",
       "          ...,\n",
       "          [ 5.1036e-01,  1.9074e+00,  7.3005e-01,  ...,  4.3747e-01,\n",
       "           -5.2265e-02,  7.4791e-01],\n",
       "          [-6.2286e-02,  8.3596e-01,  2.9987e-01,  ...,  1.0360e+00,\n",
       "           -2.1664e-01,  1.1903e+00],\n",
       "          [ 8.4043e-01,  1.1299e+00,  7.3526e-01,  ...,  7.3504e-01,\n",
       "           -4.7996e-01,  2.0017e-01]],\n",
       "\n",
       "         [[ 3.1539e-02,  4.3856e-02, -3.0721e-02,  ...,  5.9116e-02,\n",
       "            2.9610e-03,  7.5403e-02],\n",
       "          [-2.3912e-01,  2.7732e-02,  1.0704e+00,  ..., -5.6112e-01,\n",
       "            1.7960e-01,  1.1698e+00],\n",
       "          [ 1.4557e-01,  2.3514e-02, -1.4567e+00,  ...,  6.0989e-01,\n",
       "            5.2776e-01,  8.0539e-01],\n",
       "          ...,\n",
       "          [-1.4412e+00,  1.3294e+00, -2.2803e+00,  ...,  1.5842e+00,\n",
       "            1.2767e+00,  5.4718e-01],\n",
       "          [-2.7018e-01,  1.0311e+00, -3.5875e-01,  ...,  7.8242e-01,\n",
       "            5.0567e-01,  8.4399e-02],\n",
       "          [ 1.6626e+00,  1.7909e+00, -9.8912e-01,  ...,  3.5648e-01,\n",
       "           -5.8557e-02,  8.7253e-01]],\n",
       "\n",
       "         [[-1.2331e-02, -1.8096e-02,  1.5414e-02,  ...,  4.1068e-02,\n",
       "           -1.3926e-03,  5.0027e-03],\n",
       "          [-1.8715e+00,  2.0233e-01, -1.4189e+00,  ...,  1.5763e+00,\n",
       "           -5.6361e-01, -4.1971e-01],\n",
       "          [-2.9628e+00,  1.5733e+00, -2.7223e+00,  ..., -1.6052e+00,\n",
       "           -5.3776e-01,  1.0923e+00],\n",
       "          ...,\n",
       "          [ 6.7497e-01, -2.3299e+00, -5.8270e-01,  ...,  6.2148e-02,\n",
       "           -9.3275e-01,  1.8886e+00],\n",
       "          [ 1.3311e+00, -2.1383e+00, -4.3944e-01,  ..., -1.2760e+00,\n",
       "           -2.7667e+00,  4.6491e-01],\n",
       "          [ 3.7334e-01, -3.1809e+00, -2.5651e-01,  ..., -3.6698e-01,\n",
       "           -4.4080e-01,  1.0664e+00]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 4.1165,  0.1884, -0.1354,  ...,  0.4870, -0.0291, -0.3337],\n",
       "          [-3.1314, -0.5952,  0.0652,  ...,  2.1607, -1.3426,  0.4821],\n",
       "          [-3.2372, -0.4420, -0.8493,  ...,  1.1627, -1.5204,  1.0765],\n",
       "          ...,\n",
       "          [-2.5439,  0.0951, -1.3982,  ...,  1.3416, -2.6220,  0.7854],\n",
       "          [-1.3238,  0.6995, -0.5454,  ...,  2.6468, -0.1057,  1.9977],\n",
       "          [-2.1186,  0.2305,  0.0479,  ...,  1.2798, -1.7688,  1.5484]],\n",
       "\n",
       "         [[ 0.3608,  0.7604, -0.5615,  ...,  0.5717,  0.4021,  0.3574],\n",
       "          [ 1.7380,  0.2915,  0.2039,  ...,  0.6333, -0.8106, -0.1127],\n",
       "          [ 0.2818,  0.5534, -1.4997,  ..., -0.0042, -0.6501,  1.0392],\n",
       "          ...,\n",
       "          [ 2.1648,  0.1765, -1.3629,  ...,  0.4718,  1.1455,  0.4654],\n",
       "          [ 1.4719,  0.7920, -1.2500,  ...,  0.6923,  1.4185, -0.0546],\n",
       "          [ 0.4536,  0.9402, -0.7474,  ...,  0.8974,  1.9800, -1.8635]],\n",
       "\n",
       "         [[-1.8273, -1.2509,  0.2355,  ..., -1.1978, -0.2933,  1.4138],\n",
       "          [-0.2034, -1.5921,  0.9002,  ...,  0.0953, -0.0903,  0.1989],\n",
       "          [ 0.4325, -0.5284,  1.2690,  ..., -0.3746, -0.3294,  1.0166],\n",
       "          ...,\n",
       "          [ 2.1771, -0.1286,  1.7397,  ...,  0.2671, -1.8188,  1.8358],\n",
       "          [ 1.4512, -0.1921, -0.1408,  ...,  0.8369, -0.1745, -0.5059],\n",
       "          [ 1.7190,  0.0552,  0.3183,  ..., -1.1053, -0.1515,  1.6833]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2010,  0.5214, -0.1202,  ...,  0.2939,  0.0447, -0.0538],\n",
       "          [ 0.8595,  0.7783,  0.5989,  ...,  0.3374,  1.8510, -1.3119],\n",
       "          [ 2.6472, -0.6212, -0.4434,  ..., -0.6777,  0.5983,  1.1707],\n",
       "          ...,\n",
       "          [-1.2549,  0.1208, -0.6367,  ..., -0.5757,  0.1839, -0.3916],\n",
       "          [-0.9088, -0.0268,  1.3863,  ..., -1.7334,  0.5401, -1.7469],\n",
       "          [-0.1539,  0.2096, -0.2904,  ..., -1.6199,  2.5729,  1.4094]],\n",
       "\n",
       "         [[ 0.1542,  0.2425, -0.5417,  ..., -0.4031,  0.5370, -0.0347],\n",
       "          [ 1.0136, -1.7024, -0.6927,  ...,  0.6892,  1.5684, -0.3883],\n",
       "          [-0.6692,  0.7925, -1.0440,  ..., -0.6189,  2.6284,  0.2150],\n",
       "          ...,\n",
       "          [-0.6137, -1.2912, -0.9552,  ...,  0.2096,  1.6425, -2.5607],\n",
       "          [ 0.9470, -0.9938, -1.1914,  ...,  0.8701,  1.4327, -1.4556],\n",
       "          [ 1.2837, -1.2092, -1.2179,  ...,  3.1538,  2.1576,  0.2210]],\n",
       "\n",
       "         [[ 0.5844, -0.8429, -1.6183,  ...,  0.6886, -0.2667, -0.8960],\n",
       "          [-0.0132, -1.1647, -0.6941,  ...,  1.2870,  0.3182, -2.3175],\n",
       "          [ 0.1036,  0.3466,  0.5381,  ...,  0.8447,  1.2052, -3.4693],\n",
       "          ...,\n",
       "          [ 1.1721, -1.7919,  1.0532,  ...,  2.1015,  0.3504,  1.3365],\n",
       "          [-1.3602, -0.1707, -0.0529,  ...,  2.0300, -0.3559, -1.7625],\n",
       "          [-1.4331,  0.2422,  0.4091,  ...,  0.4741, -1.7075, -1.9701]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 4.6965e-02, -2.5188e-02, -2.4338e-02,  ..., -2.3930e-02,\n",
       "           -3.4114e-02,  1.4056e-02],\n",
       "          [ 8.2625e-01,  6.9380e-01, -8.6718e-01,  ...,  7.3889e-01,\n",
       "            2.3995e-01, -1.9545e+00],\n",
       "          [-3.0643e-02,  1.4677e-01,  1.2175e-01,  ...,  6.8463e-01,\n",
       "            5.1346e-01, -1.8021e+00],\n",
       "          ...,\n",
       "          [-1.4585e+00, -8.9990e-01, -2.8260e+00,  ...,  1.2542e+00,\n",
       "           -8.1315e-01,  5.4804e-01],\n",
       "          [-2.2061e+00, -1.6547e+00, -2.2325e-01,  ...,  1.4503e+00,\n",
       "            1.2785e-01,  1.9523e-01],\n",
       "          [-1.3202e+00, -1.0856e+00, -1.3387e+00,  ...,  2.4038e-01,\n",
       "            6.5438e-02,  7.7423e-01]],\n",
       "\n",
       "         [[-1.2132e-02,  6.9857e-04,  2.3733e-02,  ...,  7.0280e-02,\n",
       "            4.9146e-02,  1.3465e-02],\n",
       "          [ 7.2122e-01, -1.1949e+00,  1.0259e+00,  ...,  1.1624e+00,\n",
       "           -1.3238e-01,  1.4567e-02],\n",
       "          [ 1.1936e-01, -9.4019e-01,  6.1919e-01,  ...,  9.9921e-01,\n",
       "           -7.3441e-01,  2.5669e-01],\n",
       "          ...,\n",
       "          [ 1.0969e+00, -1.7246e+00,  4.1811e-01,  ...,  7.6057e-01,\n",
       "            2.5263e-01, -1.5781e-02],\n",
       "          [-1.5091e+00, -7.6464e-01, -3.8236e-01,  ...,  1.0399e+00,\n",
       "           -8.5594e-01, -3.6625e-01],\n",
       "          [ 1.2597e+00, -2.8870e-01, -7.5116e-01,  ...,  1.5437e+00,\n",
       "           -1.5708e-01,  6.5103e-01]],\n",
       "\n",
       "         [[-2.2287e-02, -6.5978e-02,  2.7241e-02,  ...,  1.1398e-03,\n",
       "            4.3731e-03,  2.0222e-03],\n",
       "          [-9.9155e-01,  1.4038e-01,  6.7499e-01,  ..., -2.7707e+00,\n",
       "            1.5255e-02,  2.5016e-01],\n",
       "          [-5.5319e-01, -3.2071e+00,  2.0970e-01,  ..., -4.1438e-01,\n",
       "           -1.0999e+00, -7.7339e-01],\n",
       "          ...,\n",
       "          [ 5.9590e-01,  5.8876e-01, -2.7115e-01,  ..., -8.8427e-01,\n",
       "            6.3060e-02, -1.2291e+00],\n",
       "          [-2.2833e+00, -2.1812e-01,  1.9442e+00,  ...,  1.5965e-01,\n",
       "            1.0293e+00,  1.0400e+00],\n",
       "          [-1.0075e+00,  4.4155e-01, -1.3001e-01,  ..., -2.1465e-01,\n",
       "           -1.7182e+00, -1.3494e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7057e-03, -2.8445e-02,  2.2825e-03,  ...,  8.3927e-03,\n",
       "            3.2488e-02,  3.0580e-02],\n",
       "          [-4.1707e-01,  6.9560e-01, -1.4024e-01,  ..., -1.0204e+00,\n",
       "           -2.0606e+00, -3.0317e-01],\n",
       "          [-5.5863e-01,  2.2119e-01, -1.0166e+00,  ..., -4.4448e-01,\n",
       "           -9.2919e-01, -2.1112e-01],\n",
       "          ...,\n",
       "          [-2.1827e+00,  1.3231e+00,  8.7528e-02,  ...,  1.2528e+00,\n",
       "           -1.8450e+00, -2.1916e-01],\n",
       "          [ 5.8407e-01, -1.0625e+00,  6.6666e-02,  ..., -1.2720e+00,\n",
       "            7.6617e-01,  3.2358e-01],\n",
       "          [-1.6166e-01,  9.8383e-01,  5.2951e-01,  ..., -1.3953e-01,\n",
       "           -1.4106e+00,  4.9164e-01]],\n",
       "\n",
       "         [[ 3.1021e-02,  4.1347e-02, -3.7333e-02,  ...,  8.2819e-03,\n",
       "            1.1129e-01,  1.1687e-02],\n",
       "          [-1.4094e-01,  7.2597e-01, -6.8680e-03,  ...,  1.0248e+00,\n",
       "           -6.8426e-01, -1.9631e-01],\n",
       "          [ 1.7846e-01,  9.8345e-01,  8.7966e-01,  ..., -3.0178e-01,\n",
       "           -6.7142e-02, -5.3630e-01],\n",
       "          ...,\n",
       "          [-5.1603e-01,  2.9424e+00,  1.1126e-01,  ...,  4.6121e-01,\n",
       "           -1.4065e+00,  5.2596e-01],\n",
       "          [-1.1793e+00,  1.4231e+00,  3.6725e-01,  ..., -2.7117e-01,\n",
       "           -3.5321e-01,  1.0936e+00],\n",
       "          [-1.2785e+00,  5.3407e-01, -1.9008e-01,  ..., -5.1953e-01,\n",
       "            2.6358e+00,  1.0152e+00]],\n",
       "\n",
       "         [[ 7.0426e-03,  2.5959e-01, -3.1172e-02,  ..., -1.3890e-02,\n",
       "            2.2816e-02,  1.6540e-02],\n",
       "          [-1.3587e-01, -3.2419e+00,  8.1443e-01,  ..., -8.1447e-02,\n",
       "            1.3811e+00,  3.0634e+00],\n",
       "          [-1.0057e+00,  2.9603e-01, -1.4635e+00,  ...,  3.6034e-01,\n",
       "            2.2722e+00, -4.9406e-01],\n",
       "          ...,\n",
       "          [ 5.1998e-01,  1.0114e+00, -1.5805e-01,  ...,  1.3506e+00,\n",
       "           -4.1639e-01,  1.0423e+00],\n",
       "          [ 1.5215e+00,  1.3364e+00, -1.0497e+00,  ..., -4.7918e-02,\n",
       "           -3.0583e-01,  5.8098e-01],\n",
       "          [-1.3365e+00,  2.8463e+00, -2.9058e-01,  ...,  2.0979e+00,\n",
       "           -6.2529e-01,  8.8912e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-2.9506e-02,  2.8565e-03, -9.4808e-02,  ...,  4.9915e-02,\n",
       "            3.4641e-01,  2.1305e-01],\n",
       "          [ 3.7824e-01, -1.6410e+00,  2.8564e-01,  ...,  6.6299e-01,\n",
       "            3.0290e-01, -7.8839e-01],\n",
       "          [ 1.0459e-01, -3.4854e+00,  5.5674e-03,  ...,  2.1368e-01,\n",
       "            1.2026e+00, -2.3463e-01],\n",
       "          ...,\n",
       "          [ 1.0408e+00, -1.2164e+00,  1.1121e+00,  ..., -5.2915e-01,\n",
       "            1.1038e+00,  8.4716e-01],\n",
       "          [-2.6707e-01, -6.3125e-01,  6.8357e-02,  ..., -2.0565e-01,\n",
       "           -1.3255e-01, -4.5179e-01],\n",
       "          [-6.4078e-01, -2.5579e+00,  1.9637e-01,  ...,  6.0793e-01,\n",
       "            1.0093e+00, -7.8986e-01]],\n",
       "\n",
       "         [[-1.5333e+00, -2.4647e-01,  1.2535e+00,  ..., -5.3648e-01,\n",
       "            2.0026e+00,  9.3150e-01],\n",
       "          [-5.0701e-01,  6.5962e-01,  1.7769e+00,  ..., -2.6254e-01,\n",
       "            1.3714e+00,  1.5734e+00],\n",
       "          [-2.0423e-01,  8.6747e-01,  1.5061e+00,  ..., -2.5686e-02,\n",
       "            1.4132e+00,  1.3734e+00],\n",
       "          ...,\n",
       "          [-1.2892e+00,  2.1718e+00, -8.5100e-01,  ..., -1.6948e-01,\n",
       "            2.3190e+00,  5.6047e-01],\n",
       "          [-9.1811e-01,  2.1333e+00, -7.2892e-01,  ...,  3.3160e-01,\n",
       "            1.5800e+00,  2.7266e-01],\n",
       "          [-1.0456e+00,  4.1572e-01, -8.6382e-01,  ...,  1.9212e-01,\n",
       "            1.0886e+00,  1.1367e+00]],\n",
       "\n",
       "         [[ 3.2468e-01,  2.8413e-01,  4.4554e-01,  ...,  1.5976e-01,\n",
       "           -2.6162e-01, -4.5751e-01],\n",
       "          [-1.6519e-01,  1.4483e+00, -1.5692e+00,  ...,  1.8907e+00,\n",
       "           -1.8196e+00,  8.3077e-02],\n",
       "          [-4.1919e-01,  3.9490e-01,  6.2752e-01,  ...,  6.0227e-01,\n",
       "           -1.4676e+00, -2.9231e-01],\n",
       "          ...,\n",
       "          [ 4.8544e-01,  2.0406e+00, -5.9993e-03,  ...,  1.3924e+00,\n",
       "           -5.9060e-02, -1.2621e+00],\n",
       "          [ 1.8968e+00,  3.9783e-02,  9.8649e-01,  ..., -1.2055e+00,\n",
       "           -7.0142e-03,  1.0986e+00],\n",
       "          [ 9.1953e-01,  9.5406e-01, -6.8299e-01,  ...,  1.1049e+00,\n",
       "           -3.5124e-01,  1.9427e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1725e+00, -3.9233e-01,  8.0837e-01,  ...,  4.9047e+00,\n",
       "           -4.9977e-01, -1.1683e+00],\n",
       "          [ 1.8867e+00,  8.0481e-01,  9.4530e-01,  ..., -5.0776e+00,\n",
       "           -6.4504e-01,  5.4079e-01],\n",
       "          [ 2.4140e+00,  6.7329e-01, -9.9201e-02,  ..., -5.3377e+00,\n",
       "           -1.7132e+00,  9.2841e-01],\n",
       "          ...,\n",
       "          [ 1.3684e+00,  9.1630e-01,  1.3323e+00,  ..., -6.4638e+00,\n",
       "           -1.4129e+00,  7.0827e-01],\n",
       "          [ 2.0754e+00, -4.4753e-01,  1.0105e+00,  ..., -5.5185e+00,\n",
       "           -1.6468e+00, -6.7090e-01],\n",
       "          [ 3.3426e+00,  8.9618e-01,  1.6204e+00,  ..., -5.3015e+00,\n",
       "           -1.2719e+00,  3.7161e-01]],\n",
       "\n",
       "         [[ 1.4397e-02, -2.2754e-01,  7.3494e-02,  ..., -6.7132e-02,\n",
       "           -2.3537e-01,  2.0014e-01],\n",
       "          [ 1.0809e+00, -1.1243e+00,  3.6995e-01,  ..., -9.3517e-01,\n",
       "           -1.1423e+00,  1.2432e+00],\n",
       "          [ 1.3627e+00,  1.9071e-01,  7.8148e-01,  ..., -1.9987e+00,\n",
       "           -1.1641e+00, -4.2560e-01],\n",
       "          ...,\n",
       "          [ 2.2236e+00, -1.1179e+00,  1.7754e+00,  ..., -2.0379e+00,\n",
       "           -5.1244e-01, -8.6903e-01],\n",
       "          [-3.7036e-01, -6.9570e-01,  6.8480e-01,  ...,  1.3433e-01,\n",
       "           -6.1115e-01,  2.2459e+00],\n",
       "          [ 8.4208e-01, -4.4964e-02, -1.6103e-01,  ..., -1.0247e+00,\n",
       "           -1.4677e+00,  1.2164e+00]],\n",
       "\n",
       "         [[-6.3300e-01,  3.7918e-01, -1.6612e+00,  ...,  2.0535e+00,\n",
       "            1.6990e+00,  3.9835e+00],\n",
       "          [ 1.3592e+00,  3.5819e-02, -1.2517e+00,  ...,  1.2627e+00,\n",
       "            1.0330e+00,  2.2872e+00],\n",
       "          [ 4.7887e-01,  2.0052e-01, -1.8474e+00,  ...,  6.6009e-01,\n",
       "            5.3511e-01,  1.6818e+00],\n",
       "          ...,\n",
       "          [ 7.5350e-01, -8.6778e-02, -3.6639e+00,  ...,  3.7329e+00,\n",
       "            1.8463e+00,  2.2520e+00],\n",
       "          [ 1.8941e+00, -2.6872e-01, -1.1740e+00,  ...,  2.9588e+00,\n",
       "            2.1386e+00,  1.7953e+00],\n",
       "          [ 1.2649e+00, -7.1689e-01, -1.2314e+00,  ...,  3.7923e+00,\n",
       "            5.8293e-01,  1.7601e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[-1.2625e-01,  2.8493e-02,  2.0844e-02,  ..., -3.8569e-02,\n",
       "            2.1802e-01, -6.1277e-02],\n",
       "          [ 1.6773e+00,  9.4475e-01, -1.6017e+00,  ...,  4.8613e-01,\n",
       "           -1.2809e-01,  9.6241e-01],\n",
       "          [ 4.3297e-01,  2.1036e+00,  1.7865e+00,  ...,  3.5723e-01,\n",
       "            9.0841e-02,  1.1212e-01],\n",
       "          ...,\n",
       "          [ 4.5442e-01,  2.3145e-01,  1.9556e-01,  ..., -1.1333e+00,\n",
       "           -5.5342e-01,  7.9612e-01],\n",
       "          [ 9.6720e-01,  1.2587e+00, -2.3912e-01,  ...,  3.1425e-01,\n",
       "           -7.6679e-02, -2.3695e-01],\n",
       "          [ 8.8466e-03,  9.6004e-03,  2.9858e-01,  ...,  3.1239e-01,\n",
       "           -1.0896e+00,  4.2296e-01]],\n",
       "\n",
       "         [[-2.6336e-02,  2.4562e-02, -1.7279e-01,  ...,  2.4048e-02,\n",
       "            9.2561e-03,  1.8000e-01],\n",
       "          [ 4.2226e-01, -9.5142e-01,  7.5684e-02,  ...,  5.9562e-01,\n",
       "            2.0307e-01,  1.8474e+00],\n",
       "          [-2.4602e-01,  4.7711e-01,  6.6684e-01,  ...,  2.0068e+00,\n",
       "           -8.1675e-01,  1.2955e+00],\n",
       "          ...,\n",
       "          [ 7.6140e-01, -1.9257e-01, -1.0839e-01,  ..., -3.4205e-01,\n",
       "           -1.8928e+00,  1.4968e+00],\n",
       "          [-3.1665e-01, -9.3503e-01,  3.9917e-01,  ..., -9.4477e-01,\n",
       "           -1.0893e+00,  2.5537e+00],\n",
       "          [ 5.1619e-01, -5.9406e-01,  1.9553e-01,  ...,  5.5315e-01,\n",
       "           -9.3292e-01,  2.8410e+00]],\n",
       "\n",
       "         [[-1.7455e-02, -3.2298e-02, -5.4231e-02,  ..., -5.3910e-03,\n",
       "           -1.6458e-02,  2.0739e-03],\n",
       "          [-1.3502e+00,  7.8608e-01, -6.9100e-01,  ..., -5.7151e-01,\n",
       "           -1.9076e-01,  1.3500e+00],\n",
       "          [ 3.6800e-01,  1.8800e+00, -1.7670e+00,  ...,  3.3269e-01,\n",
       "           -6.1620e-01, -1.1672e+00],\n",
       "          ...,\n",
       "          [-4.8931e-01, -1.4146e-01, -5.2856e-01,  ...,  4.9991e-01,\n",
       "            1.0010e+00, -6.0204e-01],\n",
       "          [ 4.0424e-01,  1.6825e+00,  7.8934e-01,  ..., -6.0055e-01,\n",
       "           -1.0887e+00,  1.7647e-01],\n",
       "          [-1.7763e+00, -1.2610e+00, -8.2781e-01,  ...,  2.2125e-01,\n",
       "            7.3210e-01,  6.7047e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4159e-02, -3.9881e-02, -1.2366e-02,  ..., -1.6226e-02,\n",
       "            4.2214e-02, -7.5445e-03],\n",
       "          [-1.8119e-01, -3.7116e-01, -1.4082e-01,  ...,  8.3846e-01,\n",
       "           -5.1024e-01, -1.6391e+00],\n",
       "          [-1.6329e-01, -6.6709e-01, -1.0378e+00,  ...,  3.8555e-01,\n",
       "           -5.6172e-01, -1.5248e+00],\n",
       "          ...,\n",
       "          [-5.2618e-01, -4.6086e-01, -7.2178e-01,  ...,  2.0769e-01,\n",
       "            3.5502e-01, -9.9407e-01],\n",
       "          [-5.2016e-01, -4.7826e-01, -5.9923e-01,  ...,  4.1649e-01,\n",
       "            2.5285e-01, -2.0242e-01],\n",
       "          [ 1.5746e-01, -5.4891e-01, -8.0429e-01,  ...,  8.0583e-01,\n",
       "           -3.2065e-01, -1.0474e+00]],\n",
       "\n",
       "         [[-1.0684e-03, -5.0511e-03, -1.3846e-02,  ...,  8.2823e-03,\n",
       "           -3.3046e-02, -5.8528e-04],\n",
       "          [-2.2702e-01,  6.6016e-01,  2.5187e-01,  ..., -6.1637e-01,\n",
       "            1.3121e+00, -2.5474e-01],\n",
       "          [-7.5910e-01, -6.2438e-02,  8.4471e-01,  ..., -3.4478e-01,\n",
       "           -1.4686e+00, -2.1768e-01],\n",
       "          ...,\n",
       "          [-7.4651e-01,  1.6836e-01,  6.0824e-01,  ..., -8.9791e-01,\n",
       "           -5.7202e-01, -1.2371e-01],\n",
       "          [-9.7483e-01,  2.3282e+00, -2.5489e-01,  ..., -6.2667e-02,\n",
       "            2.3736e-01, -3.7700e-01],\n",
       "          [ 8.7898e-01,  1.1269e+00, -1.0013e+00,  ...,  8.2985e-01,\n",
       "            3.0527e-02, -3.7186e-01]],\n",
       "\n",
       "         [[ 1.9064e-02,  9.0633e-03, -4.4499e-03,  ..., -4.8078e-02,\n",
       "           -1.2815e-02, -9.8025e-03],\n",
       "          [ 1.9223e-02,  5.9522e-01, -1.9149e+00,  ...,  4.6769e-01,\n",
       "            3.1243e-01,  6.5645e-01],\n",
       "          [ 5.1379e-01,  5.7516e-01, -1.1754e+00,  ...,  7.1741e-01,\n",
       "            6.0595e-01, -4.8345e-01],\n",
       "          ...,\n",
       "          [ 3.0491e-01,  8.5286e-01, -3.9696e-01,  ...,  1.0090e+00,\n",
       "           -6.2306e-01,  8.6965e-01],\n",
       "          [ 2.6251e-02,  7.4758e-01, -6.5715e-01,  ..., -4.7723e-01,\n",
       "            3.7326e-01,  6.9366e-02],\n",
       "          [-2.2030e+00,  6.1988e-01, -4.9066e-01,  ..., -2.4132e-01,\n",
       "            9.4151e-01, -8.3138e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-0.5747, -0.1936, -1.0579,  ..., -0.4035,  0.3472,  0.4603],\n",
       "          [ 0.2211,  1.4295, -2.2959,  ..., -0.2134, -1.8294, -0.6401],\n",
       "          [-0.2317,  0.8230, -1.6503,  ...,  2.1485, -0.3964, -0.9095],\n",
       "          ...,\n",
       "          [-1.2317,  0.2524, -0.9053,  ..., -0.6611, -1.2265, -1.0775],\n",
       "          [-0.1874,  1.2939,  0.3166,  ..., -2.1171, -0.6489, -0.0537],\n",
       "          [-1.6998,  1.1036,  0.4399,  ..., -1.7942, -1.6766,  0.1630]],\n",
       "\n",
       "         [[ 0.2776,  0.0744,  0.2123,  ..., -0.3098, -0.1898,  0.1831],\n",
       "          [-0.8253,  0.9582,  0.2192,  ...,  0.2213, -0.7959,  1.1608],\n",
       "          [-0.3567,  0.0773,  0.4477,  ..., -1.1595, -0.8412, -0.5869],\n",
       "          ...,\n",
       "          [-0.8504, -1.5781,  0.4285,  ...,  0.5930,  0.7916, -1.1303],\n",
       "          [-2.6085, -1.1010,  1.0546,  ..., -1.6528,  0.2697, -0.4995],\n",
       "          [-0.9672,  0.8309,  2.6692,  ..., -1.3442,  0.6100, -0.3250]],\n",
       "\n",
       "         [[ 0.7155, -3.0312,  0.5511,  ...,  1.0201, -0.4459, -0.4274],\n",
       "          [-0.4183,  0.6720, -0.4801,  ...,  0.9370, -2.9824, -1.4698],\n",
       "          [ 0.0303,  0.9883,  0.7281,  ...,  0.2819, -3.4822, -1.4010],\n",
       "          ...,\n",
       "          [-0.0979,  1.5800,  0.8527,  ..., -2.1886, -3.3264, -2.0850],\n",
       "          [ 1.1273,  1.4675,  2.7224,  ..., -0.5520, -2.5923, -1.3328],\n",
       "          [ 0.4058,  0.5913,  1.0892,  ..., -1.2732, -2.3605, -2.6364]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4699,  0.4546, -0.2930,  ...,  0.2526,  0.3726, -0.1572],\n",
       "          [-0.6885, -0.4348, -1.1053,  ..., -1.0919, -0.5989, -0.3614],\n",
       "          [-2.0544, -0.6973, -1.3344,  ..., -0.4475,  0.3831,  1.9794],\n",
       "          ...,\n",
       "          [-0.3351, -1.0369, -0.4026,  ...,  0.8796,  0.2456,  2.4374],\n",
       "          [-0.0804, -0.7350, -0.5276,  ...,  0.9181, -0.4514,  1.4194],\n",
       "          [-1.4307,  0.9818, -1.1402,  ..., -1.1104, -0.8455,  2.9060]],\n",
       "\n",
       "         [[-0.3207,  0.3533, -0.2380,  ..., -1.0957,  0.4173,  0.1706],\n",
       "          [-0.6248,  1.3777, -1.4928,  ...,  1.1612,  1.0783,  0.0581],\n",
       "          [-1.3282,  1.5903, -0.0354,  ..., -0.4267,  0.1279, -0.4201],\n",
       "          ...,\n",
       "          [ 0.8001,  0.6712,  0.9335,  ...,  0.1064,  0.0558, -0.3244],\n",
       "          [-0.3351,  2.0199,  0.9169,  ...,  0.2052,  0.3556,  0.6386],\n",
       "          [ 1.2500,  2.6971,  0.2224,  ..., -0.7387,  0.0660, -0.3412]],\n",
       "\n",
       "         [[-4.2779,  0.8885, -0.1834,  ...,  1.5295,  0.1673, -0.2992],\n",
       "          [-1.4292, -0.4312, -1.3848,  ...,  2.5314, -0.7673,  0.7606],\n",
       "          [-0.6844,  1.5766, -0.4494,  ...,  0.8850, -1.4331, -0.0549],\n",
       "          ...,\n",
       "          [ 0.9741,  1.9663, -1.4436,  ..., -0.5077, -0.9002, -1.5274],\n",
       "          [-1.1303,  1.3516, -1.0280,  ...,  0.0544, -0.8997, -0.1472],\n",
       "          [ 0.2506,  0.5197,  0.1460,  ...,  0.8713, -2.2257, -1.9336]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-7.4023e-02, -4.3049e-02,  1.0000e-01,  ..., -1.1449e-02,\n",
       "            2.4425e-02,  7.5586e-03],\n",
       "          [-9.1436e-02, -3.7997e-01,  1.7193e+00,  ...,  4.1401e-01,\n",
       "           -1.8101e-02,  5.8391e-01],\n",
       "          [ 1.9939e-01,  2.6162e-01, -4.3047e-02,  ..., -5.1181e-01,\n",
       "           -5.5193e-01, -8.8907e-01],\n",
       "          ...,\n",
       "          [ 1.1440e+00,  1.8076e+00,  2.1997e+00,  ..., -3.1183e-01,\n",
       "            1.0066e+00, -3.8903e+00],\n",
       "          [ 1.1103e+00, -2.3139e-01,  1.0925e+00,  ...,  3.5241e-01,\n",
       "            6.1488e-01, -2.3956e+00],\n",
       "          [-1.3480e-01,  4.3094e-01,  2.3171e+00,  ..., -1.2773e-01,\n",
       "            1.3793e+00, -1.1061e+00]],\n",
       "\n",
       "         [[-1.3614e-02, -1.3338e-02,  8.6618e-03,  ..., -3.2414e-02,\n",
       "            8.0680e-03,  7.2715e-03],\n",
       "          [ 7.6024e-02,  3.0014e-01,  1.9665e-01,  ..., -4.9063e-02,\n",
       "           -4.1039e-01,  2.0986e-02],\n",
       "          [ 1.9104e-01, -1.5076e+00,  9.0812e-01,  ..., -4.9465e-01,\n",
       "           -7.2694e-01, -1.0647e+00],\n",
       "          ...,\n",
       "          [ 1.4442e+00, -1.1145e+00,  3.3829e-01,  ..., -4.1021e-01,\n",
       "           -2.1309e+00,  2.4973e-01],\n",
       "          [ 5.8831e-01, -9.9959e-02,  4.2118e-01,  ...,  1.4381e+00,\n",
       "           -1.2907e+00, -2.3875e-01],\n",
       "          [ 1.5494e+00, -2.2966e+00,  8.0416e-01,  ...,  2.2017e+00,\n",
       "           -4.3163e+00,  1.8231e+00]],\n",
       "\n",
       "         [[-8.9746e-03, -3.1459e-02, -3.7932e-03,  ...,  5.2488e-02,\n",
       "            1.8642e-02,  2.9215e-02],\n",
       "          [ 4.6107e-01, -2.1705e+00, -2.6045e+00,  ..., -1.1663e+00,\n",
       "            5.5219e-01, -5.8643e-02],\n",
       "          [-7.3727e-01,  3.8687e-01, -1.9918e-01,  ..., -1.5020e+00,\n",
       "           -4.5439e-01,  1.3818e+00],\n",
       "          ...,\n",
       "          [ 1.1227e+00, -2.8885e-01, -5.9019e-01,  ..., -1.8611e-01,\n",
       "            6.5996e-01, -7.3345e-01],\n",
       "          [-1.6154e+00,  1.5220e+00, -2.8783e-01,  ..., -1.0013e+00,\n",
       "            1.9088e-01, -1.9034e-02],\n",
       "          [-1.0421e+00,  8.0410e-01,  1.0422e+00,  ...,  1.7267e+00,\n",
       "           -1.6403e-01,  4.8230e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3263e-02,  8.0819e-02,  3.9806e-02,  ..., -1.0830e-01,\n",
       "           -2.0571e-02,  1.4771e-02],\n",
       "          [-2.9583e-01, -8.1416e-01,  3.9801e-01,  ...,  2.3574e+00,\n",
       "            1.6158e+00, -5.1468e-01],\n",
       "          [ 1.7015e+00, -2.2481e-01,  1.6419e+00,  ...,  1.7395e+00,\n",
       "           -5.3276e-01, -1.9940e-01],\n",
       "          ...,\n",
       "          [ 2.1718e+00, -3.7334e-01, -2.6933e-01,  ...,  1.7910e+00,\n",
       "           -2.1933e+00,  1.0813e+00],\n",
       "          [ 1.5114e+00, -1.1047e+00, -1.3917e-01,  ...,  1.6411e+00,\n",
       "           -9.4583e-01,  1.9407e+00],\n",
       "          [ 1.3122e+00, -3.9213e-01,  1.9681e-01,  ...,  2.0951e-01,\n",
       "           -6.4146e-01,  9.4824e-01]],\n",
       "\n",
       "         [[-5.4138e-02,  1.0691e-02,  8.9289e-03,  ..., -3.7348e-03,\n",
       "           -5.5784e-02, -6.7557e-03],\n",
       "          [-1.6488e+00, -2.2189e-01,  2.9817e-01,  ...,  3.5869e+00,\n",
       "           -3.5448e-01, -1.8639e+00],\n",
       "          [-2.7084e-01,  5.3306e-01,  4.3819e-01,  ...,  2.6619e+00,\n",
       "            1.3788e+00,  2.8253e+00],\n",
       "          ...,\n",
       "          [-8.6812e-01, -3.7871e-02,  1.6465e+00,  ...,  3.8072e-01,\n",
       "            4.9934e-01,  1.1938e+00],\n",
       "          [-2.4514e+00,  9.1686e-01, -8.7199e-01,  ..., -1.4440e-01,\n",
       "            2.1181e-02,  1.6007e+00],\n",
       "          [-1.8811e+00, -1.1995e+00, -9.8834e-01,  ...,  1.1914e+00,\n",
       "           -7.6317e-01, -1.6239e-01]],\n",
       "\n",
       "         [[ 9.2412e-04, -1.4691e-02,  3.1212e-02,  ...,  6.2072e-03,\n",
       "            2.9425e-02, -2.4945e-04],\n",
       "          [ 4.0684e-01, -3.2703e-01, -5.4133e-01,  ...,  6.6620e-01,\n",
       "           -9.3731e-01,  1.5041e-01],\n",
       "          [ 4.5772e-01, -1.0869e+00, -5.6053e-01,  ...,  2.6198e-01,\n",
       "           -1.1692e+00,  1.5529e-01],\n",
       "          ...,\n",
       "          [-7.2698e-02, -9.7522e-01, -1.4040e-01,  ..., -6.5286e-01,\n",
       "            1.7727e+00, -1.6617e+00],\n",
       "          [-4.3512e-01,  2.0584e+00, -1.7203e+00,  ...,  1.0033e+00,\n",
       "           -1.2965e+00, -5.1506e-01],\n",
       "          [-6.3761e-01,  2.7186e+00,  1.0373e+00,  ..., -7.4382e-01,\n",
       "           -8.7558e-01, -6.7302e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 8.9878e-01,  1.0092e+00, -5.8162e-01,  ..., -5.9482e-01,\n",
       "            6.0091e-01, -3.0801e-01],\n",
       "          [ 1.2857e+00,  1.0108e-01, -1.9959e+00,  ...,  2.6026e+00,\n",
       "            5.4419e-02, -2.5748e-01],\n",
       "          [ 6.2537e-01, -4.0298e-01, -2.9573e+00,  ...,  1.6658e+00,\n",
       "           -6.1806e-01, -9.7287e-01],\n",
       "          ...,\n",
       "          [-3.6055e-01, -1.2459e+00, -1.9063e+00,  ...,  9.0093e-01,\n",
       "            7.0935e-01, -1.3629e+00],\n",
       "          [-8.8028e-01, -3.0154e+00, -2.2896e+00,  ...,  1.3479e+00,\n",
       "            4.7063e-01,  3.4580e-01],\n",
       "          [ 1.1571e+00,  1.4335e+00, -1.3883e+00,  ...,  3.1343e-01,\n",
       "           -8.4320e-01, -3.4010e-01]],\n",
       "\n",
       "         [[ 1.7836e-01,  3.0264e-01,  4.2053e-01,  ...,  1.0676e+00,\n",
       "            5.5447e-01,  4.4503e-01],\n",
       "          [-6.7448e-01, -2.1465e+00, -1.2126e+00,  ..., -2.0612e+00,\n",
       "           -1.2112e-01, -3.0826e-01],\n",
       "          [-1.3257e-01,  5.4381e-01, -3.9138e-01,  ..., -1.8043e+00,\n",
       "           -3.2837e-01,  1.4116e+00],\n",
       "          ...,\n",
       "          [ 1.4344e+00, -1.3788e+00,  8.6266e-01,  ..., -3.8274e-02,\n",
       "           -1.7510e+00,  5.9129e-01],\n",
       "          [ 6.8965e-02,  5.4761e-01,  8.3315e-01,  ..., -1.4237e+00,\n",
       "           -1.7209e+00,  7.1122e-01],\n",
       "          [ 7.9031e-02, -9.2737e-01, -6.0515e-01,  ...,  3.7964e-01,\n",
       "           -3.8844e-01,  1.2731e+00]],\n",
       "\n",
       "         [[ 7.6445e-01, -4.5784e-01,  2.4069e-01,  ..., -2.8202e-01,\n",
       "           -2.4347e-01, -2.1750e-01],\n",
       "          [ 1.2038e+00,  2.5293e-01, -8.1606e-02,  ...,  1.6669e+00,\n",
       "            6.0786e-01, -1.6832e+00],\n",
       "          [ 9.5627e-01, -5.5317e-01,  1.4512e+00,  ...,  1.6300e+00,\n",
       "            6.5398e-01, -9.0007e-01],\n",
       "          ...,\n",
       "          [-1.3621e+00,  1.1651e-01, -1.2585e+00,  ..., -1.5499e-01,\n",
       "           -1.2887e+00,  2.4966e-01],\n",
       "          [-4.1176e-02,  8.3612e-01, -6.7762e-01,  ...,  6.3264e-02,\n",
       "           -1.5930e-02, -5.0446e-01],\n",
       "          [-5.2192e-01, -1.9325e-01,  7.5796e-01,  ...,  1.4262e+00,\n",
       "           -1.3715e+00,  1.1257e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0911e+00,  5.5096e-01, -4.9958e-01,  ...,  1.4008e+00,\n",
       "            3.7107e-01, -5.1888e-01],\n",
       "          [-1.4911e+00,  4.7221e-02, -6.3075e-01,  ...,  1.9115e+00,\n",
       "           -7.8982e-01,  2.5138e+00],\n",
       "          [-4.5840e+00,  1.5292e-01,  2.3166e-01,  ...,  3.2919e-01,\n",
       "            2.5671e-01,  2.3860e+00],\n",
       "          ...,\n",
       "          [-5.6231e+00,  4.1125e-01, -7.9241e-01,  ...,  1.7941e+00,\n",
       "            1.4761e+00,  1.5073e+00],\n",
       "          [-2.3696e+00,  2.0058e+00,  5.4386e-02,  ...,  1.8037e+00,\n",
       "            2.0388e+00,  2.8997e+00],\n",
       "          [-4.5047e+00,  6.5470e-01, -9.3925e-01,  ...,  2.0816e+00,\n",
       "            1.4522e+00,  1.0928e+00]],\n",
       "\n",
       "         [[ 2.6788e-01,  4.9637e-01,  5.6669e-02,  ...,  4.7363e-01,\n",
       "           -4.2349e-01, -5.2468e-01],\n",
       "          [-9.7223e-01,  1.1353e-01, -2.3433e+00,  ...,  2.2225e-01,\n",
       "           -6.4804e-01, -1.2503e+00],\n",
       "          [ 1.0417e+00,  1.3834e+00,  6.1856e-01,  ..., -2.4970e-01,\n",
       "            1.1836e+00, -6.6666e-01],\n",
       "          ...,\n",
       "          [ 5.1442e-01, -4.7655e-01, -3.5821e-02,  ..., -1.5277e-01,\n",
       "           -4.4089e-01, -3.1540e-03],\n",
       "          [ 4.1034e-01, -5.0751e-01, -2.9385e-01,  ...,  4.2380e-01,\n",
       "           -2.4284e+00,  5.1601e-01],\n",
       "          [-1.1765e+00,  5.6884e-01,  1.0726e+00,  ...,  8.3182e-01,\n",
       "           -1.9527e+00,  3.9070e-01]],\n",
       "\n",
       "         [[-1.2388e-01,  4.8062e-01,  2.4206e+00,  ..., -4.6833e-01,\n",
       "           -1.8396e+00, -1.4459e+00],\n",
       "          [-1.5544e-01, -1.8663e+00,  3.2522e-01,  ..., -7.5268e-01,\n",
       "           -1.5322e+00, -1.1147e+00],\n",
       "          [ 2.6524e-01, -1.1679e+00, -4.0079e-01,  ..., -6.9893e-01,\n",
       "           -3.3914e+00, -2.6235e-01],\n",
       "          ...,\n",
       "          [-6.2378e-01,  2.4104e-01, -6.9832e-01,  ..., -1.5731e-01,\n",
       "           -1.7493e+00, -2.2912e+00],\n",
       "          [-3.1183e-01,  1.8050e-01,  8.6384e-01,  ...,  9.2166e-01,\n",
       "           -6.7706e-01, -1.5618e+00],\n",
       "          [-3.8325e-01,  3.8832e-01,  1.5547e+00,  ..., -8.6107e-01,\n",
       "           -1.6474e+00, -2.0740e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[-3.1099e-01, -4.6182e-01,  3.1046e-02,  ..., -5.2096e-01,\n",
       "           -6.9228e-01, -1.1453e-01],\n",
       "          [ 2.0794e+00, -2.0959e+00, -7.4522e-01,  ...,  9.2154e-02,\n",
       "           -3.0525e-02, -1.1302e+00],\n",
       "          [ 2.1470e-01, -2.6657e+00, -2.4766e-01,  ...,  1.2940e-01,\n",
       "           -1.4992e+00, -1.2644e+00],\n",
       "          ...,\n",
       "          [-2.3283e+00, -2.1702e+00,  2.5010e-01,  ..., -1.4729e+00,\n",
       "            9.4263e-01,  3.6479e+00],\n",
       "          [-1.5435e+00, -4.4916e+00, -6.8826e-01,  ..., -2.6738e-01,\n",
       "           -1.2182e-02,  3.2654e+00],\n",
       "          [-4.3350e-01, -1.3348e+00,  1.3372e+00,  ..., -7.0688e-01,\n",
       "           -2.1389e-01,  3.7431e+00]],\n",
       "\n",
       "         [[ 1.0502e-01,  7.1541e-03,  5.2570e-02,  ..., -2.0248e-02,\n",
       "           -3.0080e-02, -2.5176e-03],\n",
       "          [ 1.6045e+00, -1.1106e+00, -1.0598e+00,  ..., -6.5190e-01,\n",
       "           -1.3459e+00, -1.3781e+00],\n",
       "          [-8.0097e-01, -9.9728e-01, -7.7470e-01,  ...,  1.0136e+00,\n",
       "            5.8227e-01,  1.6934e+00],\n",
       "          ...,\n",
       "          [ 2.5838e-01, -1.3479e+00,  5.3070e-01,  ..., -1.2725e+00,\n",
       "            8.7429e-01,  7.9004e-01],\n",
       "          [-1.0839e+00, -2.1870e-01,  8.5787e-01,  ...,  5.0322e-01,\n",
       "           -1.2232e+00,  7.6343e-01],\n",
       "          [-9.1688e-01,  7.7075e-01, -8.2480e-02,  ..., -7.2377e-01,\n",
       "           -4.4189e-01, -4.3671e-01]],\n",
       "\n",
       "         [[ 3.2186e-02,  9.1382e-02,  1.3097e-01,  ...,  4.1888e-02,\n",
       "            3.9931e-02, -1.1312e-03],\n",
       "          [ 1.0185e+00, -1.2000e+00,  4.8301e-01,  ...,  3.5697e-01,\n",
       "           -7.7118e-01,  1.5626e+00],\n",
       "          [-9.9344e-01, -1.1178e-01,  4.2652e-02,  ..., -1.3671e+00,\n",
       "            1.3185e-01, -1.4012e+00],\n",
       "          ...,\n",
       "          [-1.1808e+00,  7.7231e-03, -1.1281e+00,  ..., -7.3510e-01,\n",
       "            5.1932e-01,  2.6845e+00],\n",
       "          [-2.0424e+00, -2.3207e-01,  9.1590e-01,  ..., -2.8056e-01,\n",
       "            1.1593e+00,  1.6349e+00],\n",
       "          [-1.3587e+00, -1.7547e+00, -3.7971e+00,  ..., -1.5734e+00,\n",
       "            2.6261e+00,  7.0643e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.5188e-03,  7.7823e-03, -6.2634e-02,  ..., -3.3401e-02,\n",
       "           -2.3986e-02,  5.5995e-02],\n",
       "          [ 5.4468e-01, -4.4560e+00,  2.7222e+00,  ...,  1.6459e+00,\n",
       "            2.0000e+00,  1.4391e+00],\n",
       "          [ 1.2286e-01,  1.5608e+00, -2.5076e-01,  ...,  6.7060e-01,\n",
       "           -8.3763e-01,  5.1192e-01],\n",
       "          ...,\n",
       "          [-1.6846e+00,  1.2157e+00, -1.5898e+00,  ..., -2.0573e+00,\n",
       "            8.1627e-01,  1.1089e+00],\n",
       "          [ 7.2082e-01, -1.2603e+00,  3.0197e-02,  ...,  1.4251e-01,\n",
       "            2.9653e+00, -7.5544e-01],\n",
       "          [-6.4098e-01,  1.1487e+00, -1.1555e+00,  ..., -1.3036e+00,\n",
       "            9.7964e-01,  2.0511e+00]],\n",
       "\n",
       "         [[-2.2311e-02,  2.6248e-02,  8.9067e-03,  ...,  7.8912e-03,\n",
       "            4.0171e-03, -3.5862e-03],\n",
       "          [-7.5321e-01,  7.6571e-01, -2.4679e+00,  ..., -1.0342e-01,\n",
       "            7.1812e-01,  6.4034e-01],\n",
       "          [-1.7385e+00,  7.2010e-01, -2.1328e+00,  ..., -1.6112e+00,\n",
       "            8.3742e-01, -1.3472e+00],\n",
       "          ...,\n",
       "          [-2.6599e+00,  8.1989e-01, -3.1224e+00,  ...,  6.3787e-01,\n",
       "            1.9494e+00, -2.5718e+00],\n",
       "          [-1.4320e+00, -9.9355e-02, -1.9397e+00,  ...,  2.4738e-01,\n",
       "            8.6548e-02, -4.0278e-01],\n",
       "          [-7.2819e-01, -7.9618e-01, -2.0322e+00,  ...,  1.5183e-01,\n",
       "           -2.6530e-01, -2.4167e+00]],\n",
       "\n",
       "         [[ 7.9937e-02,  4.2339e-02,  8.4539e-03,  ..., -3.6057e-02,\n",
       "           -5.6319e-02,  5.6590e-03],\n",
       "          [-7.5809e-01, -2.1399e+00, -8.1678e-01,  ...,  2.1954e+00,\n",
       "           -1.7534e+00,  6.2670e-01],\n",
       "          [-1.7790e+00,  2.0071e+00,  9.0618e-01,  ..., -1.4168e+00,\n",
       "            2.5267e-01, -1.5636e-01],\n",
       "          ...,\n",
       "          [ 1.4639e+00,  1.2389e+00,  6.1424e-01,  ..., -7.1490e-02,\n",
       "            2.6059e+00,  1.5873e-01],\n",
       "          [ 3.3499e-01,  3.0952e-01,  1.4072e+00,  ...,  4.8807e-01,\n",
       "           -8.2873e-01, -1.5595e+00],\n",
       "          [ 1.4744e+00,  3.9393e-01, -3.7832e-01,  ..., -1.0689e+00,\n",
       "            2.2191e+00, -4.8019e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.4488, -0.0465,  0.1658,  ...,  0.0205, -0.7184,  1.0608],\n",
       "          [-0.0991, -1.1019,  1.3743,  ..., -0.5185,  0.3103,  0.6812],\n",
       "          [-0.5272,  0.3569, -0.3330,  ..., -0.1912, -2.3547,  1.3902],\n",
       "          ...,\n",
       "          [-1.3376,  1.2560, -0.3267,  ..., -0.2089, -2.6762,  0.3066],\n",
       "          [ 0.0528,  0.3028,  0.3094,  ...,  0.5033, -1.2524,  1.3426],\n",
       "          [-0.9733,  0.4142, -0.8945,  ..., -0.0603, -1.3415,  1.0055]],\n",
       "\n",
       "         [[ 0.3121,  0.3517,  0.0859,  ..., -1.1778,  0.1389,  1.3112],\n",
       "          [-0.0466,  0.3482,  0.9288,  ..., -1.2434,  1.5916, -0.0524],\n",
       "          [-0.5909, -0.9655,  0.6939,  ...,  0.2702,  0.2753,  0.1472],\n",
       "          ...,\n",
       "          [-0.8536,  0.1004,  0.0154,  ..., -0.8865,  1.7444,  0.1987],\n",
       "          [-1.5620, -0.5527,  1.4167,  ...,  0.6350,  1.8514,  2.2435],\n",
       "          [-1.1194,  0.0973,  0.0807,  ...,  0.2532,  0.9522,  0.8303]],\n",
       "\n",
       "         [[ 0.3834, -0.4483, -0.1268,  ...,  0.5279,  0.0500, -0.2453],\n",
       "          [-1.1224, -1.6171,  7.0018,  ...,  1.9863, -0.1325, -5.3443],\n",
       "          [-1.9175,  0.1794,  7.9457,  ...,  2.7472,  1.0765, -5.4925],\n",
       "          ...,\n",
       "          [-1.5416, -0.5714,  8.2796,  ...,  1.3099,  1.0683, -6.9979],\n",
       "          [-1.7765, -0.3683,  8.5062,  ...,  2.4061,  0.2344, -8.1060],\n",
       "          [-1.4807, -0.0357,  7.9354,  ...,  1.9832,  0.8019, -5.5482]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1090,  1.0455, -0.3583,  ..., -0.1319,  0.6184, -1.2756],\n",
       "          [ 2.3881,  5.0288,  1.2539,  ...,  1.5873,  0.4477, -4.1529],\n",
       "          [ 0.4695,  3.5394,  0.0245,  ...,  0.1406,  0.2327, -3.6032],\n",
       "          ...,\n",
       "          [-0.8931,  5.0606, -0.0580,  ..., -0.1650,  0.8524, -4.5655],\n",
       "          [ 1.0804,  3.7954, -0.8876,  ..., -0.0438,  0.1832, -4.5346],\n",
       "          [ 0.5297,  4.8158, -1.2210,  ...,  0.1748,  1.2437, -4.1181]],\n",
       "\n",
       "         [[-0.4680,  1.0336, -1.0637,  ...,  2.2390, -0.6996,  0.1934],\n",
       "          [-0.0162,  1.6477, -1.3614,  ...,  3.8356, -0.2067, -0.8762],\n",
       "          [-0.1575,  1.0758, -3.0583,  ...,  3.4033,  0.3009, -0.1698],\n",
       "          ...,\n",
       "          [-0.1526,  0.9048, -1.6733,  ...,  3.6201,  1.8785, -0.9492],\n",
       "          [-0.4278,  0.4937, -2.0538,  ...,  6.7858,  1.2284, -0.7833],\n",
       "          [ 0.0404,  0.8063, -1.5972,  ...,  3.8174,  0.6576,  0.6302]],\n",
       "\n",
       "         [[-0.4025,  0.1967, -0.4228,  ..., -0.1137, -0.0845,  1.0282],\n",
       "          [-2.4819, -0.4941,  0.0912,  ...,  0.3058, -0.8231,  0.3790],\n",
       "          [-0.8134,  0.5142,  0.0749,  ..., -0.3188, -0.2283,  0.0628],\n",
       "          ...,\n",
       "          [ 0.0345, -1.7364,  2.2420,  ...,  2.7480, -0.8079,  1.0227],\n",
       "          [-0.7480, -0.8191,  0.0996,  ...,  4.0500, -2.1413,  3.1066],\n",
       "          [-0.2896, -0.6766, -0.3150,  ...,  1.0455,  0.2319,  1.2794]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-1.3398e-01,  7.1664e-02, -4.2587e-03,  ...,  1.6617e-02,\n",
       "           -7.4362e-03, -3.4115e-02],\n",
       "          [ 1.4205e+00,  4.0620e-01, -1.1156e+00,  ..., -6.3743e-01,\n",
       "            9.0145e-01, -1.9321e+00],\n",
       "          [-6.9867e-01, -3.6143e-01, -1.1872e+00,  ..., -1.3838e-01,\n",
       "           -1.2125e+00,  2.1702e-01],\n",
       "          ...,\n",
       "          [-4.9976e-01, -1.0455e+00, -1.5337e+00,  ..., -6.7521e-01,\n",
       "           -7.2200e-01, -3.2506e-02],\n",
       "          [-6.6850e-01,  3.9106e-01, -1.2508e+00,  ..., -3.1433e-01,\n",
       "            9.1206e-01, -1.6534e+00],\n",
       "          [-1.3242e+00, -1.1762e-01, -3.2349e-01,  ..., -1.8196e-01,\n",
       "           -5.9278e-02, -4.0634e-01]],\n",
       "\n",
       "         [[ 1.4105e-01,  3.0161e-01, -2.3357e-01,  ...,  1.1928e-01,\n",
       "           -5.7716e-01, -3.3641e-01],\n",
       "          [-1.4352e+00, -2.0730e+00, -9.9869e-01,  ..., -6.8211e-01,\n",
       "            5.4049e-03, -4.3003e+00],\n",
       "          [-1.3628e+00, -2.8011e+00, -4.3306e-01,  ...,  9.1839e-01,\n",
       "            2.5738e+00, -2.7456e+00],\n",
       "          ...,\n",
       "          [-1.9426e+00, -8.6763e-01, -4.4350e-01,  ..., -2.3053e+00,\n",
       "            5.2536e-01,  5.5299e-01],\n",
       "          [-2.8929e-02,  1.4461e+00, -3.0643e+00,  ..., -5.4606e-01,\n",
       "            1.0474e+00, -1.8016e+00],\n",
       "          [-1.3256e+00, -1.2641e+00,  3.2756e-01,  ...,  1.4437e+00,\n",
       "           -1.5042e+00, -1.6145e+00]],\n",
       "\n",
       "         [[-5.6703e-02, -3.0871e-02, -3.3834e-02,  ..., -3.6619e-02,\n",
       "            4.3231e-02, -1.7383e-02],\n",
       "          [-1.4874e+00, -2.0920e-01,  2.2365e-01,  ..., -1.9556e-01,\n",
       "            9.2458e-01, -1.5084e+00],\n",
       "          [-8.5920e-01,  1.4800e-01, -7.8401e-01,  ..., -4.5174e-01,\n",
       "           -1.0643e-01, -1.0301e+00],\n",
       "          ...,\n",
       "          [ 9.3452e-01,  6.5717e-01, -6.3779e-02,  ..., -8.9387e-01,\n",
       "            2.5485e+00,  1.2418e+00],\n",
       "          [ 1.1444e+00, -1.1769e+00, -5.3118e-01,  ..., -1.8433e-01,\n",
       "            3.1865e-01,  6.7685e-01],\n",
       "          [-4.9437e-01,  4.0471e-01, -4.4922e-01,  ..., -5.3830e-02,\n",
       "            5.2720e-01,  9.8270e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4755e-02,  8.0570e-03, -1.3468e-02,  ..., -1.8277e-02,\n",
       "            3.2317e-02, -2.5364e-02],\n",
       "          [-3.6228e-01, -6.1024e-01,  3.4584e+00,  ...,  1.6725e+00,\n",
       "            1.5858e+00, -3.3878e-01],\n",
       "          [-1.2905e+00, -2.5863e-01,  2.3832e+00,  ...,  2.8264e-03,\n",
       "            3.3569e-02,  4.6524e-01],\n",
       "          ...,\n",
       "          [-8.7875e-01, -1.8489e-01,  8.5658e-01,  ...,  1.5968e+00,\n",
       "            1.8405e-01, -3.7400e-01],\n",
       "          [-2.6306e-01, -3.9334e-01, -5.0048e-01,  ...,  2.1014e+00,\n",
       "            9.2422e-02, -9.2069e-01],\n",
       "          [ 3.3679e-02, -7.2641e-02,  1.3236e+00,  ..., -1.1535e+00,\n",
       "            2.9730e-01, -1.2705e+00]],\n",
       "\n",
       "         [[-2.2746e-02,  2.4717e-02,  5.8138e-02,  ...,  2.1713e-03,\n",
       "           -5.0133e-03, -2.7822e-02],\n",
       "          [ 3.9902e-01,  1.0258e-01,  1.1959e-01,  ..., -9.4471e-01,\n",
       "           -2.6638e-01, -2.0373e+00],\n",
       "          [-7.9901e-01,  5.8666e-01, -5.7038e-01,  ...,  1.2442e-01,\n",
       "           -1.2411e-01, -2.2257e-01],\n",
       "          ...,\n",
       "          [ 7.7582e-02, -9.9500e-01,  8.9661e-01,  ..., -2.9491e-01,\n",
       "           -3.6506e-01, -1.6852e+00],\n",
       "          [-2.6958e-01,  7.6730e-01, -1.9709e-01,  ..., -2.4476e+00,\n",
       "           -1.0468e+00, -5.8846e-01],\n",
       "          [-7.5179e-01, -9.0911e-02,  4.9035e-01,  ..., -9.9082e-01,\n",
       "           -5.9903e-01, -5.2374e-01]],\n",
       "\n",
       "         [[ 1.3473e-01, -1.8072e-03,  1.4074e-01,  ...,  1.6658e-02,\n",
       "            2.9488e-01,  1.3614e-01],\n",
       "          [-2.1135e+00,  3.0748e-01,  5.3773e-01,  ..., -1.1461e+00,\n",
       "           -4.8465e-01,  6.6365e-01],\n",
       "          [-1.0139e-01, -1.2718e+00,  2.1522e+00,  ..., -1.4084e+00,\n",
       "            3.2853e-01,  6.6451e-01],\n",
       "          ...,\n",
       "          [-2.9734e-01,  1.9648e+00,  2.7230e+00,  ..., -3.7664e-01,\n",
       "           -1.8636e+00,  1.4844e+00],\n",
       "          [-1.8989e+00,  3.9609e+00, -2.2502e+00,  ...,  1.6709e+00,\n",
       "           -2.0335e+00,  2.0625e+00],\n",
       "          [ 6.2983e-01, -1.2334e+00,  2.1090e+00,  ..., -3.2081e-01,\n",
       "           -1.8891e-02,  1.7578e+00]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.3833, -0.1871,  0.7314,  ...,  0.8397,  0.3596,  0.7220],\n",
       "          [-1.6847,  1.6868, -6.1842,  ..., -4.4236,  2.9755, -1.1851],\n",
       "          [-3.3110,  2.2239, -5.3767,  ..., -3.8544,  2.7194, -0.8661],\n",
       "          ...,\n",
       "          [-2.0689,  1.5013, -5.0408,  ..., -2.4334,  3.4064, -4.1230],\n",
       "          [-2.1537,  1.2952, -7.5667,  ..., -2.7018,  0.6539, -3.8212],\n",
       "          [-0.1696,  1.5535, -3.7409,  ..., -1.1741,  0.3790, -4.2037]],\n",
       "\n",
       "         [[ 0.5578, -0.8925,  0.7706,  ..., -0.9195, -1.1971, -0.3466],\n",
       "          [ 0.5123,  0.1482, -0.3638,  ...,  0.0538, -0.2883, -0.1349],\n",
       "          [-1.2883, -1.1302, -1.5530,  ..., -0.5084, -0.2196, -1.5094],\n",
       "          ...,\n",
       "          [ 0.0713, -0.2863, -0.3099,  ...,  0.8139, -0.9328, -1.2800],\n",
       "          [ 0.4654,  0.7394, -0.7758,  ...,  0.5361, -0.5395, -1.2729],\n",
       "          [ 0.1042,  0.3026, -0.3741,  ..., -0.1203, -1.6385,  1.3468]],\n",
       "\n",
       "         [[-0.1139,  0.5239,  0.4428,  ...,  0.3790, -0.0878,  0.1023],\n",
       "          [ 2.4917, -0.6462,  3.0614,  ...,  0.5627, -0.9598,  1.0279],\n",
       "          [ 3.9877, -0.3032,  3.3689,  ...,  2.4774, -0.9022,  1.2218],\n",
       "          ...,\n",
       "          [ 3.0668,  0.5281,  2.4984,  ...,  2.3834, -2.1464,  2.8407],\n",
       "          [ 3.5938, -0.6407,  3.7952,  ...,  1.0291, -2.0383,  2.1432],\n",
       "          [ 2.6451, -0.6436,  1.9561,  ...,  2.8546, -0.7222,  3.0543]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1734, -0.7061, -0.9564,  ..., -0.3208,  0.4662,  0.3647],\n",
       "          [-1.0990, -1.9548,  0.0618,  ..., -1.6709,  1.4317, -0.3979],\n",
       "          [ 0.2187,  0.7055, -0.7384,  ..., -0.0410, -0.6196,  0.9852],\n",
       "          ...,\n",
       "          [-1.0572, -0.9390, -1.0643,  ..., -1.2707,  0.9619, -0.1131],\n",
       "          [-1.5552, -0.4397,  0.0941,  ..., -2.4816,  2.4861, -0.0228],\n",
       "          [-0.9629,  0.4545,  0.2099,  ...,  0.1436,  1.3733,  1.1641]],\n",
       "\n",
       "         [[ 0.0112,  1.0378, -0.5568,  ..., -0.0244,  0.4074, -0.4196],\n",
       "          [-0.2304, -0.2510, -0.4819,  ..., -0.5778,  1.7100, -0.7607],\n",
       "          [ 1.3416,  0.5527, -0.3038,  ..., -0.9143,  0.0140,  0.4614],\n",
       "          ...,\n",
       "          [ 0.8299,  1.3229, -2.1783,  ..., -0.1488,  0.2152,  0.7125],\n",
       "          [-0.7411,  0.9711, -1.4283,  ..., -0.8337, -0.6168,  0.4664],\n",
       "          [ 0.0693,  0.8346, -1.3375,  ..., -0.5579, -0.4323, -0.0930]],\n",
       "\n",
       "         [[ 1.5753, -0.3777,  0.1527,  ...,  0.7919,  0.2665, -0.1876],\n",
       "          [-1.5287,  1.1356,  0.1867,  ...,  1.2862, -1.1509, -0.7509],\n",
       "          [-1.8851, -0.0464,  0.5636,  ...,  1.1044, -1.2652, -1.8112],\n",
       "          ...,\n",
       "          [-2.5930,  1.1854, -1.2077,  ...,  1.8502, -1.0059, -0.5131],\n",
       "          [-2.5888,  1.1553, -1.5125,  ...,  1.1960, -0.6753,  0.7894],\n",
       "          [-3.1551,  0.1544,  0.8433,  ...,  1.5175,  0.4657,  0.1585]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 2.0753e-01, -1.0236e-01, -3.0244e-04,  ...,  6.3621e-02,\n",
       "           -6.0532e-02,  1.1192e-01],\n",
       "          [ 5.2698e-01,  9.5760e-02, -4.3748e-01,  ...,  2.2760e-01,\n",
       "           -3.0265e-01,  8.2023e-02],\n",
       "          [ 6.6462e-01,  4.9246e-01, -5.5567e-01,  ...,  1.0272e+00,\n",
       "           -3.9741e-01,  9.0196e-02],\n",
       "          ...,\n",
       "          [ 1.9614e-01,  1.0256e-01,  3.3996e-01,  ...,  1.0294e+00,\n",
       "           -5.3360e-01, -3.2157e-01],\n",
       "          [ 5.8458e-01,  3.6079e-01,  5.2391e-01,  ..., -1.4507e-01,\n",
       "            5.3823e-02, -8.3624e-01],\n",
       "          [ 8.0956e-02,  1.0240e-01,  4.8813e-02,  ..., -1.9842e-01,\n",
       "           -3.9822e-01, -6.8626e-02]],\n",
       "\n",
       "         [[-1.4557e-02, -8.7520e-03,  1.3281e-03,  ..., -1.0600e-02,\n",
       "            1.4239e-02, -5.3724e-03],\n",
       "          [ 4.3687e-01,  5.3402e-01,  1.2858e+00,  ...,  2.4398e-01,\n",
       "           -1.8072e-01, -6.4950e-01],\n",
       "          [-5.5159e-01,  1.0762e+00,  6.0948e-02,  ..., -1.2943e+00,\n",
       "           -8.1442e-01,  6.0602e-02],\n",
       "          ...,\n",
       "          [ 1.2481e-01,  1.3749e+00, -4.6702e-01,  ..., -9.3367e-01,\n",
       "           -9.3340e-01, -1.1375e+00],\n",
       "          [ 7.1755e-01,  4.9540e-01,  8.7746e-01,  ..., -5.7620e-01,\n",
       "            4.7287e-01, -7.3844e-01],\n",
       "          [ 7.0616e-01,  6.8690e-01,  1.1705e+00,  ..., -7.3442e-01,\n",
       "           -4.4774e-01, -6.7884e-01]],\n",
       "\n",
       "         [[ 1.7914e-02,  1.3213e-02,  1.1042e-02,  ..., -2.2421e-03,\n",
       "            4.0400e-02, -2.6064e-02],\n",
       "          [ 8.0717e-01,  3.2765e+00, -1.5007e+00,  ...,  1.3307e+00,\n",
       "           -1.5815e-01, -1.3370e+00],\n",
       "          [ 3.6889e-01,  1.5909e+00, -3.0950e-02,  ...,  1.4454e-01,\n",
       "           -3.1302e-01, -1.3302e+00],\n",
       "          ...,\n",
       "          [ 1.0934e+00, -6.6826e-01, -4.7479e-01,  ..., -5.2137e-01,\n",
       "            1.7379e-01, -9.2553e-01],\n",
       "          [ 4.1059e-02,  2.6267e-01,  3.2820e-02,  ..., -7.9057e-01,\n",
       "            6.9024e-01, -5.0746e-01],\n",
       "          [ 6.4146e-01,  6.4372e-01, -2.7692e-01,  ..., -8.8379e-01,\n",
       "            2.2262e-01, -3.6989e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.7760e-02, -2.6332e-02,  1.0534e-02,  ...,  8.2267e-03,\n",
       "            2.0198e-03, -2.4049e-02],\n",
       "          [ 5.1504e-01,  1.6954e+00,  5.0413e-01,  ...,  7.5437e-01,\n",
       "            5.6228e-01,  1.3323e+00],\n",
       "          [ 1.7728e+00, -3.5887e-01, -8.1577e-01,  ...,  1.3028e-01,\n",
       "            6.8930e-01,  6.6785e-01],\n",
       "          ...,\n",
       "          [ 1.4705e+00, -2.3892e-01,  4.9951e-01,  ...,  5.1994e-02,\n",
       "            1.3311e-01,  9.1323e-02],\n",
       "          [ 8.3399e-01,  1.1869e+00, -1.4890e+00,  ..., -9.9298e-03,\n",
       "           -5.5024e-01,  6.0700e-02],\n",
       "          [ 8.8849e-01,  1.7533e-02,  1.7850e+00,  ..., -1.9936e-01,\n",
       "            1.8123e-01,  5.9476e-01]],\n",
       "\n",
       "         [[-1.5440e-02, -9.1286e-03, -1.0486e-02,  ...,  4.1869e-02,\n",
       "           -3.3447e-02, -3.1913e-02],\n",
       "          [ 1.6314e+00, -2.7567e-01,  5.8441e-01,  ...,  2.6434e-01,\n",
       "            1.1051e+00,  1.4059e-02],\n",
       "          [ 9.4445e-01, -1.1893e+00,  7.6472e-01,  ...,  7.2003e-01,\n",
       "            5.7158e-01, -1.6125e+00],\n",
       "          ...,\n",
       "          [-6.8079e-01, -5.1841e-01,  9.5126e-01,  ...,  8.6555e-01,\n",
       "           -8.4331e-01, -1.1757e+00],\n",
       "          [-1.0261e+00, -1.9664e+00,  1.5705e+00,  ...,  9.0384e-01,\n",
       "           -1.1189e+00,  8.0154e-01],\n",
       "          [ 3.2789e-01, -1.1497e-01, -4.1186e-01,  ...,  2.7019e+00,\n",
       "           -6.2102e-01,  2.5156e-01]],\n",
       "\n",
       "         [[ 1.7607e-02,  5.4184e-03,  5.5915e-02,  ..., -1.0352e-02,\n",
       "           -1.1651e-02, -3.1987e-02],\n",
       "          [ 8.1874e-01,  8.0603e-01,  9.6819e-02,  ...,  5.1122e-01,\n",
       "           -7.6878e-01, -5.7602e-01],\n",
       "          [ 4.2623e-01,  1.7665e+00,  1.0459e+00,  ...,  2.9696e-01,\n",
       "           -9.8331e-01, -5.7586e-01],\n",
       "          ...,\n",
       "          [-4.0942e-01,  4.0523e-01,  2.0226e+00,  ...,  5.7429e-02,\n",
       "           -9.2772e-01, -3.3271e-01],\n",
       "          [ 2.4995e-01, -7.4989e-01,  4.8776e-01,  ...,  2.9001e-03,\n",
       "           -7.4601e-01, -9.8435e-01],\n",
       "          [-1.9619e-01,  6.7860e-01,  1.6036e+00,  ..., -2.9342e-01,\n",
       "           -1.9842e-02, -1.3045e+00]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-1.4475, -2.9301, -1.5214,  ..., -0.3633, -1.4609,  1.4797],\n",
       "          [-0.0248, -4.0111, -2.3380,  ...,  0.0810, -3.7936,  1.1041],\n",
       "          [ 0.6578, -3.6044, -3.0405,  ...,  0.4489, -2.8968,  0.7354],\n",
       "          ...,\n",
       "          [-0.3602, -3.9990, -1.8431,  ...,  0.0233, -4.1032,  1.8106],\n",
       "          [-0.7437, -4.1975, -2.2711,  ..., -1.7963, -2.8145,  2.3780],\n",
       "          [-1.3325, -5.0499, -2.1576,  ..., -0.4038, -4.2442,  0.9843]],\n",
       "\n",
       "         [[ 0.3149, -2.2754, -2.5295,  ..., -1.2915,  1.4388, -2.2951],\n",
       "          [ 1.5262, -2.5238, -2.1878,  ..., -0.0224,  2.8066, -3.1125],\n",
       "          [ 0.5738, -0.1656, -3.9956,  ...,  0.3986,  3.1714, -0.8863],\n",
       "          ...,\n",
       "          [-0.3604, -0.9946, -4.7202,  ..., -0.2919,  4.5761, -1.9205],\n",
       "          [ 0.2101, -1.6717, -3.7104,  ...,  0.8812,  4.0827, -2.2941],\n",
       "          [ 0.9162, -1.6579, -3.9857,  ...,  0.2284,  1.7700, -4.1426]],\n",
       "\n",
       "         [[-0.2408,  0.1536,  0.3896,  ..., -0.6338,  0.1914,  0.4174],\n",
       "          [-0.2030,  0.6876, -0.2107,  ...,  0.5209,  1.4027, -1.6543],\n",
       "          [-0.0833,  1.7841,  1.0251,  ..., -0.2257,  1.5899, -0.5159],\n",
       "          ...,\n",
       "          [-0.7415,  2.2667, -0.3781,  ..., -1.2844,  1.4451,  1.8276],\n",
       "          [-0.4971, -0.0562,  0.7615,  ...,  0.2594,  1.2508,  1.2640],\n",
       "          [-1.7390,  0.8490, -0.1222,  ..., -0.4880,  0.6048,  0.4625]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4043,  0.4164, -0.0080,  ...,  1.3547, -0.4454, -0.3685],\n",
       "          [ 1.6911,  1.5377,  2.0971,  ...,  0.5398, -1.7953, -1.6692],\n",
       "          [ 0.1849, -0.4145,  2.2421,  ...,  0.9997, -1.3678,  0.5796],\n",
       "          ...,\n",
       "          [-0.1915,  0.9890, -0.3757,  ..., -0.1802, -0.4430, -0.5143],\n",
       "          [ 1.9618,  1.1359,  0.5398,  ...,  0.9689, -1.2480, -0.9500],\n",
       "          [ 0.1203,  0.1666, -0.3795,  ...,  0.8189,  0.0648,  0.2312]],\n",
       "\n",
       "         [[ 0.1560,  0.3381,  0.2712,  ..., -0.1956, -0.3202,  0.2602],\n",
       "          [ 1.3876,  0.2662,  1.1139,  ..., -0.6642,  3.1507, -0.1517],\n",
       "          [ 1.1564, -0.3057,  0.1134,  ..., -0.8303,  1.9128,  1.4387],\n",
       "          ...,\n",
       "          [-0.5663,  0.3055,  0.8785,  ..., -0.6798,  1.3627,  1.3186],\n",
       "          [-1.5716,  0.3728,  0.5542,  ...,  1.0271,  2.3384,  0.6441],\n",
       "          [ 0.3922,  0.0842, -0.9334,  ..., -0.6170,  0.4065, -0.1380]],\n",
       "\n",
       "         [[ 0.3781, -1.0399,  0.3710,  ...,  0.5417,  0.1400, -2.6923],\n",
       "          [ 1.6695,  0.8654,  0.4997,  ...,  0.0101, -2.0980, -5.0604],\n",
       "          [ 2.6774, -0.2483,  1.0595,  ...,  0.3351, -0.7225, -4.3561],\n",
       "          ...,\n",
       "          [ 3.4679,  0.3492,  0.5711,  ...,  0.0386, -2.0212, -4.4697],\n",
       "          [ 4.3342,  0.5476,  0.8369,  ...,  1.2309, -2.0053, -4.0730],\n",
       "          [ 3.7607,  0.6002,  0.6300,  ...,  0.9113, -1.8418, -4.0578]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-2.6916e-02,  1.3970e-02, -1.6033e-02,  ...,  2.1528e-02,\n",
       "            5.2457e-03, -8.9160e-03],\n",
       "          [-1.1197e+00,  7.5002e-01, -4.3196e-01,  ...,  1.2707e-01,\n",
       "           -5.3838e-01, -7.4607e-01],\n",
       "          [ 2.4776e-01,  8.2977e-01,  1.2122e-01,  ..., -1.3001e+00,\n",
       "            4.2611e-02, -7.3145e-01],\n",
       "          ...,\n",
       "          [-1.4703e-01,  5.5311e-02,  4.6455e-01,  ..., -9.1206e-01,\n",
       "           -4.4499e-01,  3.6745e-01],\n",
       "          [-1.1231e-01, -7.2610e-01, -1.0701e+00,  ..., -1.2041e+00,\n",
       "           -6.7239e-01,  1.0086e-01],\n",
       "          [-1.8977e-01, -5.5453e-01,  2.4375e-01,  ..., -1.0415e+00,\n",
       "            1.7989e-01,  5.8152e-01]],\n",
       "\n",
       "         [[ 4.1929e-02,  1.2356e-02,  2.4966e-02,  ...,  2.2225e-02,\n",
       "            2.7300e-04,  3.9801e-03],\n",
       "          [ 5.3057e-01, -7.0525e-01,  3.2413e-01,  ...,  9.4446e-01,\n",
       "            3.9218e-01, -3.0272e-01],\n",
       "          [ 1.1605e+00, -5.9611e-01, -4.0273e-01,  ...,  2.8944e-02,\n",
       "            6.7138e-01, -1.0553e+00],\n",
       "          ...,\n",
       "          [ 1.0627e-01, -2.6550e-01, -2.2463e-01,  ...,  7.8611e-01,\n",
       "           -5.7942e-01, -9.2505e-03],\n",
       "          [-1.6384e+00, -5.9562e-01,  4.2667e-01,  ...,  3.4092e-01,\n",
       "           -9.2224e-01,  8.2685e-01],\n",
       "          [-5.1853e-01, -9.2491e-01, -4.7436e-01,  ..., -2.6759e-01,\n",
       "            7.6221e-01,  6.1725e-01]],\n",
       "\n",
       "         [[ 6.2642e-03, -9.8228e-03, -1.8488e-02,  ...,  7.1977e-03,\n",
       "            4.1257e-03,  1.1415e-02],\n",
       "          [ 6.9469e-01,  4.5420e-01,  2.9870e-02,  ...,  1.0897e+00,\n",
       "            1.8552e+00,  5.0254e-01],\n",
       "          [ 9.8480e-01,  5.9903e-01, -1.3521e+00,  ..., -1.4876e+00,\n",
       "           -6.7637e-01,  6.0612e-01],\n",
       "          ...,\n",
       "          [ 1.2401e+00,  8.2679e-01, -1.5396e+00,  ...,  6.4787e-01,\n",
       "            8.9623e-01,  1.2472e+00],\n",
       "          [ 6.4310e-01,  1.2080e+00, -1.0765e+00,  ...,  7.0359e-01,\n",
       "            1.3632e+00,  2.5660e+00],\n",
       "          [-1.3537e-01,  9.7775e-01,  1.0773e-02,  ...,  5.4920e-01,\n",
       "           -9.7158e-01,  1.1928e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.5737e-02,  1.9664e-01, -2.5176e-01,  ...,  3.4272e-02,\n",
       "           -2.0880e-01,  1.8073e-01],\n",
       "          [-3.5870e-01,  1.5718e+00, -4.0143e+00,  ...,  1.0717e+00,\n",
       "           -3.8480e+00,  3.8426e+00],\n",
       "          [ 5.8899e-01,  7.6323e-01, -2.1754e+00,  ...,  8.5851e-01,\n",
       "           -2.7951e+00,  2.8886e+00],\n",
       "          ...,\n",
       "          [-1.9225e-01,  8.9997e-01, -8.9701e-01,  ..., -4.9338e-01,\n",
       "           -1.4630e+00,  2.4428e+00],\n",
       "          [ 1.3882e+00,  1.9408e+00, -5.3325e+00,  ...,  6.9565e-01,\n",
       "           -3.5208e+00,  3.8478e+00],\n",
       "          [-1.1770e+00,  1.7812e+00, -1.3378e+00,  ...,  6.9791e-01,\n",
       "           -8.9789e-01,  1.4657e+00]],\n",
       "\n",
       "         [[ 7.3655e-03, -3.6641e-02,  1.7748e-02,  ...,  9.9678e-03,\n",
       "           -1.8952e-02, -3.0895e-02],\n",
       "          [-6.6026e-01,  8.1542e-01, -8.2995e-02,  ...,  5.9177e-01,\n",
       "            1.9074e-02,  7.5621e-02],\n",
       "          [ 1.0475e+00,  4.9152e-01,  1.6038e+00,  ..., -5.3633e-01,\n",
       "           -1.2954e+00,  3.4643e-01],\n",
       "          ...,\n",
       "          [ 3.6189e-01, -1.3605e-01,  5.0336e-01,  ..., -1.6787e+00,\n",
       "           -1.1440e+00,  7.4621e-01],\n",
       "          [ 1.4958e+00, -4.1461e-01, -4.2708e-01,  ..., -1.3885e+00,\n",
       "           -1.3229e+00,  1.2758e+00],\n",
       "          [ 5.4109e-01, -3.1235e-01,  3.1954e-01,  ...,  4.0616e-01,\n",
       "           -8.1647e-01,  6.3652e-01]],\n",
       "\n",
       "         [[ 1.6055e-01, -2.8448e-01, -2.3100e-01,  ..., -1.0885e+00,\n",
       "           -1.2077e-01,  4.2789e-01],\n",
       "          [ 8.5740e-01, -1.3733e+00, -2.1611e-01,  ..., -5.5184e-01,\n",
       "           -2.0730e-01,  3.7584e-01],\n",
       "          [ 8.7086e-01, -5.4874e-01, -1.7161e-01,  ..., -3.5845e-02,\n",
       "            4.7429e-01, -6.9273e-02],\n",
       "          ...,\n",
       "          [ 6.7164e-02,  4.4544e-01,  6.3622e-01,  ..., -4.4671e-01,\n",
       "            3.1615e-01,  2.8791e-01],\n",
       "          [-6.9501e-01,  4.9974e-01,  1.1254e+00,  ..., -6.5717e-01,\n",
       "            3.9272e-01,  5.7274e-01],\n",
       "          [-5.5406e-01,  1.5566e-04, -1.2686e+00,  ..., -8.2791e-01,\n",
       "            2.8202e-02, -8.1375e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-0.1351, -0.0362, -1.6113,  ...,  0.5835,  3.4358,  0.0772],\n",
       "          [ 0.3266,  0.3574, -1.4552,  ..., -0.8421,  4.8820,  1.0040],\n",
       "          [ 0.2424,  0.1607, -1.5329,  ..., -1.0684,  6.2072,  0.4569],\n",
       "          ...,\n",
       "          [ 0.3766,  0.2719, -0.5036,  ...,  0.0690,  7.7390,  1.6326],\n",
       "          [ 1.5863,  0.0140, -0.7303,  ...,  0.5886,  6.0164,  1.2811],\n",
       "          [ 0.1218,  0.4997, -1.2343,  ..., -0.4027,  6.9703,  0.5802]],\n",
       "\n",
       "         [[-0.1671,  0.2811,  0.4578,  ..., -0.3154, -0.0515, -0.0890],\n",
       "          [ 0.8385,  1.6301,  0.1086,  ...,  0.2832, -5.5078, -0.2146],\n",
       "          [-0.3835,  0.6762, -1.3178,  ...,  0.5511, -5.8474, -0.4772],\n",
       "          ...,\n",
       "          [ 1.4778,  0.1201,  0.8029,  ...,  0.7800, -5.6912, -1.7338],\n",
       "          [ 0.8840, -0.0451, -0.2922,  ...,  0.2280, -6.1206, -0.8441],\n",
       "          [ 0.6264, -0.6026, -0.7583,  ...,  0.0737, -5.4768, -1.0461]],\n",
       "\n",
       "         [[-0.3001, -0.0944, -0.5672,  ...,  0.0191, -0.4272, -0.5316],\n",
       "          [-0.3904, -2.5970, -1.1461,  ..., -3.2253, -0.7482, -1.3454],\n",
       "          [ 1.2213, -0.7639, -1.3670,  ..., -3.8375, -1.5597,  0.4074],\n",
       "          ...,\n",
       "          [ 1.5223, -0.4917, -1.2885,  ..., -4.4421, -1.7416,  0.2021],\n",
       "          [ 1.2253, -0.8760, -0.9759,  ..., -3.2343, -1.8282, -0.6949],\n",
       "          [ 1.2783,  0.4471, -3.0229,  ..., -4.3747, -2.3045, -0.2581]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6168,  0.2192,  0.3218,  ...,  0.4827, -0.4014,  0.9718],\n",
       "          [-0.0662,  1.3109, -0.0980,  ...,  0.6072,  0.6882,  2.2331],\n",
       "          [-0.6900,  1.2661,  0.6401,  ..., -0.1263, -1.1128,  1.9991],\n",
       "          ...,\n",
       "          [-1.6588,  0.8899,  1.2634,  ...,  1.4240,  0.3041,  1.5443],\n",
       "          [-0.2064,  0.8695,  0.4822,  ...,  1.3333,  0.0322,  1.7293],\n",
       "          [-1.1501,  0.2901,  1.0506,  ...,  0.5272,  0.3989,  2.6646]],\n",
       "\n",
       "         [[-2.8681,  0.6248,  2.4498,  ..., -1.3850,  0.0088,  2.5055],\n",
       "          [-2.2864,  3.1582,  1.0504,  ..., -1.4418, -0.7331,  1.9576],\n",
       "          [-1.8831,  3.3007,  1.1491,  ..., -1.8374, -1.0752,  2.6898],\n",
       "          ...,\n",
       "          [-1.2228,  2.6244,  1.8916,  ..., -1.8892, -0.1731,  3.9756],\n",
       "          [-1.5913,  2.7212,  3.3194,  ..., -3.0865, -1.0798,  4.0618],\n",
       "          [-1.6287,  3.8137,  1.8314,  ..., -2.2283, -2.6101,  3.7062]],\n",
       "\n",
       "         [[-0.4490, -0.4393, -0.5248,  ...,  0.9083, -0.1425,  0.4696],\n",
       "          [-1.2487,  1.7800,  0.2186,  ...,  0.7452, -0.2672,  2.2064],\n",
       "          [-2.2823, -0.4189, -0.8157,  ...,  1.5785, -0.3261, -1.2399],\n",
       "          ...,\n",
       "          [-1.9920, -0.5232, -0.8607,  ...,  0.3477, -0.8269, -0.1967],\n",
       "          [-3.3350,  0.8679, -1.4934,  ...,  0.2300, -1.2162,  1.0116],\n",
       "          [-0.4292, -0.6477, -1.9495,  ...,  0.5516, -0.8716, -0.1279]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-3.7720e-03, -7.2254e-02,  2.4058e-02,  ..., -1.2039e-01,\n",
       "            7.6148e-02,  5.5451e-02],\n",
       "          [-6.4065e-01, -1.5450e+00,  1.1846e+00,  ..., -5.3809e-01,\n",
       "            2.0171e-01,  1.7249e+00],\n",
       "          [ 1.1675e+00,  2.6808e-01,  3.0482e-01,  ...,  2.3511e+00,\n",
       "           -2.7215e+00, -2.7045e-01],\n",
       "          ...,\n",
       "          [ 4.0639e-02, -3.1238e-02,  1.1122e+00,  ...,  2.3227e+00,\n",
       "           -2.7119e+00, -5.3265e-01],\n",
       "          [-1.2160e+00,  5.2327e-02,  5.8259e-01,  ...,  1.5068e+00,\n",
       "           -3.8228e-01,  1.2553e-01],\n",
       "          [ 4.6529e-01,  4.1375e-01,  1.7826e-01,  ...,  2.2073e+00,\n",
       "           -2.9109e+00, -1.3603e+00]],\n",
       "\n",
       "         [[-3.2398e-02,  4.1088e-02,  2.9917e-02,  ...,  8.2838e-04,\n",
       "           -7.6249e-04,  3.1395e-03],\n",
       "          [ 7.7487e-01,  6.8574e-02, -3.0221e-01,  ...,  8.1291e-01,\n",
       "            2.0244e+00, -1.4779e+00],\n",
       "          [-5.2261e-01,  1.3560e+00,  9.6479e-01,  ..., -1.5240e-01,\n",
       "            1.2017e+00,  6.7613e-01],\n",
       "          ...,\n",
       "          [-1.2039e-01,  1.5707e+00, -1.4644e-01,  ...,  8.4649e-01,\n",
       "            4.8315e-01,  7.8508e-01],\n",
       "          [-5.8858e-01,  4.1523e-01,  4.4222e-01,  ...,  6.9833e-01,\n",
       "           -6.9534e-01, -1.0636e+00],\n",
       "          [ 1.3835e+00,  1.4130e+00,  6.3378e-02,  ...,  9.3208e-01,\n",
       "            5.0722e-01, -3.1301e-01]],\n",
       "\n",
       "         [[-2.9983e-02,  1.0624e-02, -3.3552e-02,  ..., -2.6205e-02,\n",
       "            1.4682e-03, -1.3821e-02],\n",
       "          [ 4.0298e-01, -5.7646e-01,  1.7854e+00,  ...,  4.2753e-01,\n",
       "           -1.9702e+00, -1.2466e+00],\n",
       "          [-1.6584e+00, -1.4105e+00, -1.4114e+00,  ...,  2.2098e-01,\n",
       "           -1.4387e+00,  7.6012e-01],\n",
       "          ...,\n",
       "          [ 1.4771e+00, -7.7681e-01,  1.1526e+00,  ..., -5.6008e-01,\n",
       "           -1.8228e+00, -2.7413e-01],\n",
       "          [ 4.5749e-01,  2.4564e-01, -1.6486e-01,  ..., -4.3394e-01,\n",
       "           -2.9189e+00,  4.2998e-02],\n",
       "          [-7.0736e-01,  1.3171e-01,  1.0587e+00,  ...,  1.3192e-01,\n",
       "           -1.2161e+00, -1.5181e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7200e-03,  4.0518e-02, -8.0766e-03,  ..., -2.5735e-03,\n",
       "            4.0887e-03, -1.2235e-02],\n",
       "          [ 3.3062e-01,  1.0861e+00,  1.0681e+00,  ...,  2.4072e-01,\n",
       "            1.6129e+00, -1.6564e-01],\n",
       "          [ 1.0747e+00, -9.0646e-01,  1.9817e-01,  ..., -3.6146e-01,\n",
       "           -6.1714e-01, -1.0726e+00],\n",
       "          ...,\n",
       "          [ 2.7771e+00,  2.6316e-01,  1.0550e-01,  ..., -2.6384e-02,\n",
       "            1.1497e+00, -1.7451e+00],\n",
       "          [ 8.5688e-01, -1.1849e+00, -1.6780e+00,  ...,  1.5443e-01,\n",
       "            1.6407e+00, -6.2322e-01],\n",
       "          [ 1.5298e+00, -3.1473e-01, -6.6161e-01,  ..., -9.2658e-02,\n",
       "            1.7027e+00, -1.8445e-01]],\n",
       "\n",
       "         [[-4.9156e-02, -1.7990e-01,  2.5839e-01,  ..., -2.5308e-01,\n",
       "            1.8210e-01,  2.6433e-01],\n",
       "          [ 7.4020e-01, -5.8716e-01,  4.8570e-01,  ..., -1.9085e+00,\n",
       "            1.0262e+00,  5.9074e-01],\n",
       "          [-5.2119e-02, -4.0496e-01,  3.9634e-01,  ...,  9.4189e-01,\n",
       "           -5.8632e-01,  1.9335e-01],\n",
       "          ...,\n",
       "          [-4.6038e-01, -3.9577e-01, -1.0219e+00,  ...,  7.2548e-01,\n",
       "            3.2832e-01, -9.1310e-01],\n",
       "          [-7.9768e-01, -3.7327e-01, -6.9983e-01,  ...,  7.8960e-01,\n",
       "            6.4256e-01,  8.3902e-01],\n",
       "          [-7.3296e-01,  1.9681e-01, -2.0689e+00,  ..., -1.5973e+00,\n",
       "            2.3357e-01,  3.6430e-01]],\n",
       "\n",
       "         [[-1.7954e-04,  1.1610e-02,  3.4796e-02,  ..., -9.8644e-03,\n",
       "            5.4238e-02, -1.4751e-02],\n",
       "          [-3.1343e-01,  2.1564e-01,  3.6862e-01,  ..., -5.8465e-01,\n",
       "            6.6625e-01, -1.2642e+00],\n",
       "          [-1.1923e+00, -9.8690e-03,  2.3393e-01,  ..., -5.0498e-01,\n",
       "           -5.4845e-01, -7.6472e-01],\n",
       "          ...,\n",
       "          [-1.9753e+00, -7.1620e-01, -2.1769e-01,  ..., -9.2002e-02,\n",
       "           -1.8157e-01, -3.8225e-01],\n",
       "          [-1.2406e+00,  5.1040e-01,  5.5950e-01,  ..., -9.2073e-02,\n",
       "           -1.1880e-01, -1.2023e-01],\n",
       "          [-1.0482e+00, -1.4723e-01,  6.4236e-01,  ...,  1.3925e+00,\n",
       "           -3.1424e-01, -3.3225e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[-4.2979e-01, -9.8629e-01,  5.6982e-01,  ..., -9.2473e-01,\n",
       "           -5.5969e-01, -5.8997e-01],\n",
       "          [-1.8690e+00, -5.0951e+00,  3.0375e+00,  ..., -1.0370e-01,\n",
       "           -5.6500e-01, -5.0166e-02],\n",
       "          [-2.9178e-01, -5.3937e+00,  3.6997e+00,  ...,  1.4540e-01,\n",
       "            5.1084e-03, -9.5132e-01],\n",
       "          ...,\n",
       "          [-2.1019e-01, -4.4362e+00,  4.3975e+00,  ..., -1.7469e-01,\n",
       "           -1.4638e+00, -1.7458e+00],\n",
       "          [-6.2101e-01, -5.1249e+00,  2.8442e+00,  ...,  2.3728e-02,\n",
       "           -1.5390e+00, -7.2726e-01],\n",
       "          [-7.0502e-01, -4.0709e+00,  4.9818e+00,  ..., -9.0270e-01,\n",
       "           -8.4095e-01, -1.2226e+00]],\n",
       "\n",
       "         [[-1.1620e-01, -4.4629e-01, -3.8151e-01,  ..., -4.2630e-01,\n",
       "           -7.4749e-01, -4.4265e-01],\n",
       "          [ 5.9570e-01, -3.2635e+00,  2.1596e+00,  ..., -1.7424e+00,\n",
       "            1.2715e+00, -1.1101e+00],\n",
       "          [-5.1822e-01, -2.0858e+00,  2.0203e+00,  ..., -1.9592e+00,\n",
       "            3.0147e-01, -9.0138e-01],\n",
       "          ...,\n",
       "          [-2.1230e-01, -1.6385e+00,  3.1571e-01,  ..., -2.1147e+00,\n",
       "            7.2815e-01, -2.2132e+00],\n",
       "          [-1.4298e+00, -4.5804e-01, -4.2748e-01,  ..., -3.5460e+00,\n",
       "            1.9921e+00, -1.5976e-01],\n",
       "          [-1.5855e+00, -2.3435e+00,  4.4978e-01,  ..., -8.3781e-01,\n",
       "           -3.1651e-01, -9.8502e-01]],\n",
       "\n",
       "         [[-2.5822e-01, -1.5094e-01, -4.1226e-01,  ..., -1.2009e-01,\n",
       "           -9.6287e-01, -8.9815e-03],\n",
       "          [-1.0011e+00,  1.4107e-01, -5.9468e-02,  ..., -2.8081e+00,\n",
       "            3.5312e-01,  6.7789e-01],\n",
       "          [-1.2389e+00, -6.4614e-01, -5.3313e-01,  ..., -2.9484e+00,\n",
       "            1.6611e+00, -1.0714e-01],\n",
       "          ...,\n",
       "          [-3.6478e+00, -3.4587e-01, -1.2683e+00,  ..., -4.0083e+00,\n",
       "            7.7443e-01,  8.8080e-02],\n",
       "          [-3.4230e+00, -8.1344e-01, -2.3726e+00,  ..., -4.9989e+00,\n",
       "            8.9491e-01,  4.7895e-01],\n",
       "          [-3.8653e+00,  3.4541e-01, -2.8880e+00,  ..., -3.5226e+00,\n",
       "            1.7652e+00, -2.9324e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.2311e-01, -1.2013e+00, -4.0582e-01,  ...,  9.3518e-02,\n",
       "            9.6102e-01, -4.8645e-01],\n",
       "          [ 3.3458e-02, -6.0641e-01, -1.9008e-01,  ..., -6.6021e-01,\n",
       "           -6.0173e-01, -1.2217e+00],\n",
       "          [-1.2290e+00, -1.8503e+00,  1.5936e-01,  ...,  3.0572e-01,\n",
       "            6.4191e-01,  1.7945e-01],\n",
       "          ...,\n",
       "          [ 6.7972e-02,  4.3506e-01,  8.0331e-01,  ..., -4.3890e-01,\n",
       "           -2.3893e+00, -4.4367e-01],\n",
       "          [ 5.4706e-02,  1.6151e+00,  1.3696e+00,  ..., -9.6603e-01,\n",
       "           -2.3789e+00,  1.0465e+00],\n",
       "          [-8.0204e-01, -1.2735e-01, -3.6772e-02,  ...,  6.3957e-02,\n",
       "           -1.2083e+00,  5.5421e-01]],\n",
       "\n",
       "         [[-8.9188e-01, -5.0060e-01,  2.5070e+00,  ...,  1.8292e+00,\n",
       "            1.6764e+00,  6.1598e-01],\n",
       "          [ 4.4444e-01,  1.2789e+00, -1.9758e+00,  ..., -3.3531e-01,\n",
       "           -8.1741e-01, -3.8413e+00],\n",
       "          [-1.2123e+00,  1.2441e+00, -1.4953e+00,  ...,  1.7110e-01,\n",
       "            3.1548e-01, -3.8545e+00],\n",
       "          ...,\n",
       "          [-9.3987e-01,  1.1135e-01, -5.6636e-01,  ...,  1.1272e+00,\n",
       "           -2.6985e-01, -3.3372e+00],\n",
       "          [-1.6376e+00,  6.9748e-01, -8.7665e-01,  ...,  8.4211e-01,\n",
       "           -4.0722e-01, -2.9246e+00],\n",
       "          [-1.1711e-01, -1.3949e+00, -1.4465e+00,  ...,  1.7332e+00,\n",
       "            6.2031e-01, -2.9477e+00]],\n",
       "\n",
       "         [[ 9.2693e-01,  1.2979e+00, -3.4387e-02,  ...,  1.3835e-02,\n",
       "            6.4465e-01,  1.5395e-02],\n",
       "          [ 1.5554e+00, -1.6474e+00, -8.1812e-01,  ..., -2.3272e+00,\n",
       "           -2.0928e+00,  2.8317e+00],\n",
       "          [ 1.1903e+00, -2.0815e+00, -1.5975e+00,  ..., -1.8723e+00,\n",
       "           -2.4918e+00,  2.7988e+00],\n",
       "          ...,\n",
       "          [ 6.5078e-01, -3.1003e+00,  5.7355e-01,  ..., -1.3509e+00,\n",
       "           -1.6807e+00,  3.9847e+00],\n",
       "          [-5.7984e-01, -3.6906e+00,  4.5380e-01,  ..., -9.7216e-01,\n",
       "           -1.9288e+00,  4.5602e+00],\n",
       "          [ 7.7508e-01, -2.5874e+00, -7.0510e-01,  ..., -1.8124e+00,\n",
       "           -1.4241e+00,  2.6121e+00]]]], grad_fn=<CloneBackward0>), tensor([[[[ 2.0888e-03,  3.4191e-02, -1.4537e-02,  ...,  2.5668e-02,\n",
       "            1.8979e-02,  2.4921e-02],\n",
       "          [-8.2908e-01,  1.1603e+00,  1.2424e+00,  ...,  5.3285e-01,\n",
       "           -3.8456e-01,  6.1099e-01],\n",
       "          [-3.5282e-01, -5.0885e-01, -2.3546e-01,  ...,  6.9992e-02,\n",
       "            6.7116e-02,  1.2102e+00],\n",
       "          ...,\n",
       "          [ 1.0726e+00,  5.6365e-01,  1.3843e+00,  ..., -4.0832e-02,\n",
       "            7.1192e-01,  1.1200e+00],\n",
       "          [-7.4310e-01,  1.7790e+00,  7.3856e-01,  ..., -3.1011e-01,\n",
       "            4.3923e-01,  2.5590e-01],\n",
       "          [-1.8543e-01,  5.9299e-02, -2.0941e-01,  ...,  6.6225e-01,\n",
       "           -7.1272e-01,  1.8451e-01]],\n",
       "\n",
       "         [[ 3.6381e-02, -1.0629e-02, -2.2596e-03,  ...,  4.7989e-02,\n",
       "           -2.5187e-02,  1.2511e-02],\n",
       "          [ 2.0197e-01, -2.6569e-01,  1.2116e+00,  ..., -4.9246e-01,\n",
       "            1.3159e+00, -1.0418e-01],\n",
       "          [ 8.1127e-01, -4.7091e-01,  1.3528e-01,  ..., -4.6559e-02,\n",
       "           -4.7058e-01, -9.1505e-02],\n",
       "          ...,\n",
       "          [ 1.1032e+00, -3.7501e-01, -6.3936e-01,  ..., -6.0237e-01,\n",
       "           -3.4410e-01, -5.5798e-01],\n",
       "          [ 4.3772e-01,  1.6843e-01, -4.7008e-01,  ..., -6.7789e-01,\n",
       "            1.3970e+00, -1.5951e+00],\n",
       "          [ 1.2216e-01, -3.6200e-01,  3.5953e-01,  ..., -6.4175e-01,\n",
       "           -8.1021e-01,  2.3354e-01]],\n",
       "\n",
       "         [[-5.0207e-02, -4.9454e-02, -2.0872e-03,  ..., -4.6345e-02,\n",
       "           -7.2054e-03,  2.7855e-02],\n",
       "          [-2.1402e-01,  7.8085e-01,  3.8868e-01,  ...,  2.7844e-01,\n",
       "            2.9506e-01,  5.9958e-01],\n",
       "          [-2.3595e-01, -2.1024e-01,  9.0151e-02,  ..., -1.0202e-01,\n",
       "           -7.6838e-01,  7.2400e-01],\n",
       "          ...,\n",
       "          [-1.7805e-01,  9.5446e-01, -7.6394e-01,  ..., -3.3225e-01,\n",
       "           -1.5148e+00, -6.2018e-01],\n",
       "          [-6.3982e-02,  2.0822e+00, -5.7981e-01,  ..., -5.7401e-01,\n",
       "           -1.2594e+00, -2.0808e+00],\n",
       "          [-8.9486e-01,  5.7404e-01, -1.7787e+00,  ...,  2.6994e-01,\n",
       "           -5.8597e-02,  5.8466e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.0649e-01,  1.2487e-01, -1.5533e-03,  ..., -1.4172e-01,\n",
       "           -3.9813e-02, -1.3679e-01],\n",
       "          [-4.8396e-01, -4.9120e-01,  9.0451e-01,  ...,  1.1312e+00,\n",
       "           -5.1656e-01,  4.7787e-01],\n",
       "          [ 1.3712e+00, -2.5765e+00,  1.3771e-01,  ...,  1.8290e-01,\n",
       "            8.0750e-01,  2.1782e-01],\n",
       "          ...,\n",
       "          [ 5.4695e-01, -6.3088e-01,  1.0751e-01,  ..., -9.2356e-01,\n",
       "           -9.3493e-01,  7.5474e-02],\n",
       "          [ 6.1914e-01,  1.9949e+00,  2.7069e-01,  ...,  2.4778e+00,\n",
       "           -2.3721e+00,  9.6583e-01],\n",
       "          [-2.6156e-01,  9.2196e-01, -9.1030e-01,  ...,  9.4709e-01,\n",
       "           -1.1623e+00,  3.8233e-02]],\n",
       "\n",
       "         [[ 6.6056e+00, -6.4331e+00, -5.7317e+00,  ..., -4.8388e+00,\n",
       "            8.6172e+00,  6.6357e+00],\n",
       "          [-1.3913e-01, -1.2355e+00, -1.6108e-01,  ..., -6.8516e-01,\n",
       "           -6.1668e-01,  3.9828e-01],\n",
       "          [ 3.1193e-01, -1.4813e+00,  2.1936e-01,  ..., -1.0262e+00,\n",
       "            3.6315e-01,  1.6489e-01],\n",
       "          ...,\n",
       "          [-1.6393e-01, -1.2413e+00, -1.5629e-01,  ...,  5.4269e-01,\n",
       "           -2.3319e-01,  7.4196e-01],\n",
       "          [ 3.6719e-02, -8.6796e-01, -1.1136e+00,  ...,  5.4552e-01,\n",
       "            7.4668e-03,  8.1686e-01],\n",
       "          [-8.4668e-01, -8.3772e-01, -7.0348e-01,  ..., -1.9784e-01,\n",
       "           -5.4256e-01,  1.7856e+00]],\n",
       "\n",
       "         [[ 2.4136e-02, -3.3757e-04, -6.9993e-02,  ...,  8.0505e-03,\n",
       "           -2.5117e-02,  1.0879e-02],\n",
       "          [ 9.4979e-02,  1.6729e+00, -1.7130e-01,  ...,  5.5105e-01,\n",
       "            1.8406e+00,  3.1792e-01],\n",
       "          [-6.2368e-01, -1.0494e+00, -7.4608e-01,  ..., -3.8535e-01,\n",
       "            5.5138e-01, -2.1966e-01],\n",
       "          ...,\n",
       "          [-9.2595e-02,  6.2144e-01, -3.7716e-01,  ...,  6.7907e-01,\n",
       "            6.5772e-01, -6.2082e-01],\n",
       "          [ 2.2246e-01,  2.6780e-01, -4.3068e-01,  ...,  3.9050e-01,\n",
       "            1.1002e-01, -6.8504e-01],\n",
       "          [-1.1027e-01, -3.9569e-01, -5.4049e-01,  ..., -2.7684e-01,\n",
       "            3.8127e-01, -1.6013e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 2.4195e-01,  7.3868e-01, -2.8266e-01,  ...,  1.8650e+00,\n",
       "            3.5290e+00, -3.2826e-01],\n",
       "          [ 7.5980e-01,  4.3891e-01, -8.5092e-01,  ...,  6.1802e-01,\n",
       "            8.1313e-01, -1.1110e+00],\n",
       "          [ 5.7869e-01,  9.3089e-01, -1.3574e+00,  ...,  9.3863e-01,\n",
       "            2.4275e+00, -7.1145e-01],\n",
       "          ...,\n",
       "          [ 1.3296e+00, -6.3521e-01, -3.1101e+00,  ...,  2.7996e+00,\n",
       "            1.1276e+00, -1.3549e+00],\n",
       "          [ 2.0143e-01, -2.1727e-01, -2.6971e+00,  ...,  3.0097e+00,\n",
       "            8.3802e-01, -6.1966e-01],\n",
       "          [-8.6116e-01,  1.3657e-01, -2.4769e+00,  ...,  3.3221e+00,\n",
       "            1.2824e+00, -1.4848e+00]],\n",
       "\n",
       "         [[ 8.6485e-01,  6.7177e-01,  5.7300e-01,  ..., -1.3346e+00,\n",
       "           -4.1196e-01,  3.9488e-01],\n",
       "          [-1.0564e+00, -2.1800e-01, -3.2157e-01,  ..., -1.0576e+00,\n",
       "           -6.9398e-01,  8.6921e-01],\n",
       "          [-3.7539e-01,  2.4954e+00,  4.0846e-01,  ..., -2.2242e+00,\n",
       "           -9.6682e-01,  9.8861e-01],\n",
       "          ...,\n",
       "          [-1.0371e+00,  4.2852e+00, -3.2929e-01,  ..., -3.0707e+00,\n",
       "           -2.0762e+00,  1.4528e+00],\n",
       "          [-8.5008e-01,  3.0804e+00, -1.2150e+00,  ..., -3.1456e+00,\n",
       "           -1.2461e+00,  1.9303e+00],\n",
       "          [-3.2975e-01,  4.0173e+00, -1.0858e+00,  ..., -3.1254e+00,\n",
       "           -1.5727e+00,  5.0070e-01]],\n",
       "\n",
       "         [[-4.2164e-01, -6.8963e-01,  8.2256e-01,  ..., -2.6505e+00,\n",
       "           -1.9418e-01, -2.8203e-01],\n",
       "          [-5.8532e-01, -1.3398e+00,  1.4776e+00,  ..., -4.5482e+00,\n",
       "            1.6540e-01, -1.1708e+00],\n",
       "          [ 7.3326e-01,  1.3794e+00,  1.1260e+00,  ..., -3.1585e+00,\n",
       "            1.1845e+00, -1.2455e-01],\n",
       "          ...,\n",
       "          [ 1.1175e+00,  3.3691e+00,  2.8952e+00,  ..., -1.2648e+00,\n",
       "            2.0524e+00, -6.0483e-01],\n",
       "          [ 1.6355e+00,  2.2643e+00,  3.5949e+00,  ..., -1.3772e+00,\n",
       "            1.2091e+00,  6.1483e-01],\n",
       "          [ 6.4241e-01,  2.4549e+00,  4.4355e+00,  ..., -2.3551e+00,\n",
       "            2.0106e-01,  8.3240e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.2544e-01,  9.4866e-01,  3.5708e-02,  ..., -1.0864e+00,\n",
       "            1.4699e+00, -6.0402e-01],\n",
       "          [-1.8364e-01, -1.6383e+00,  1.0907e+00,  ..., -1.5019e+00,\n",
       "           -1.5264e+00, -8.7841e-01],\n",
       "          [ 3.5824e-01, -1.1344e+00,  4.6711e-01,  ...,  3.9571e-01,\n",
       "            2.6061e-02,  1.3055e-01],\n",
       "          ...,\n",
       "          [ 9.5706e-01, -1.7451e+00,  5.5404e-02,  ...,  9.0713e-01,\n",
       "           -2.4591e-01, -4.1209e-01],\n",
       "          [ 1.3760e+00,  7.8512e-01, -9.2478e-01,  ...,  1.8139e+00,\n",
       "           -3.9427e-03, -1.6376e+00],\n",
       "          [ 1.3105e+00, -1.4466e+00, -1.7040e-01,  ...,  1.1619e+00,\n",
       "           -4.7327e-01, -3.8257e-01]],\n",
       "\n",
       "         [[-4.4327e+00, -4.3045e-01,  8.9099e-01,  ..., -8.7674e-01,\n",
       "            1.3129e+00, -7.3340e-01],\n",
       "          [-7.5284e+00, -1.2464e+00,  2.0603e-01,  ..., -2.3714e-01,\n",
       "            1.7460e+00, -1.8333e+00],\n",
       "          [-6.3472e+00,  5.2716e-01,  3.6456e-01,  ..., -2.5444e-01,\n",
       "            1.6849e+00, -1.5160e+00],\n",
       "          ...,\n",
       "          [-6.3198e+00, -7.7416e-01,  8.1709e-01,  ..., -8.3292e-01,\n",
       "            1.4452e+00, -1.6553e+00],\n",
       "          [-6.6300e+00, -5.0731e-01,  8.8112e-01,  ..., -1.1029e+00,\n",
       "            1.4743e+00, -1.8882e+00],\n",
       "          [-7.4519e+00, -6.3406e-01,  5.9572e-01,  ..., -1.4607e+00,\n",
       "            1.7715e+00, -1.5152e+00]],\n",
       "\n",
       "         [[ 1.2757e+00,  1.1059e+00, -2.5172e-01,  ...,  4.6634e-01,\n",
       "           -9.9843e-01,  5.6792e-01],\n",
       "          [ 9.8755e-01, -4.8401e-01,  5.3190e-01,  ...,  1.1038e+00,\n",
       "           -5.9008e-01,  1.8214e-01],\n",
       "          [ 5.4763e-01, -6.4445e-01, -3.1173e-01,  ...,  2.6398e-01,\n",
       "            2.0847e-01,  3.3118e-01],\n",
       "          ...,\n",
       "          [ 2.5314e+00, -7.6335e-01, -1.0492e-01,  ...,  8.2085e-01,\n",
       "           -1.1988e+00, -2.9279e-01],\n",
       "          [ 2.4746e+00, -5.5484e-01, -3.4783e-01,  ...,  4.1895e-01,\n",
       "           -2.1694e+00,  5.2507e-01],\n",
       "          [ 2.9709e+00, -2.3832e+00, -1.0347e+00,  ...,  8.9473e-01,\n",
       "           -1.0084e+00,  8.8439e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-1.2405e+00,  6.8344e-01,  6.0533e-01,  ...,  1.9600e-01,\n",
       "            5.0117e-01, -5.2980e-01],\n",
       "          [ 1.4534e+00, -1.3942e+00,  7.0076e-01,  ..., -5.1735e-01,\n",
       "           -2.6272e+00,  1.4793e+00],\n",
       "          [-1.2126e-01,  5.9387e-01,  1.3257e-01,  ...,  1.8426e+00,\n",
       "            1.1823e+00, -1.7376e+00],\n",
       "          ...,\n",
       "          [ 1.9028e+00, -5.0025e-01, -4.7611e-01,  ...,  2.4878e+00,\n",
       "            1.7365e+00, -2.4627e+00],\n",
       "          [ 2.8016e+00, -1.3498e-01, -2.4239e+00,  ..., -1.8036e-01,\n",
       "            1.5148e+00,  1.5909e+00],\n",
       "          [ 1.6867e+00, -1.0004e+00, -6.0360e-01,  ...,  1.1552e+00,\n",
       "            1.6337e+00, -1.6988e+00]],\n",
       "\n",
       "         [[-1.3134e-01, -2.8157e-01, -5.0443e-01,  ...,  9.2303e-02,\n",
       "            8.6368e-02, -4.6295e-01],\n",
       "          [ 8.8280e-01,  1.0358e+00,  3.5039e-02,  ...,  8.2118e-01,\n",
       "           -2.2631e-01,  5.8121e-01],\n",
       "          [ 8.1469e-02, -2.6948e-01,  1.6502e-01,  ...,  7.5645e-01,\n",
       "           -6.7810e-01, -1.0102e+00],\n",
       "          ...,\n",
       "          [ 7.7176e-01,  5.3321e-01, -4.6775e-01,  ..., -3.5666e-02,\n",
       "            3.3792e-01, -7.7448e-03],\n",
       "          [ 8.2928e-01,  1.4073e+00,  2.7924e-01,  ..., -8.5846e-01,\n",
       "            5.5501e-01,  8.4504e-02],\n",
       "          [ 4.5938e-02,  6.8225e-01, -5.6330e-02,  ..., -3.2949e-02,\n",
       "            9.1059e-01, -7.1482e-02]],\n",
       "\n",
       "         [[ 5.3262e-01,  1.2994e-01,  4.6814e-01,  ..., -4.5993e-02,\n",
       "           -2.8624e-02, -2.5593e-01],\n",
       "          [-3.5041e-01,  1.1177e-01, -1.7866e+00,  ...,  8.9796e-01,\n",
       "           -5.6005e-01,  8.3345e-01],\n",
       "          [ 1.5998e+00, -1.9562e+00,  3.9539e-01,  ..., -1.3924e+00,\n",
       "           -1.6195e+00,  3.1011e-04],\n",
       "          ...,\n",
       "          [ 9.8781e-01, -1.4355e+00, -1.5733e-01,  ..., -1.2118e+00,\n",
       "           -1.8139e+00, -1.5774e-01],\n",
       "          [-3.0392e-02,  1.8863e+00, -2.4560e+00,  ..., -2.9182e-02,\n",
       "           -1.6919e+00,  1.4411e+00],\n",
       "          [-2.1705e-01, -2.1457e-01, -2.4259e+00,  ..., -1.2604e-02,\n",
       "           -3.1994e+00, -1.3560e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.4218e-01,  4.5034e-01,  3.2959e-01,  ...,  1.5257e-01,\n",
       "           -5.4010e-01, -1.3105e-01],\n",
       "          [-1.6998e-01, -6.2825e-01, -3.0970e-01,  ..., -2.6133e-01,\n",
       "            8.4398e-01,  1.1571e+00],\n",
       "          [ 1.2212e-01,  1.4089e-01,  5.9344e-01,  ..., -1.3145e+00,\n",
       "            2.3209e-01,  3.4021e-01],\n",
       "          ...,\n",
       "          [ 1.3941e+00, -7.4462e-01,  4.0570e-01,  ...,  3.4865e-01,\n",
       "            5.3334e-02, -3.6749e-01],\n",
       "          [ 2.4863e+00, -9.3636e-02, -1.4209e+00,  ...,  3.4191e-01,\n",
       "            1.8452e+00, -1.0579e+00],\n",
       "          [ 9.9593e-01, -1.6290e+00,  4.6020e-01,  ...,  6.0638e-03,\n",
       "            4.8632e-01, -1.4308e+00]],\n",
       "\n",
       "         [[-1.9029e-01,  2.1448e-01, -1.2890e-01,  ..., -1.9447e-01,\n",
       "            3.7060e-01,  3.1871e-02],\n",
       "          [ 5.2733e-01, -4.8201e-01,  1.2074e-01,  ...,  6.0809e-01,\n",
       "           -6.2142e-01,  1.8368e-01],\n",
       "          [-3.9262e-02, -1.9922e-02, -7.4932e-01,  ...,  1.2447e-01,\n",
       "            3.3078e-01, -1.2285e-01],\n",
       "          ...,\n",
       "          [ 4.0893e-02, -1.3086e+00, -1.4561e+00,  ..., -1.0226e+00,\n",
       "            2.1528e-01, -5.0108e-01],\n",
       "          [-1.4542e-02, -2.6776e-01, -1.5489e+00,  ..., -4.1730e-01,\n",
       "           -7.6307e-01, -1.5448e-01],\n",
       "          [-4.4181e-02, -2.8432e-02,  2.7176e-02,  ...,  1.2021e+00,\n",
       "            8.8415e-01,  3.0869e-01]],\n",
       "\n",
       "         [[ 1.4124e-01,  1.4771e-01,  1.5121e-01,  ...,  5.1501e-02,\n",
       "           -1.4830e-01,  4.5938e-02],\n",
       "          [-1.0055e+00, -1.7474e-01, -4.7402e-02,  ...,  2.7254e-01,\n",
       "            1.0390e+00, -4.1485e-01],\n",
       "          [-1.1690e+00, -1.5100e-01,  5.9131e-02,  ...,  4.1324e-01,\n",
       "           -3.1795e-01, -4.8702e-02],\n",
       "          ...,\n",
       "          [-1.7238e+00,  1.6809e+00,  7.3360e-01,  ..., -4.3620e-01,\n",
       "           -1.9385e-01,  8.3178e-01],\n",
       "          [-1.1526e+00,  1.6640e+00,  5.5051e-01,  ..., -1.7697e+00,\n",
       "            3.2607e-01,  3.6001e-01],\n",
       "          [ 2.3871e-01,  5.7655e-01, -7.2164e-01,  ..., -1.8870e-01,\n",
       "            1.4384e+00, -1.6465e-02]]]], grad_fn=<CloneBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = XGLM_model(**inputs, labels=inputs['input_ids'])\n",
    "outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> Emma and Monica are not doctors, but Mark and Andrew are. Who are doctors? Emma and Monica are doctors, but Mark and Andrew are doctors.</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = XGLM_model.generate(**inputs, max_length=50,\n",
    "            num_beams=2,\n",
    "            early_stopping=True)\n",
    "\n",
    "decoded = [XGLM_tokenizer.decode(ids) for ids in outputs]\n",
    "\n",
    "decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Emma and Monica are not doctors, but Mark and Andrew are. Who are doctors? A:  Mark and Andrew are doctors.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "XGLM_pipe(context + ' ' + question + ' A: ', return_full_text=True, max_new_tokens=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters will return suggestions, and only the newly created text making it easier for prompting suggestions.\n",
    "mGPT_pipe(\"My tart needs some\", num_return_sequences=4, return_full_text=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
